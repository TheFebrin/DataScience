{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "from re import sub\n",
    "from collections import OrderedDict \n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bayes' theorem allows us to construct a classifier in which we\n",
    "model how the data is generated. Here we will describe a\n",
    "simple and popular example of such a classifier called the naive\n",
    "Bayes classifier.  Despite its simplicity It is quite effective for\n",
    "classification of text documents (e.g. as spam and non-spam).\n",
    "\n",
    "Let a document be a sequence of words $D=W_1,W_2,\\ldots,W_n$ \n",
    "We will model generation of text documents as a two-stage process.\n",
    "First, document category $C_j$ is drawn at random with probability\n",
    "$p(C_j)$, also called the *a priori* probability.\n",
    "To define the class-conditional probability\n",
    "$p(D|C_j)$, we will make a simplifying (naive)\n",
    "assumption, that every word in the document is drawn independently at\n",
    "random with probability $p(W_i|C)$:\n",
    "\n",
    "\\begin{equation*}\n",
    "  p(D|C_j) = p(W_1,W_2,\\ldots,W_n | C_j) \\approx p(W_1|C_j)p(W_2|C_j)\\ldots p(W_n|C_j).\n",
    "\\end{equation*}\n",
    "\n",
    "To infer the class of a document we apply the Bayes theorem:\n",
    "\\begin{equation*}   p(C_j|D) = \\frac{p(D|C_j)p(C_j)}{p(D)} = \\frac{p(C_j)p(W_1|C_j)p(W_2|C_j)\\ldots p(W_n|C_j)}{p(D)}.\n",
    "\\end{equation*}\n",
    "Please note that since we assumed only a finite number of classes,\n",
    "we can compute the term $p(D)$ by making sure that the *a\n",
    "posteriori probabilities* $p(C_j|D)$ sum to $1$ over all classes.\n",
    "\n",
    "We will try to mimic the language-guessing feature\n",
    "of [Google Translate](https://translate.google.com/), although\n",
    "on a much smaller scale.  We are given an input which is a\n",
    "lower-case sequence of characters (such as *\"some people like\n",
    "pineapple on their pizza\"*), and we determine whether the\n",
    "sequence's language is English, Polish or Spanish.\n",
    "We will treat each character as a separate observation.\n",
    "The numbers are taken from [Wikipedia article on letter frequency](https://en.wikipedia.org/wiki/Letter_frequency#Relative_frequencies_of_letters_in_other_languages). We display the first few rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_table = u\"\"\"English|French|German|Spanish|Portuguese|Esperanto|Italian|Turkish|Swedish|Polish|Dutch|Danish|Icelandic|Finnish|Czech\n",
    "a|8.167|7.636|6.516|11.525|14.634|12.117|11.745|12.920|9.383|10.503|7.486|6.025|10.110|12.217|8.421\n",
    "b|1.492|0.901|1.886|2.215|1.043|0.980|0.927|2.844|1.535|1.740|1.584|2.000|1.043|0.281|0.822\n",
    "c|2.782|3.260|2.732|4.019|3.882|0.776|4.501|1.463|1.486|3.895|1.242|0.565|0|0.281|0.740\n",
    "d|4.253|3.669|5.076|5.010|4.992|3.044|3.736|5.206|4.702|3.725|5.933|5.858|1.575|1.043|3.475\n",
    "e|12.702|14.715|16.396|12.181|12.570|8.995|11.792|9.912|10.149|7.352|18.91|15.453|6.418|7.968|7.562\n",
    "f|2.228|1.066|1.656|0.692|1.023|1.037|1.153|0.461|2.027|0.143|0.805|2.406|3.013|0.194|0.084\n",
    "g|2.015|0.866|3.009|1.768|1.303|1.171|1.644|1.253|2.862|1.731|3.403|4.077|4.241|0.392|0.092\n",
    "h|6.094|0.737|4.577|0.703|0.781|0.384|0.636|1.212|2.090|1.015|2.380|1.621|1.871|1.851|1.356\n",
    "i|6.966|7.529|6.550|6.247|6.186|10.012|10.143|9.600|5.817|8.328|6.499|6.000|7.578|10.817|6.073\n",
    "j|0.153|0.613|0.268|0.493|0.397|3.501|0.011|0.034|0.614|1.836|1.46|0.730|1.144|2.042|1.433\n",
    "k|0.772|0.049|1.417|0.011|0.015|4.163|0.009|5.683|3.140|2.753|2.248|3.395|3.314|4.973|2.894\n",
    "l|4.025|5.456|3.437|4.967|2.779|6.104|6.510|5.922|5.275|2.564|3.568|5.229|4.532|5.761|3.802\n",
    "m|2.406|2.968|2.534|3.157|4.738|2.994|2.512|3.752|3.471|2.515|2.213|3.237|4.041|3.202|2.446\n",
    "n|6.749|7.095|9.776|6.712|4.446|7.955|6.883|7.987|8.542|6.237|10.032|7.240|7.711|8.826|6.468\n",
    "o|7.507|5.796|2.594|8.683|9.735|8.779|9.832|2.976|4.482|6.667|6.063|4.636|2.166|5.614|6.695\n",
    "p|1.929|2.521|0.670|2.510|2.523|2.755|3.056|0.886|1.839|2.445|1.57|1.756|0.789|1.842|1.906\n",
    "q|0.095|1.362|0.018|0.877|1.204|0|0.505|0|0.020|0|0.009|0.007|0|0.013|0.001\n",
    "r|5.987|6.693|7.003|6.871|6.530|5.914|6.367|7.722|8.431|5.243|6.411|8.956|8.581|2.872|4.799\n",
    "s|6.327|7.948|7.270|7.977|6.805|6.092|4.981|3.014|6.590|5.224|3.73|5.805|5.630|7.862|5.212\n",
    "t|9.056|7.244|6.154|4.632|4.336|5.276|5.623|3.314|7.691|2.475|6.79|6.862|4.953|8.750|5.727\n",
    "u|2.758|6.311|4.166|2.927|3.639|3.183|3.011|3.235|1.919|2.062|1.99|1.979|4.562|5.008|2.160\n",
    "v|0.978|1.838|0.846|1.138|1.575|1.904|2.097|0.959|2.415|0.012|2.85|2.332|2.437|2.250|5.344\n",
    "w|2.360|0.074|1.921|0.017|0.037|0|0.033|0|0.142|5.813|1.52|0.069|0|0.094|0.016\n",
    "x|0.150|0.427|0.034|0.215|0.253|0|0.003|0|0.159|0.004|0.036|0.028|0.046|0.031|0.027\n",
    "y|1.974|0.128|0.039|1.008|0.006|0|0.020|3.336|0.708|3.206|0.035|0.698|0.900|1.745|1.043\n",
    "z|0.074|0.326|1.134|0.467|0.470|0.494|1.181|1.500|0.070|4.852|1.39|0.034|0|0.051|1.503\n",
    "à|0|0.486|0|0|0.072|0|0.635|0|0|0|0|0|0|0|0\n",
    "â|0|0.051|0|0|0.562|0|0|0|0|0|0|0|0|0|0\n",
    "á|0|0|0|0.502|0.118|0|0|0|0|0|0|0|1.799|0|0.867\n",
    "å|0|0|0|0|0|0|0|0|1.338|0|0|1.190|0|0.003|0\n",
    "ä|0|0|0.578|0|0|0|0|0|1.797|0|0|0|0|3.577|0\n",
    "ã|0|0|0|0|0.733|0|0|0|0|0|0|0|0|0|0\n",
    "ą|0|0|0|0|0|0|0|0|0|0.699|0|0|0|0|0\n",
    "æ|0|0|0|0|0|0|0|0|0|0|0|0.872|0.867|0|0\n",
    "œ|0|0.018|0|0|0|0|0|0|0|0|0|0|0|0|0\n",
    "ç|0|0.085|0|0|0.530|0|0|1.156|0|0|0|0|0|0|0\n",
    "ĉ|0|0|0|0|0|0.657|0|0|0|0|0|0|0|0|0\n",
    "ć|0|0|0|0|0|0|0|0|0|0.743|0|0|0|0|0\n",
    "č|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0.462\n",
    "ď|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0.015\n",
    "ð|0|0|0|0|0|0|0|0|0|0|0|0|4.393|0|0\n",
    "è|0|0.271|0|0|0|0|0.263|0|0|0|0|0|0|0|0\n",
    "é|0|1.504|0|0.433|0.337|0|0|0|0|0|0|0|0.647|0|0.633\n",
    "ê|0|0.218|0|0|0.450|0|0|0|0|0|0|0|0|0|0\n",
    "ë|0|0.008|0|0|0|0|0|0|0|0|0|0|0|0|0\n",
    "ę|0|0|0|0|0|0|0|0|0|1.035|0|0|0|0|0\n",
    "ě|0|0|0|0|0|0|0|0|0|0|0|0|0|0|1.222\n",
    "ĝ|0|0|0|0|0|0.691|0|0|0|0|0|0|0|0|0\n",
    "ğ|0|0|0|0|0|0|0|1.125|0|0|0|0|0|0|0\n",
    "ĥ|0|0|0|0|0|0.022|0|0|0|0|0|0|0|0|0\n",
    "î|0|0.045|0|0|0|0|0|0|0|0|0|0|0|0|0\n",
    "ì|0|0|0|0|0|0|0.030|0|0|0|0|0|0|0|0\n",
    "í|0|0|0|0.725|0.132|0|0|0|0|0|0|0|1.570|0|1.643\n",
    "ï|0|0.005|0|0|0|0|0|0|0|0|0|0|0|0|0\n",
    "ı|0|0|0|0|0|0|0|5.114|0|0|0|0|0|0|0\n",
    "ĵ|0|0|0|0|0|0.055|0|0|0|0|0|0|0|0|0\n",
    "ł|0|0|0|0|0|0|0|0|0|2.109|0|0|0|0|0\n",
    "ñ|0|0|0|0.311|0|0|0|0|0|0|0|0|0|0|0\n",
    "ń|0|0|0|0|0|0|0|0|0|0.362|0|0|0|0|0\n",
    "ň|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0.007\n",
    "ò|0|0|0|0|0|0|0.002|0|0|0|0|0|0|0|0\n",
    "ö|0|0|0.443|0|0|0|0|0.777|1.305|0|0|0|0.777|0.444|0\n",
    "ô|0|0.023|0|0|0.635|0|0|0|0|0|0|0|0|0|0\n",
    "ó|0|0|0|0.827|0.296|0|0|0|0|1.141|0|0|0.994|0|0.024\n",
    "õ|0|0|0|0|0.040|0|0|0|0|0|0|0|0|0|0\n",
    "ø|0|0|0|0|0|0|0|0|0|0|0|0.939|0|0|0\n",
    "ř|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0.380\n",
    "ŝ|0|0|0|0|0|0.385|0|0|0|0|0|0|0|0|0\n",
    "ş|0|0|0|0|0|0|0|1.780|0|0|0|0|0|0|0\n",
    "ś|0|0|0|0|0|0|0|0|0|0.814|0|0|0|0|0\n",
    "š|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0.688\n",
    "ß|0|0|0.307|0|0|0|0|0|0|0|0|0|0|0|0\n",
    "ť|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0.006\n",
    "þ|0|0|0|0|0|0|0|0|0|0|0|0|1.455|0|0\n",
    "ù|0|0.058|0|0|0|0|0.166|0|0|0|0|0|0|0|0\n",
    "ú|0|0|0|0.168|0.207|0|0|0|0|0|0|0|0.613|0|0.045\n",
    "û|0|0.060|0|0|0|0|0|0|0|0|0|0|0|0|0\n",
    "ŭ|0|0|0|0|0|0.520|0|0|0|0|0|0|0|0|0\n",
    "ü|0|0|0.995|0.012|0.026|0|0|1.854|0|0|0|0|0|0|0\n",
    "ů|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0.204\n",
    "ý|0|0|0|0|0|0|0|0|0|0|0|0|0.228|0|0.995\n",
    "ź|0|0|0|0|0|0|0|0|0|0.078|0|0|0|0|0\n",
    "ż|0|0|0|0|0|0|0|0|0|0.706|0|0|0|0|0\n",
    "ž|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0.721\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>French</th>\n",
       "      <th>German</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>Portuguese</th>\n",
       "      <th>Esperanto</th>\n",
       "      <th>Italian</th>\n",
       "      <th>Turkish</th>\n",
       "      <th>Swedish</th>\n",
       "      <th>Polish</th>\n",
       "      <th>Dutch</th>\n",
       "      <th>Danish</th>\n",
       "      <th>Icelandic</th>\n",
       "      <th>Finnish</th>\n",
       "      <th>Czech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>8.167</td>\n",
       "      <td>7.636</td>\n",
       "      <td>6.516</td>\n",
       "      <td>11.525</td>\n",
       "      <td>14.634</td>\n",
       "      <td>12.117</td>\n",
       "      <td>11.745</td>\n",
       "      <td>12.920</td>\n",
       "      <td>9.383</td>\n",
       "      <td>10.503</td>\n",
       "      <td>7.486</td>\n",
       "      <td>6.025</td>\n",
       "      <td>10.110</td>\n",
       "      <td>12.217</td>\n",
       "      <td>8.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1.492</td>\n",
       "      <td>0.901</td>\n",
       "      <td>1.886</td>\n",
       "      <td>2.215</td>\n",
       "      <td>1.043</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.927</td>\n",
       "      <td>2.844</td>\n",
       "      <td>1.535</td>\n",
       "      <td>1.740</td>\n",
       "      <td>1.584</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.043</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>2.782</td>\n",
       "      <td>3.260</td>\n",
       "      <td>2.732</td>\n",
       "      <td>4.019</td>\n",
       "      <td>3.882</td>\n",
       "      <td>0.776</td>\n",
       "      <td>4.501</td>\n",
       "      <td>1.463</td>\n",
       "      <td>1.486</td>\n",
       "      <td>3.895</td>\n",
       "      <td>1.242</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>4.253</td>\n",
       "      <td>3.669</td>\n",
       "      <td>5.076</td>\n",
       "      <td>5.010</td>\n",
       "      <td>4.992</td>\n",
       "      <td>3.044</td>\n",
       "      <td>3.736</td>\n",
       "      <td>5.206</td>\n",
       "      <td>4.702</td>\n",
       "      <td>3.725</td>\n",
       "      <td>5.933</td>\n",
       "      <td>5.858</td>\n",
       "      <td>1.575</td>\n",
       "      <td>1.043</td>\n",
       "      <td>3.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>12.702</td>\n",
       "      <td>14.715</td>\n",
       "      <td>16.396</td>\n",
       "      <td>12.181</td>\n",
       "      <td>12.570</td>\n",
       "      <td>8.995</td>\n",
       "      <td>11.792</td>\n",
       "      <td>9.912</td>\n",
       "      <td>10.149</td>\n",
       "      <td>7.352</td>\n",
       "      <td>18.910</td>\n",
       "      <td>15.453</td>\n",
       "      <td>6.418</td>\n",
       "      <td>7.968</td>\n",
       "      <td>7.562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   English  French  German  Spanish  Portuguese  Esperanto  Italian  Turkish  \\\n",
       "a    8.167   7.636   6.516   11.525      14.634     12.117   11.745   12.920   \n",
       "b    1.492   0.901   1.886    2.215       1.043      0.980    0.927    2.844   \n",
       "c    2.782   3.260   2.732    4.019       3.882      0.776    4.501    1.463   \n",
       "d    4.253   3.669   5.076    5.010       4.992      3.044    3.736    5.206   \n",
       "e   12.702  14.715  16.396   12.181      12.570      8.995   11.792    9.912   \n",
       "\n",
       "   Swedish  Polish   Dutch  Danish  Icelandic  Finnish  Czech  \n",
       "a    9.383  10.503   7.486   6.025     10.110   12.217  8.421  \n",
       "b    1.535   1.740   1.584   2.000      1.043    0.281  0.822  \n",
       "c    1.486   3.895   1.242   0.565      0.000    0.281  0.740  \n",
       "d    4.702   3.725   5.933   5.858      1.575    1.043  3.475  \n",
       "e   10.149   7.352  18.910  15.453      6.418    7.968  7.562  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(StringIO(wiki_table), sep='|', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Languages: English,French,German,Spanish,Portuguese,Esperanto,Italian,Turkish,Swedish,Polish,Dutch,Danish,Icelandic,Finnish,Czech\n",
      "Letters: a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z, à, â, á, å, ä, ã, ą, æ, œ, ç, ĉ, ć, č, ď, ð, è, é, ê, ë, ę, ě, ĝ, ğ, ĥ, î, ì, í, ï, ı, ĵ, ł, ñ, ń, ň, ò, ö, ô, ó, õ, ø, ř, ŝ, ş, ś, š, ß, ť, þ, ù, ú, û, ŭ, ü, ů, ý, ź, ż, ž\n",
      "P(ę|Polish) = 1.035\n"
     ]
    }
   ],
   "source": [
    "# We can easiily manipulate the letter frequency table using Pandas\n",
    "langs = list(df)\n",
    "letters = list(df.index)\n",
    "print('Languages:', ','.join(langs))\n",
    "print('Letters:', ', '.join(letters))\n",
    "print('P(ę|Polish) =', df.loc['ę', 'Polish'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total letter count by language:\n",
      "English        99.999\n",
      "French        100.060\n",
      "German        100.002\n",
      "Spanish       100.000\n",
      "Portuguese    100.040\n",
      "Esperanto      99.960\n",
      "Italian       100.007\n",
      "Turkish       106.997\n",
      "Swedish        99.999\n",
      "Polish        100.027\n",
      "Dutch         100.157\n",
      "Danish         99.999\n",
      "Icelandic      99.998\n",
      "Finnish       100.004\n",
      "Czech          88.013\n",
      "dtype: float64\n",
      "\n",
      "After normalization:\n",
      "English       1.0\n",
      "French        1.0\n",
      "German        1.0\n",
      "Spanish       1.0\n",
      "Portuguese    1.0\n",
      "Esperanto     1.0\n",
      "Italian       1.0\n",
      "Turkish       1.0\n",
      "Swedish       1.0\n",
      "Polish        1.0\n",
      "Dutch         1.0\n",
      "Danish        1.0\n",
      "Icelandic     1.0\n",
      "Finnish       1.0\n",
      "Czech         1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# The values are percentages of letter appearance, but curiously enough they don't\n",
    "# sum to 100%.\n",
    "print(f'\\nTotal letter count by language:\\n{df.sum(0)}')\n",
    "\n",
    "# Normalize the data such that the letter frequencies add up to 1 for each language\n",
    "df_norm = df.div(df.sum(axis=0), axis=1)\n",
    "print(f'\\nAfter normalization:\\n{df_norm.sum(0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(sent, langs, df):\n",
    "    \"\"\"Returns the most probable language of a sentence\"\"\"\n",
    "    \n",
    "    # Try working with log-probabilities. \n",
    "    # to prevent taking log(0) you can e.g. add a very small amount (1e-100)\n",
    "    # to each tabulated frequency.\n",
    "    \n",
    "    df_log = np.log(df + 1e-100)\n",
    "\n",
    "    # normalize the sentence: remove spaces and punctuations, take lower case\n",
    "    sent = sub('\\W+', '', sent.lower())\n",
    "\n",
    "    log_probs = {}\n",
    "    Z = 0\n",
    "    for lang in langs:\n",
    "        P_DC = np.sum(np.array(([df_log.loc[x, lang] for x in sent])))\n",
    "        P_DC = np.exp(P_DC)\n",
    "        log_probs[lang] = P_DC * (1 / len(langs))\n",
    "        Z += log_probs[lang]\n",
    "        \n",
    "    \n",
    "    for x in log_probs:\n",
    "        log_probs[x] /= Z\n",
    "        \n",
    "    # TODO compute language probabilitie and order from most to least probable\n",
    "    probs = OrderedDict(reversed(sorted(log_probs.items(), key=itemgetter(1))))\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No dejes para mañana lo que puedas hacer hoy.:\n",
      "Spanish: 1.000\t\n",
      "\n",
      "Przed wyruszeniem w drogę należy zebrać drużynę.:\n",
      "Polish: 1.000\t\n",
      "\n",
      "Żeby zrozumieć rekurencję, należy najpierw zrozumieć rekurencję.:\n",
      "Polish: 1.000\t\n",
      "\n",
      "Si vale la pena hacerlo vale la pena hacerlo bien.:\n",
      "Italian: 0.925\tSpanish: 0.047\tEnglish: 0.007\tFrench: 0.006\tDutch: 0.006\tSwedish: 0.004\tPortuguese: 0.003\tEsperanto: 0.001\t\n",
      "\n",
      "Experience is what you get when you didn't get what you wanted.:\n",
      "English: 1.000\t\n",
      "\n",
      "Należy prowokować intelekt, nie intelektualistów.:\n",
      "Polish: 1.000\t\n",
      "\n",
      "Ich habe ein Katze und Hund und Schule.:\n",
      "German: 0.995\tDutch: 0.003\tEnglish: 0.002\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"No dejes para mañana lo que puedas hacer hoy.\",\n",
    "    \"Przed wyruszeniem w drogę należy zebrać drużynę.\",\n",
    "    \"Żeby zrozumieć rekurencję, należy najpierw zrozumieć rekurencję.\",\n",
    "    \"Si vale la pena hacerlo vale la pena hacerlo bien.\",\n",
    "    \"Experience is what you get when you didn't get what you wanted.\",\n",
    "    \"Należy prowokować intelekt, nie intelektualistów.\",\n",
    "    \"Ich habe ein Katze und Hund und Schule.\"]\n",
    "\n",
    "for sent in sentences:\n",
    "    print(f'{sent}:')\n",
    "    for k, v in naive_bayes(sent, langs, df_norm).items():\n",
    "        if v < 1e-3:\n",
    "            break\n",
    "        print(f'{k}: {v:.3f}\\t', end='')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
