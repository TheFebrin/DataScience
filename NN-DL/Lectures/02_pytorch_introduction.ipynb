{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "colab": {
      "name": "02-pytorch_introduction.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7iwf99lUqra5",
        "1uCHWXHqqrbC",
        "5vDwMr3Pqrbf",
        "ilIlhSZiqrcE",
        "7rslBU14qrcI",
        "VdPVOXZjqrcL"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kkulczak/dl_uwr/blob/summer2020/Lectures/02_pytorch_introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "94C63t_kqraJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "eR3NShy9qraO",
        "colab_type": "code",
        "outputId": "1b1db7bb-35fc-4505-a2cb-b4439ab69dd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.4.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "QJi62WF3qraS",
        "colab_type": "code",
        "outputId": "7e96bb7a-9fee-4536-b95c-e46c8a847cda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# Similar to numpy\n",
        "x_torch = torch.ones(5, 4)\n",
        "print(x_torch)\n",
        "print(x_torch.shape) #alias for x.size()\n",
        "print(x_torch.dtype)\n",
        "print()\n",
        "y_np = np.ones((5,4))\n",
        "print(y_np)\n",
        "print(y_np.shape)\n",
        "print(y_np.dtype)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "torch.Size([5, 4])\n",
            "torch.float32\n",
            "\n",
            "[[1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]]\n",
            "(5, 4)\n",
            "float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "XLVzt2owqraW",
        "colab_type": "code",
        "outputId": "a6b250b7-d230-45e3-8626-7ab79279996f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "# Rand\n",
        "rand = torch.rand(2,2)\n",
        "print('rand:', rand)\n",
        "# From List\n",
        "from_list = torch.tensor([[1.,2.], [4., 5.]])\n",
        "print('from_list:', from_list)\n",
        "x = rand * from_list\n",
        "print('element wise:', x)\n",
        "y = rand @ from_list\n",
        "print('matrix multiplication: ', y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rand: tensor([[0.2206, 0.3276],\n",
            "        [0.7629, 0.6468]])\n",
            "from_list: tensor([[1., 2.],\n",
            "        [4., 5.]])\n",
            "element wise: tensor([[0.2206, 0.6551],\n",
            "        [3.0516, 3.2338]])\n",
            "matrix multiplication:  tensor([[1.5308, 2.0790],\n",
            "        [3.3500, 4.7597]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "ybIY4y1-qrab",
        "colab_type": "code",
        "outputId": "bbc1db82-fd80-4156-9082-cec36c79ba50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "#  broadcasting also works as expected\n",
        "arange = torch.arange(2)[:, None]\n",
        "print('arange:', arange)\n",
        "res = from_list + arange\n",
        "print('res:', res)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "arange: tensor([[0],\n",
            "        [1]])\n",
            "res: tensor([[1., 2.],\n",
            "        [5., 6.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "eZtfsRSjqraf",
        "colab_type": "code",
        "outputId": "a3d5ef38-65ad-4b79-eb75-36763f324124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# in place\n",
        "res.add_(2)\n",
        "res"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3., 4.],\n",
              "        [7., 8.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ZYt6_kgdqraj",
        "colab_type": "text"
      },
      "source": [
        "Any operation that mutates a tensor in-place is post-fixed with an ``_``.\n",
        "    For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "66no4WHMqrak",
        "colab_type": "code",
        "outputId": "305b6b32-384d-4b7b-ba31-c658fee3981d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "#But some functionalities are diffrent\n",
        "#You have been warned\n",
        "x_torch = x_torch.view(2, 2, -1)\n",
        "print(x_torch)\n",
        "\n",
        "\n",
        "#Reshape can copy, if layout is not compatible\n",
        "x_torch = x_torch.reshape(2, 2, -1)\n",
        "print(x_torch)\n",
        "\n",
        "y_np = y_np.reshape(2, 2, -1)\n",
        "print(y_np)\n",
        "\n",
        "# In torch there is also `reshape` function. But it beahves difrentlly.\n",
        "# It sometimes can make a copy of an array instead of a reference.\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[1., 1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1.]]])\n",
            "tensor([[[1., 1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1.]]])\n",
            "[[[1. 1. 1. 1. 1.]\n",
            "  [1. 1. 1. 1. 1.]]\n",
            "\n",
            " [[1. 1. 1. 1. 1.]\n",
            "  [1. 1. 1. 1. 1.]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "XYrUxhexqrao",
        "colab_type": "text"
      },
      "source": [
        "If you have a one element tensor, use ``.item()`` to get the value as a\n",
        "Python number\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "ufnuYJw2qrap",
        "colab_type": "code",
        "outputId": "a80cb9c1-3a34-433f-e938-3c0adcaf435a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item(), type(x.item()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.2808])\n",
            "0.28076329827308655 <class 'float'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "g_TAkV77qras",
        "colab_type": "text"
      },
      "source": [
        "# Numpy bridge\n",
        "Converting a Torch Tensor to a NumPy array and vice versa is a breeze.\n",
        "Transformation do not need copying underlying C array. Only `python` properties of the object has to be changed\n",
        "\n",
        "### Conclussion: It is fast\n",
        "Sometimes it is easier to transofrm data in numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "mPROHNviqrau",
        "colab_type": "code",
        "outputId": "c1164167-574b-4f02-b4a1-99391edde47d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = torch.ones(5)\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "2MN9Iaueqrax",
        "colab_type": "code",
        "outputId": "7890e539-db7d-43cd-dd44-ec444414d286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "b = a.numpy()\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "nsajACiZqra0",
        "colab_type": "text"
      },
      "source": [
        "See how the numpy array changed in value.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "T0GeNUYcqra1",
        "colab_type": "code",
        "outputId": "6fa08bc6-4032-4882-f9c4-ce3a78db27ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "7iwf99lUqra5",
        "colab_type": "text"
      },
      "source": [
        "### Converting NumPy Array to Torch Tensor\n",
        "\n",
        "See how changing the np array changed the Torch Tensor automatically\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "kBDqB29Sqra6",
        "colab_type": "code",
        "outputId": "f2db8843-008f-4f89-c123-1795b3463ce6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "McyHgpZ8qra9",
        "colab_type": "text"
      },
      "source": [
        "All the Tensors on the CPU except a CharTensor support converting to\n",
        "NumPy and back.\n",
        "\n",
        "# CUDA Tensors\n",
        "\n",
        "\n",
        "Tensors can be moved onto any device using the ``.to`` method. To interact with each other both tensors have to be on the same device. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "JRjVo7pvqra-",
        "colab_type": "code",
        "outputId": "c70f44f0-8772-49d8-eeb2-332b8fcce1b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# let us run this cell only if CUDA is available\n",
        "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    print(z)\n",
        "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.2808], device='cuda:0')\n",
            "tensor([1.2808], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "1uCHWXHqqrbC",
        "colab_type": "text"
      },
      "source": [
        "### Recommended way for comapatibillity\n",
        "\n",
        "On systems with multiple GPU's there will be {`cuda:1`, `cuda:2`...} and so on.\n",
        "\n",
        "There is no automatic way to decide which GPU is \"free\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "gQPte9lYqrbD",
        "colab_type": "code",
        "outputId": "1860f87e-3019-44e0-942d-58e5811891e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "tensor = torch.zeros(2,2).to(device)\n",
        "tensor"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "AJ0OsEu8qrbG",
        "colab_type": "code",
        "outputId": "de91f499-cd19-41be-e54a-98f2aa03c940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cpu = torch.ones(1)\n",
        "try:\n",
        "    cpu + tensor\n",
        "except Exception as e:\n",
        "    print(type(e), e)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'RuntimeError'> expected device cpu but got device cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZE-EC_bqrbJ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Autograd: Automatic Differentiation\n",
        "===================================\n",
        "\n",
        "The ``autograd`` package provides automatic differentiation for all operations\n",
        "on Tensors. It is a define-by-run framework, which means that your backprop is\n",
        "defined by how your code is run, and that every single iteration can be\n",
        "different.\n",
        "\n",
        "\n",
        "Tensor\n",
        "--------\n",
        "\n",
        "1. If you set its attribute``.requires_grad`` as ``True``, it starts to track all operations on it. \n",
        "\n",
        "2. When\n",
        "you finish your computation you can call ``.backward()`` and have all the\n",
        "gradients computed automatically. The gradient for this tensor will be\n",
        "accumulated into ``.grad`` attribute.\n",
        "\n",
        "3. To stop a tensor from tracking history, you can call ``.detach()`` to detach\n",
        "it from the computation history, and to prevent future computation from being\n",
        "tracked.\n",
        "\n",
        "4. To prevent tracking history (and using memory), you can also wrap the code block\n",
        "in ``with torch.no_grad():``. This can be particularly helpful when **evaluating a\n",
        "model** because the model may have trainable parameters with\n",
        "``requires_grad=True``, but for which we don't need the gradients.\n",
        "\n",
        "There’s one more class which is very important for autograd\n",
        "implementation - a ``Function``.\n",
        "\n",
        "``Tensor`` and ``Function`` are interconnected and build up an acyclic\n",
        "graph, that encodes a complete history of computation. Each tensor has\n",
        "a ``.grad_fn`` attribute that references a ``Function`` that has created\n",
        "the ``Tensor`` (except for Tensors created by the user - their\n",
        "``grad_fn is None``).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "MpmAP8jYqrbK",
        "colab_type": "text"
      },
      "source": [
        "Create a tensor and set ``requires_grad=True`` to track computation with it\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "X5aSfXVdqrbL",
        "colab_type": "code",
        "outputId": "e9cc9560-4bfd-4245-f3e7-865a2cc7c683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x = torch.ones(2, 3, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "G--2GzHOqrbO",
        "colab_type": "text"
      },
      "source": [
        "Do a tensor operation:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "6wJgQ4f0qrbP",
        "colab_type": "code",
        "outputId": "bc5fb1c5-c165-48dd-a441-a8a5dc303f20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "y = x + 2\n",
        "print(y)\n",
        "print(y.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3., 3., 3.],\n",
            "        [3., 3., 3.]], grad_fn=<AddBackward0>)\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "bb1_6slBqrbT",
        "colab_type": "text"
      },
      "source": [
        "``y`` was created as a result of an operation, so it has a ``grad_fn``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "CLiElAMkqrbU",
        "colab_type": "code",
        "outputId": "ffed88e8-fb40-462d-c830-386db2fd863f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y.grad_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<AddBackward0 object at 0x7f22bdd9b278>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "AtQkwk8_qrbX",
        "colab_type": "text"
      },
      "source": [
        "Do more operations on ``y``\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "3WyyX3d6qrbY",
        "colab_type": "code",
        "outputId": "7d8e9474-e989-48f3-89de-5432e1751795",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "print(z, out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[27., 27., 27.],\n",
            "        [27., 27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "x5jufLAcqrbb",
        "colab_type": "text"
      },
      "source": [
        "``.requires_grad_( ... )`` changes an existing Tensor's ``requires_grad``\n",
        "flag in-place. The input flag defaults to ``False`` if not given.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "c_VluC56qrbc",
        "colab_type": "code",
        "outputId": "c2b08a81-ef50-402c-a05e-e80209fe4d84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "a = torch.randn(2, 2)\n",
        "print(a.requires_grad)\n",
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "5vDwMr3Pqrbf",
        "colab_type": "text"
      },
      "source": [
        "Gradients\n",
        "---------\n",
        "Let's backprop now.\n",
        "Because ``out`` contains a single scalar, ``out.backward()`` is\n",
        "equivalent to ``out.backward(torch.tensor(1.))``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "XijLdWRAqrbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "rymS5qMIqrbi",
        "colab_type": "text"
      },
      "source": [
        "Print gradients d(out)/dx\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "GzEzwCU0qrbj",
        "colab_type": "code",
        "outputId": "1b76b19c-a3a2-4f24-948f-a8fb8eceb9c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3., 3., 3.],\n",
            "        [3., 3., 3.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Vmqt1PDRqrbm",
        "colab_type": "text"
      },
      "source": [
        "Now let's take a look at an example of vector-Jacobian product:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "UH_QskgRqrbn",
        "colab_type": "code",
        "outputId": "7b30a32a-651d-49e3-9b90-3e53476b1917",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "x_1 = torch.ones(2,2, requires_grad=True)\n",
        "x_2 = (x_1 ** 2 * 3).sum()\n",
        "x_2.backward(torch.tensor(17.))\n",
        "print(x_1.grad)\n",
        "x_3 = (x_1 * 20).sum()\n",
        "x_3.backward(torch.tensor(2.))\n",
        "print(x_1.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[102., 102.],\n",
            "        [102., 102.]])\n",
            "tensor([[142., 142.],\n",
            "        [142., 142.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "X4yuuGjlqrbq",
        "colab_type": "text"
      },
      "source": [
        "You can also stop autograd from tracking history on Tensors\n",
        "with ``.requires_grad=True`` either by wrapping the code block in\n",
        "``with torch.no_grad():``\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "eSqz5ZbZqrbr",
        "colab_type": "code",
        "outputId": "5ea0f536-9ebd-42a8-a177-09c9ce48a212",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(x.requires_grad)\n",
        "print((x ** 2).requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "\tprint((x ** 2).requires_grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "7PAdBqBbqrbv",
        "colab_type": "text"
      },
      "source": [
        "Or by using ``.detach()`` to get a new Tensor with the same\n",
        "content but that does not require gradients:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "bO4whMS6qrbw",
        "colab_type": "code",
        "outputId": "38c33200-35c6-4313-c2dc-0723c108c58f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(x.requires_grad)\n",
        "y = x.detach()\n",
        "print(y.requires_grad)\n",
        "print(x.eq(y).all())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "False\n",
            "tensor(True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "4Cfb2BWlqrby",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Neural Networks\n",
        "\n",
        "\n",
        "Neural networks can be constructed using the ``torch.nn`` package.\n",
        "\n",
        "Now that you had a glimpse of ``autograd``, ``nn`` depends on\n",
        "``autograd`` to define models and differentiate them.\n",
        "An ``nn.Module`` contains layers, and a method ``forward(input)``\\ that\n",
        "returns the ``output``.\n",
        "\n",
        "For example, look at this network that classifies digit images:\n",
        "\n",
        "\n",
        "It is a simple feed-forward network. It takes the input, feeds it\n",
        "through several layers one after the other, and then finally gives the\n",
        "output.\n",
        "\n",
        "A typical training procedure for a neural network is as follows:\n",
        "\n",
        "- Define the neural network that has some learnable parameters (or\n",
        "  weights)\n",
        "- Iterate over a dataset of inputs\n",
        "- Process input through the network\n",
        "- Compute the loss (how far is the output from being correct)\n",
        "- Propagate gradients back into the network’s parameters\n",
        "- Update the weights of the network, typically using a simple update rule:\n",
        "  ``weight = weight - learning_rate * gradient``\n",
        "\n",
        "Define the network\n",
        "------------------\n",
        "\n",
        "Let’s define this network:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "UASizWDdqrbz",
        "colab_type": "code",
        "outputId": "c4e84010-cf84-4abe-9966-86b27f682cbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "import torch\n",
        "# torch modules\n",
        "import torch.nn as nn\n",
        "# torch functions\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # an affine operations: y = Wx + b\n",
        "        self.fc1 = nn.Linear(32 * 32, 200)\n",
        "        self.fc2 = nn.Linear(200, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # x.shape => BATCH_SIZE x Height X Width \n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x \n",
        "    \n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=1024, out_features=200, bias=True)\n",
            "  (fc2): Linear(in_features=200, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnZp_DzRqrb3",
        "colab_type": "code",
        "outputId": "8d77911f-4c87-49be-880f-2f3cb6882b3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "class Net_with_sequential(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net_with_sequential, self).__init__()\n",
        "        # an affine operations: y = Wx + b\n",
        "        self.dense_layers = nn.Sequential(\n",
        "            nn.Linear(32 * 32, 200),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(200, 10),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.dense_layers(x)\n",
        "        return x \n",
        "    \n",
        "\n",
        "net_ws = Net_with_sequential()\n",
        "on_GPU=net_ws.to(device)\n",
        "print(net_ws)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net_with_sequential(\n",
            "  (dense_layers): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=200, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMrxqPNjqrb5",
        "colab_type": "text"
      },
      "source": [
        "You just have to define the ``forward`` function, and the ``backward``\n",
        "function (where gradients are computed) is automatically defined for you\n",
        "using ``autograd``.\n",
        "You can use any of the Tensor operations in the ``forward`` function.\n",
        "\n",
        "The learnable parameters of a model are returned by ``net.parameters()``\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "Z5yK0hgpqrb6",
        "colab_type": "code",
        "outputId": "88b0546b-a8a8-44c9-c5d4-baf66ef95694",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "params = list(net.parameters())\n",
        "print(len(params))\n",
        "print(params[0].size())  # fc1 .weight"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "torch.Size([200, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdAx1znYqrb9",
        "colab_type": "text"
      },
      "source": [
        "Let's try a random 32x32 input.\n",
        "Note: expected input size of this net (LeNet) is 32x32. To use this net on\n",
        "the MNIST dataset, please resize the images from the dataset to 32x32.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "MxxKL9n5qrb-",
        "colab_type": "code",
        "outputId": "33655ecd-65b5-4a16-abb4-f55380950b3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "input = torch.randn(1, 1, 32, 32)\n",
        "out = net(input) #alias for net.(input)\n",
        "print(out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.2224,  0.0062,  0.5402,  0.1943,  0.0606, -0.2214,  0.3895, -0.4705,\n",
            "         -0.0406, -0.0587]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czgW8X7kqrcB",
        "colab_type": "text"
      },
      "source": [
        "Zero the gradient buffers of all parameters and backprops with random\n",
        "gradients:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "B8LRqMWhqrcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.zero_grad()\n",
        "out.backward(torch.randn(1, 10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilIlhSZiqrcE",
        "colab_type": "text"
      },
      "source": [
        "``torch.nn`` only supports mini-batches. The entire ``torch.nn``\n",
        "    package only supports inputs that are a mini-batch of samples, and not\n",
        "    a single sample.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Loss Function\n",
        "-------------\n",
        "A loss function takes the (output, target) pair of inputs, and computes a\n",
        "value that estimates how far away the output is from the target.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "w2SqegJMqrcF",
        "colab_type": "code",
        "outputId": "f19d0c50-ccfa-4775-f490-87be8d2c0c81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "output = net(input)\n",
        "target = torch.randn(10)  # a dummy target, for example\n",
        "target = target.view(1, -1)  # make it the same shape as output\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "loss = criterion(output, target)\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.7363, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOuPZ4YLqrcH",
        "colab_type": "text"
      },
      "source": [
        "Now, if you follow ``loss`` in the backward direction, using its\n",
        "``.grad_fn`` attribute, you will see a graph of computations that looks\n",
        "like this:\n",
        "\n",
        "\n",
        "\n",
        "    input -> view -> linear -> relu -> linear -> relu -> linear\n",
        "          -> MSELoss\n",
        "          -> loss\n",
        "\n",
        "So, when we call ``loss.backward()``, the whole graph is differentiated\n",
        "w.r.t. the loss, and all Tensors in the graph that has ``requires_grad=True``\n",
        "will have their ``.grad`` Tensor accumulated with the gradient.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "7rslBU14qrcI",
        "colab_type": "text"
      },
      "source": [
        "Backprop\n",
        "--------\n",
        "To backpropagate the error all we have to do is to ``loss.backward()``.\n",
        "You need to clear the existing gradients though, else gradients will be\n",
        "accumulated to existing gradients.\n",
        "\n",
        "\n",
        "Now we shall call ``loss.backward()``, and have a look at linear bias\n",
        "gradients before and after the backward.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "scrolled": true,
        "id": "2_WvEEpAqrcJ",
        "colab_type": "code",
        "outputId": "ca35efb7-ef6a-4db3-a5fb-835fac4306dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "source": [
        "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
        "\n",
        "print('fc1.bias.grad before backward')\n",
        "print(net.fc1.bias.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('fc1.bias.grad after backward')\n",
        "print(net.fc1.bias.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fc1.bias.grad before backward\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "fc1.bias.grad after backward\n",
            "tensor([ 0.0000, -0.0047, -0.0128,  0.0181,  0.0000, -0.0360,  0.0371, -0.0405,\n",
            "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0251,  0.0303,\n",
            "        -0.0134,  0.0108, -0.0085,  0.0122,  0.0000,  0.0000,  0.0281,  0.0000,\n",
            "         0.0119,  0.0000, -0.0112,  0.0000,  0.0000,  0.0187,  0.0253,  0.0000,\n",
            "         0.0000,  0.0000, -0.0346, -0.0204,  0.0000,  0.0000,  0.0000, -0.0165,\n",
            "         0.0000,  0.0000, -0.0251,  0.0075, -0.0004,  0.0000,  0.0022,  0.0000,\n",
            "         0.0000,  0.0000,  0.0043, -0.0387, -0.0101,  0.0000,  0.0000, -0.0253,\n",
            "         0.0000,  0.0000, -0.0232,  0.0000,  0.0222, -0.0050,  0.0000, -0.0256,\n",
            "         0.0000,  0.0274, -0.0128, -0.0075,  0.0195,  0.0000,  0.0000, -0.0119,\n",
            "        -0.0222,  0.0274,  0.0138, -0.0183,  0.0000, -0.0095, -0.0221, -0.0102,\n",
            "         0.0000,  0.0000,  0.0000, -0.0056,  0.0269,  0.0000,  0.0455,  0.0000,\n",
            "        -0.0186,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0083, -0.0138,\n",
            "         0.0080, -0.0019,  0.0000,  0.0000,  0.0000,  0.0220,  0.0051, -0.0202,\n",
            "         0.0085,  0.0000,  0.0193,  0.0000,  0.0000, -0.0105,  0.0252,  0.0091,\n",
            "        -0.0137,  0.0189,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0087,\n",
            "         0.0000,  0.0000,  0.0294,  0.0388,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         0.0000,  0.0000,  0.0000, -0.0351,  0.0000,  0.0225,  0.0035,  0.0120,\n",
            "        -0.0171, -0.0310,  0.0260,  0.0000,  0.0350,  0.0000,  0.0264,  0.0000,\n",
            "        -0.0136,  0.0000,  0.0067,  0.0000,  0.0000,  0.0000,  0.0184,  0.0000,\n",
            "         0.0035, -0.0199, -0.0269,  0.0000,  0.0175,  0.0000,  0.0000,  0.0468,\n",
            "         0.0242,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "        -0.0129,  0.0000,  0.0067,  0.0000,  0.0000,  0.0183,  0.0057, -0.0171,\n",
            "         0.0000,  0.0000,  0.0377,  0.0143, -0.0076,  0.0000,  0.0000,  0.0000,\n",
            "         0.0055,  0.0000,  0.0000,  0.0039,  0.0000, -0.0239, -0.0224,  0.0000,\n",
            "         0.0138,  0.0000, -0.0399,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "VdPVOXZjqrcL",
        "colab_type": "text"
      },
      "source": [
        "Update the weights\n",
        "------------------\n",
        "The simplest update rule used in practice is the Stochastic Gradient\n",
        "Descent (SGD):\n",
        "\n",
        " ``weight = weight - learning_rate * gradient``\n",
        "\n",
        "We can implement this using simple Python code:\n",
        "\n",
        "```\n",
        "learning_rate = 0.01\n",
        "with torch.nograd():\n",
        "    for f in net.parameters():\n",
        "        f.sub_(f.grad.data * learning_rate)\n",
        "```\n",
        "However, as you use neural networks, you want to use various different\n",
        "update rules such as SGD, Nesterov-SGD, Adam, RMSProp, etc.\n",
        "To enable this, we built a small package: ``torch.optim`` that\n",
        "implements all these methods. Using it is very simple:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "a7MXwyOzqrcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# create your optimizer\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "# in your training loop:\n",
        "optimizer.zero_grad()   # zero the gradient buffers\n",
        "output = net(input)\n",
        "loss = criterion(output, target)\n",
        "loss.backward()\n",
        "optimizer.step()    # Does the update"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "3FZhjfFPqrcQ",
        "colab_type": "text"
      },
      "source": [
        "# Preparing a dataset\n",
        "\n",
        "A lot of effort in solving any machine learning problem goes in to preparing the data. PyTorch provides many tools to make data loading easy and hopefully, to make your code more readable.\n",
        "\n",
        "Dataset class\n",
        "-------------\n",
        "\n",
        "``torch.utils.data.Dataset`` is an abstract class representing a\n",
        "dataset.\n",
        "Your custom dataset should inherit ``Dataset`` and override the following\n",
        "methods:\n",
        "\n",
        "-  ``__len__`` so that ``len(dataset)`` returns the size of the dataset.\n",
        "-  ``__getitem__`` to support the indexing such that ``dataset[i]`` can\n",
        "   be used to get $i$'th sample\n",
        "\n",
        "\n",
        "Sample of our dataset will be a dict\n",
        "``{'image': image, 'label': label}``.\n",
        "\n",
        "### my_SimpleDataset\n",
        "\n",
        "Dataset containes images build form zeroes and ones.\n",
        "Our machine_learning task is to figure out if we have **more ones than zeros** in the picture. (This task is trivial)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9uzXs4vqrcR",
        "colab_type": "code",
        "outputId": "6c3d21c5-f9ca-40f2-f724-8bd9eb80bf76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "PICTURE_SIZE = 10\n",
        "\n",
        "class SimpleDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, size):\n",
        "        self.data = torch.zeros(size, PICTURE_SIZE, PICTURE_SIZE)\n",
        "        self.data[torch.rand_like(self.data) > 0.5] = 1.\n",
        "        \n",
        "        self.labels = torch.zeros(size)\n",
        "        self.labels[self.data.mean(dim=[1,2]) > 0.5] = 1.\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        # Accepts scalars, tuples and dictionaries\n",
        "        return {\n",
        "                'image': self.data[item],\n",
        "                'label': self.labels[item]\n",
        "        }\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "dataset = SimpleDataset(2**13)\n",
        "# __len__\n",
        "print('dataset_len:', len(dataset))\n",
        "\n",
        "# __getitem__\n",
        "print(dataset[15])\n",
        "\n",
        "for x in dataset:\n",
        "    pass\n",
        "print('looping sucesfull')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset_len: 8192\n",
            "{'image': tensor([[1., 1., 0., 1., 1., 0., 1., 0., 1., 0.],\n",
            "        [1., 0., 1., 0., 0., 1., 1., 1., 0., 0.],\n",
            "        [0., 0., 1., 1., 0., 0., 1., 1., 1., 1.],\n",
            "        [1., 1., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 1., 0., 1., 0., 1.],\n",
            "        [1., 0., 0., 1., 0., 0., 1., 0., 1., 0.],\n",
            "        [1., 1., 0., 0., 0., 1., 1., 0., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 0., 1., 0., 1.],\n",
            "        [1., 1., 0., 1., 0., 0., 1., 0., 1., 0.],\n",
            "        [0., 1., 0., 1., 0., 0., 1., 0., 0., 0.]]), 'label': tensor(0.)}\n",
            "looping sucesfull\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "nE47QhzWqrcU",
        "colab_type": "text"
      },
      "source": [
        "However, we are losing a lot of features by using a simple ``for`` loop to\n",
        "iterate over the data. In particular, we are missing out on:\n",
        "\n",
        "-  Batching the data\n",
        "-  Shuffling the data\n",
        "-  Load the data in parallel using ``multiprocessing`` workers.\n",
        "\n",
        "``torch.utils.data.DataLoader`` is an iterator which provides all these\n",
        "features. Parameters used below should be clear."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qXiEex_tqrcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=2\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "k5svrzN4qrcX",
        "colab_type": "text"
      },
      "source": [
        "### NeuralNet definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%% \n"
        },
        "id": "06-iawIoqrcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HIDDEN_SIZE = 800\n",
        "\n",
        "class CustomDenseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomDenseNetwork, self).__init__()\n",
        "        self.hidden = nn.Sequential(\n",
        "                nn.Linear(PICTURE_SIZE * PICTURE_SIZE, HIDDEN_SIZE),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(HIDDEN_SIZE, 1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, PICTURE_SIZE * PICTURE_SIZE)\n",
        "        x = self.hidden(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZAfN75_sqrcb",
        "colab_type": "code",
        "outputId": "1812d79e-88c4-4713-ee2b-2fe088e73bc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "# Move model weigths to device\n",
        "device = ('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "net = CustomDenseNetwork().to(device)\n",
        "\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.005)\n",
        "\n",
        "for e in range(EPOCHS):\n",
        "    loss_avg = 0.\n",
        "    acc_avg = 0.\n",
        "    for i, batch_data in enumerate(dataloader):\n",
        "        # Start with zeroing .grad fields in model\n",
        "        net.zero_grad()\n",
        "        \n",
        "        # Move data to device\n",
        "        images = batch_data['image'].to(device)\n",
        "        labels = batch_data['label'].to(device)\n",
        "        \n",
        "        #Run neural net\n",
        "        out = net(images)\n",
        "\n",
        "        #Compute loss and apply autograd for model parameters\n",
        "        loss = ((out.view(-1) - labels)** 2).mean()\n",
        "        loss.backward()\n",
        "        \n",
        "        #Update network weigths\n",
        "        optimizer.step()\n",
        "\n",
        "        # Statistics generation\n",
        "        res = torch.where(\n",
        "                out.view(-1) > 0.5,\n",
        "                torch.tensor(1., device=device),\n",
        "                torch.tensor(0., device=device)\n",
        "        )\n",
        "        acc = (res == labels).sum()\n",
        "        loss_avg += loss\n",
        "        acc_avg += acc\n",
        "        if i % 30 == 0 and i != 0:\n",
        "            print(f'epoch:{e + 1:2d} step: {(i):3d} loss: {loss_avg / 30:.3f} acc: {acc_avg / (BATCH_SIZE * 30):.3f}')\n",
        "            acc_avg = 0.\n",
        "            loss_avg = 0.\n",
        "        # End of statistics generation"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 step:  30 loss: 0.243 acc: 0.631\n",
            "epoch: 1 step:  60 loss: 0.227 acc: 0.631\n",
            "epoch: 1 step:  90 loss: 0.229 acc: 0.620\n",
            "epoch: 1 step: 120 loss: 0.218 acc: 0.667\n",
            "epoch: 1 step: 150 loss: 0.212 acc: 0.701\n",
            "epoch: 1 step: 180 loss: 0.206 acc: 0.711\n",
            "epoch: 1 step: 210 loss: 0.203 acc: 0.720\n",
            "epoch: 1 step: 240 loss: 0.202 acc: 0.730\n",
            "epoch: 2 step:  30 loss: 0.199 acc: 0.786\n",
            "epoch: 2 step:  60 loss: 0.186 acc: 0.807\n",
            "epoch: 2 step:  90 loss: 0.184 acc: 0.784\n",
            "epoch: 2 step: 120 loss: 0.182 acc: 0.809\n",
            "epoch: 2 step: 150 loss: 0.180 acc: 0.809\n",
            "epoch: 2 step: 180 loss: 0.178 acc: 0.802\n",
            "epoch: 2 step: 210 loss: 0.176 acc: 0.804\n",
            "epoch: 2 step: 240 loss: 0.176 acc: 0.796\n",
            "epoch: 3 step:  30 loss: 0.169 acc: 0.883\n",
            "epoch: 3 step:  60 loss: 0.162 acc: 0.831\n",
            "epoch: 3 step:  90 loss: 0.163 acc: 0.831\n",
            "epoch: 3 step: 120 loss: 0.158 acc: 0.852\n",
            "epoch: 3 step: 150 loss: 0.162 acc: 0.828\n",
            "epoch: 3 step: 180 loss: 0.162 acc: 0.843\n",
            "epoch: 3 step: 210 loss: 0.154 acc: 0.864\n",
            "epoch: 3 step: 240 loss: 0.151 acc: 0.849\n",
            "epoch: 4 step:  30 loss: 0.158 acc: 0.885\n",
            "epoch: 4 step:  60 loss: 0.144 acc: 0.861\n",
            "epoch: 4 step:  90 loss: 0.149 acc: 0.864\n",
            "epoch: 4 step: 120 loss: 0.144 acc: 0.859\n",
            "epoch: 4 step: 150 loss: 0.142 acc: 0.876\n",
            "epoch: 4 step: 180 loss: 0.135 acc: 0.884\n",
            "epoch: 4 step: 210 loss: 0.135 acc: 0.891\n",
            "epoch: 4 step: 240 loss: 0.140 acc: 0.853\n",
            "epoch: 5 step:  30 loss: 0.141 acc: 0.917\n",
            "epoch: 5 step:  60 loss: 0.130 acc: 0.886\n",
            "epoch: 5 step:  90 loss: 0.133 acc: 0.890\n",
            "epoch: 5 step: 120 loss: 0.130 acc: 0.894\n",
            "epoch: 5 step: 150 loss: 0.128 acc: 0.892\n",
            "epoch: 5 step: 180 loss: 0.129 acc: 0.889\n",
            "epoch: 5 step: 210 loss: 0.130 acc: 0.892\n",
            "epoch: 5 step: 240 loss: 0.125 acc: 0.889\n",
            "epoch: 6 step:  30 loss: 0.128 acc: 0.934\n",
            "epoch: 6 step:  60 loss: 0.120 acc: 0.901\n",
            "epoch: 6 step:  90 loss: 0.121 acc: 0.902\n",
            "epoch: 6 step: 120 loss: 0.121 acc: 0.907\n",
            "epoch: 6 step: 150 loss: 0.126 acc: 0.872\n",
            "epoch: 6 step: 180 loss: 0.117 acc: 0.901\n",
            "epoch: 6 step: 210 loss: 0.121 acc: 0.907\n",
            "epoch: 6 step: 240 loss: 0.114 acc: 0.917\n",
            "epoch: 7 step:  30 loss: 0.120 acc: 0.931\n",
            "epoch: 7 step:  60 loss: 0.114 acc: 0.909\n",
            "epoch: 7 step:  90 loss: 0.110 acc: 0.907\n",
            "epoch: 7 step: 120 loss: 0.110 acc: 0.910\n",
            "epoch: 7 step: 150 loss: 0.115 acc: 0.913\n",
            "epoch: 7 step: 180 loss: 0.111 acc: 0.913\n",
            "epoch: 7 step: 210 loss: 0.114 acc: 0.908\n",
            "epoch: 7 step: 240 loss: 0.115 acc: 0.899\n",
            "epoch: 8 step:  30 loss: 0.111 acc: 0.947\n",
            "epoch: 8 step:  60 loss: 0.109 acc: 0.918\n",
            "epoch: 8 step:  90 loss: 0.113 acc: 0.907\n",
            "epoch: 8 step: 120 loss: 0.102 acc: 0.926\n",
            "epoch: 8 step: 150 loss: 0.108 acc: 0.911\n",
            "epoch: 8 step: 180 loss: 0.109 acc: 0.903\n",
            "epoch: 8 step: 210 loss: 0.102 acc: 0.936\n",
            "epoch: 8 step: 240 loss: 0.109 acc: 0.913\n",
            "epoch: 9 step:  30 loss: 0.109 acc: 0.961\n",
            "epoch: 9 step:  60 loss: 0.105 acc: 0.919\n",
            "epoch: 9 step:  90 loss: 0.104 acc: 0.927\n",
            "epoch: 9 step: 120 loss: 0.105 acc: 0.922\n",
            "epoch: 9 step: 150 loss: 0.102 acc: 0.926\n",
            "epoch: 9 step: 180 loss: 0.098 acc: 0.926\n",
            "epoch: 9 step: 210 loss: 0.105 acc: 0.911\n",
            "epoch: 9 step: 240 loss: 0.096 acc: 0.925\n",
            "epoch:10 step:  30 loss: 0.104 acc: 0.946\n",
            "epoch:10 step:  60 loss: 0.097 acc: 0.925\n",
            "epoch:10 step:  90 loss: 0.108 acc: 0.908\n",
            "epoch:10 step: 120 loss: 0.102 acc: 0.924\n",
            "epoch:10 step: 150 loss: 0.095 acc: 0.938\n",
            "epoch:10 step: 180 loss: 0.102 acc: 0.914\n",
            "epoch:10 step: 210 loss: 0.098 acc: 0.929\n",
            "epoch:10 step: 240 loss: 0.102 acc: 0.936\n",
            "epoch:11 step:  30 loss: 0.098 acc: 0.969\n",
            "epoch:11 step:  60 loss: 0.101 acc: 0.922\n",
            "epoch:11 step:  90 loss: 0.096 acc: 0.926\n",
            "epoch:11 step: 120 loss: 0.098 acc: 0.924\n",
            "epoch:11 step: 150 loss: 0.101 acc: 0.926\n",
            "epoch:11 step: 180 loss: 0.099 acc: 0.918\n",
            "epoch:11 step: 210 loss: 0.097 acc: 0.929\n",
            "epoch:11 step: 240 loss: 0.095 acc: 0.939\n",
            "epoch:12 step:  30 loss: 0.098 acc: 0.976\n",
            "epoch:12 step:  60 loss: 0.097 acc: 0.914\n",
            "epoch:12 step:  90 loss: 0.089 acc: 0.941\n",
            "epoch:12 step: 120 loss: 0.094 acc: 0.919\n",
            "epoch:12 step: 150 loss: 0.099 acc: 0.914\n",
            "epoch:12 step: 180 loss: 0.098 acc: 0.926\n",
            "epoch:12 step: 210 loss: 0.102 acc: 0.921\n",
            "epoch:12 step: 240 loss: 0.098 acc: 0.927\n",
            "epoch:13 step:  30 loss: 0.093 acc: 0.966\n",
            "epoch:13 step:  60 loss: 0.095 acc: 0.939\n",
            "epoch:13 step:  90 loss: 0.094 acc: 0.933\n",
            "epoch:13 step: 120 loss: 0.094 acc: 0.926\n",
            "epoch:13 step: 150 loss: 0.097 acc: 0.930\n",
            "epoch:13 step: 180 loss: 0.097 acc: 0.916\n",
            "epoch:13 step: 210 loss: 0.096 acc: 0.939\n",
            "epoch:13 step: 240 loss: 0.093 acc: 0.931\n",
            "epoch:14 step:  30 loss: 0.093 acc: 0.977\n",
            "epoch:14 step:  60 loss: 0.094 acc: 0.933\n",
            "epoch:14 step:  90 loss: 0.100 acc: 0.932\n",
            "epoch:14 step: 120 loss: 0.093 acc: 0.930\n",
            "epoch:14 step: 150 loss: 0.094 acc: 0.932\n",
            "epoch:14 step: 180 loss: 0.095 acc: 0.936\n",
            "epoch:14 step: 210 loss: 0.095 acc: 0.934\n",
            "epoch:14 step: 240 loss: 0.095 acc: 0.931\n",
            "epoch:15 step:  30 loss: 0.097 acc: 0.974\n",
            "epoch:15 step:  60 loss: 0.096 acc: 0.936\n",
            "epoch:15 step:  90 loss: 0.097 acc: 0.929\n",
            "epoch:15 step: 120 loss: 0.089 acc: 0.941\n",
            "epoch:15 step: 150 loss: 0.098 acc: 0.930\n",
            "epoch:15 step: 180 loss: 0.092 acc: 0.944\n",
            "epoch:15 step: 210 loss: 0.092 acc: 0.936\n",
            "epoch:15 step: 240 loss: 0.087 acc: 0.941\n",
            "epoch:16 step:  30 loss: 0.095 acc: 0.971\n",
            "epoch:16 step:  60 loss: 0.092 acc: 0.931\n",
            "epoch:16 step:  90 loss: 0.093 acc: 0.941\n",
            "epoch:16 step: 120 loss: 0.095 acc: 0.934\n",
            "epoch:16 step: 150 loss: 0.093 acc: 0.931\n",
            "epoch:16 step: 180 loss: 0.091 acc: 0.946\n",
            "epoch:16 step: 210 loss: 0.092 acc: 0.931\n",
            "epoch:16 step: 240 loss: 0.090 acc: 0.942\n",
            "epoch:17 step:  30 loss: 0.096 acc: 0.965\n",
            "epoch:17 step:  60 loss: 0.081 acc: 0.942\n",
            "epoch:17 step:  90 loss: 0.097 acc: 0.940\n",
            "epoch:17 step: 120 loss: 0.093 acc: 0.940\n",
            "epoch:17 step: 150 loss: 0.095 acc: 0.923\n",
            "epoch:17 step: 180 loss: 0.092 acc: 0.946\n",
            "epoch:17 step: 210 loss: 0.091 acc: 0.934\n",
            "epoch:17 step: 240 loss: 0.092 acc: 0.936\n",
            "epoch:18 step:  30 loss: 0.094 acc: 0.973\n",
            "epoch:18 step:  60 loss: 0.092 acc: 0.951\n",
            "epoch:18 step:  90 loss: 0.094 acc: 0.942\n",
            "epoch:18 step: 120 loss: 0.086 acc: 0.947\n",
            "epoch:18 step: 150 loss: 0.090 acc: 0.939\n",
            "epoch:18 step: 180 loss: 0.094 acc: 0.935\n",
            "epoch:18 step: 210 loss: 0.093 acc: 0.931\n",
            "epoch:18 step: 240 loss: 0.089 acc: 0.946\n",
            "epoch:19 step:  30 loss: 0.095 acc: 0.973\n",
            "epoch:19 step:  60 loss: 0.093 acc: 0.942\n",
            "epoch:19 step:  90 loss: 0.086 acc: 0.953\n",
            "epoch:19 step: 120 loss: 0.090 acc: 0.945\n",
            "epoch:19 step: 150 loss: 0.092 acc: 0.941\n",
            "epoch:19 step: 180 loss: 0.089 acc: 0.944\n",
            "epoch:19 step: 210 loss: 0.091 acc: 0.938\n",
            "epoch:19 step: 240 loss: 0.088 acc: 0.941\n",
            "epoch:20 step:  30 loss: 0.090 acc: 0.981\n",
            "epoch:20 step:  60 loss: 0.088 acc: 0.944\n",
            "epoch:20 step:  90 loss: 0.086 acc: 0.950\n",
            "epoch:20 step: 120 loss: 0.087 acc: 0.947\n",
            "epoch:20 step: 150 loss: 0.089 acc: 0.954\n",
            "epoch:20 step: 180 loss: 0.093 acc: 0.922\n",
            "epoch:20 step: 210 loss: 0.094 acc: 0.933\n",
            "epoch:20 step: 240 loss: 0.087 acc: 0.951\n",
            "epoch:21 step:  30 loss: 0.098 acc: 0.966\n",
            "epoch:21 step:  60 loss: 0.083 acc: 0.955\n",
            "epoch:21 step:  90 loss: 0.089 acc: 0.939\n",
            "epoch:21 step: 120 loss: 0.088 acc: 0.942\n",
            "epoch:21 step: 150 loss: 0.087 acc: 0.940\n",
            "epoch:21 step: 180 loss: 0.089 acc: 0.946\n",
            "epoch:21 step: 210 loss: 0.089 acc: 0.942\n",
            "epoch:21 step: 240 loss: 0.090 acc: 0.946\n",
            "epoch:22 step:  30 loss: 0.092 acc: 0.978\n",
            "epoch:22 step:  60 loss: 0.091 acc: 0.949\n",
            "epoch:22 step:  90 loss: 0.087 acc: 0.941\n",
            "epoch:22 step: 120 loss: 0.091 acc: 0.933\n",
            "epoch:22 step: 150 loss: 0.085 acc: 0.955\n",
            "epoch:22 step: 180 loss: 0.089 acc: 0.948\n",
            "epoch:22 step: 210 loss: 0.089 acc: 0.947\n",
            "epoch:22 step: 240 loss: 0.088 acc: 0.944\n",
            "epoch:23 step:  30 loss: 0.087 acc: 0.985\n",
            "epoch:23 step:  60 loss: 0.088 acc: 0.952\n",
            "epoch:23 step:  90 loss: 0.090 acc: 0.946\n",
            "epoch:23 step: 120 loss: 0.088 acc: 0.941\n",
            "epoch:23 step: 150 loss: 0.084 acc: 0.947\n",
            "epoch:23 step: 180 loss: 0.089 acc: 0.946\n",
            "epoch:23 step: 210 loss: 0.088 acc: 0.955\n",
            "epoch:23 step: 240 loss: 0.085 acc: 0.947\n",
            "epoch:24 step:  30 loss: 0.091 acc: 0.986\n",
            "epoch:24 step:  60 loss: 0.088 acc: 0.941\n",
            "epoch:24 step:  90 loss: 0.087 acc: 0.951\n",
            "epoch:24 step: 120 loss: 0.087 acc: 0.945\n",
            "epoch:24 step: 150 loss: 0.087 acc: 0.951\n",
            "epoch:24 step: 180 loss: 0.087 acc: 0.949\n",
            "epoch:24 step: 210 loss: 0.087 acc: 0.950\n",
            "epoch:24 step: 240 loss: 0.086 acc: 0.941\n",
            "epoch:25 step:  30 loss: 0.091 acc: 0.979\n",
            "epoch:25 step:  60 loss: 0.086 acc: 0.953\n",
            "epoch:25 step:  90 loss: 0.089 acc: 0.940\n",
            "epoch:25 step: 120 loss: 0.082 acc: 0.955\n",
            "epoch:25 step: 150 loss: 0.088 acc: 0.940\n",
            "epoch:25 step: 180 loss: 0.086 acc: 0.955\n",
            "epoch:25 step: 210 loss: 0.086 acc: 0.961\n",
            "epoch:25 step: 240 loss: 0.087 acc: 0.951\n",
            "epoch:26 step:  30 loss: 0.087 acc: 0.983\n",
            "epoch:26 step:  60 loss: 0.092 acc: 0.946\n",
            "epoch:26 step:  90 loss: 0.082 acc: 0.964\n",
            "epoch:26 step: 120 loss: 0.082 acc: 0.954\n",
            "epoch:26 step: 150 loss: 0.084 acc: 0.956\n",
            "epoch:26 step: 180 loss: 0.086 acc: 0.946\n",
            "epoch:26 step: 210 loss: 0.085 acc: 0.959\n",
            "epoch:26 step: 240 loss: 0.088 acc: 0.945\n",
            "epoch:27 step:  30 loss: 0.089 acc: 0.983\n",
            "epoch:27 step:  60 loss: 0.082 acc: 0.956\n",
            "epoch:27 step:  90 loss: 0.088 acc: 0.949\n",
            "epoch:27 step: 120 loss: 0.088 acc: 0.955\n",
            "epoch:27 step: 150 loss: 0.086 acc: 0.947\n",
            "epoch:27 step: 180 loss: 0.086 acc: 0.956\n",
            "epoch:27 step: 210 loss: 0.088 acc: 0.944\n",
            "epoch:27 step: 240 loss: 0.087 acc: 0.956\n",
            "epoch:28 step:  30 loss: 0.094 acc: 0.979\n",
            "epoch:28 step:  60 loss: 0.084 acc: 0.942\n",
            "epoch:28 step:  90 loss: 0.084 acc: 0.949\n",
            "epoch:28 step: 120 loss: 0.083 acc: 0.953\n",
            "epoch:28 step: 150 loss: 0.085 acc: 0.949\n",
            "epoch:28 step: 180 loss: 0.085 acc: 0.956\n",
            "epoch:28 step: 210 loss: 0.087 acc: 0.952\n",
            "epoch:28 step: 240 loss: 0.087 acc: 0.955\n",
            "epoch:29 step:  30 loss: 0.088 acc: 0.994\n",
            "epoch:29 step:  60 loss: 0.086 acc: 0.946\n",
            "epoch:29 step:  90 loss: 0.080 acc: 0.970\n",
            "epoch:29 step: 120 loss: 0.086 acc: 0.950\n",
            "epoch:29 step: 150 loss: 0.083 acc: 0.953\n",
            "epoch:29 step: 180 loss: 0.084 acc: 0.954\n",
            "epoch:29 step: 210 loss: 0.086 acc: 0.950\n",
            "epoch:29 step: 240 loss: 0.080 acc: 0.956\n",
            "epoch:30 step:  30 loss: 0.087 acc: 0.982\n",
            "epoch:30 step:  60 loss: 0.084 acc: 0.951\n",
            "epoch:30 step:  90 loss: 0.080 acc: 0.959\n",
            "epoch:30 step: 120 loss: 0.083 acc: 0.956\n",
            "epoch:30 step: 150 loss: 0.086 acc: 0.953\n",
            "epoch:30 step: 180 loss: 0.086 acc: 0.958\n",
            "epoch:30 step: 210 loss: 0.085 acc: 0.951\n",
            "epoch:30 step: 240 loss: 0.084 acc: 0.957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "YpEKraCvqrcd",
        "colab_type": "text"
      },
      "source": [
        "## ProTip: mnist InMemDataLoder\n",
        "\n",
        "**Fast DataLoader** for **small datasets** (MNIST for example). On Colab, this code snippet sagnificantlly improves data loading time, which can have huge impact on duration of the traning. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "VpG1inIUqrcf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InMemDataLoader(object):\n",
        "    __initialized = False\n",
        "    def __init__(self, tensors, batch_size=1, shuffle=False, sampler=None,\n",
        "                 batch_sampler=None, drop_last=False):\n",
        "        \"\"\"A torch dataloader that fetches data from memory.\"\"\"\n",
        "        tensors = [torch.tensor(tensor) for tensor in tensors]\n",
        "        dataset = torch.utils.data.TensorDataset(*tensors)\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.drop_last = drop_last\n",
        "        \n",
        "        if batch_sampler is not None:\n",
        "            if batch_size > 1 or shuffle or sampler is not None or drop_last:\n",
        "                raise ValueError('batch_sampler option is mutually exclusive '\n",
        "                                 'with batch_size, shuffle, sampler, and '\n",
        "                                 'drop_last')\n",
        "            self.batch_size = None\n",
        "            self.drop_last = None\n",
        "\n",
        "        if sampler is not None and shuffle:\n",
        "            raise ValueError('sampler option is mutually exclusive with '\n",
        "                             'shuffle')\n",
        "            \n",
        "        if batch_sampler is None:\n",
        "            if sampler is None:\n",
        "                if shuffle:\n",
        "                    sampler = torch.utils.data.RandomSampler(dataset)\n",
        "                else:\n",
        "                    sampler = torch.utils.data.SequentialSampler(dataset)\n",
        "            batch_sampler = torch.utils.data.BatchSampler(sampler, batch_size, drop_last)\n",
        "\n",
        "        self.sampler = sampler\n",
        "        self.batch_sampler = batch_sampler\n",
        "        self.__initialized = True\n",
        "    \n",
        "    def __setattr__(self, attr, val):\n",
        "        if self.__initialized and attr in ('batch_size', 'sampler', 'drop_last'):\n",
        "            raise ValueError('{} attribute should not be set after {} is '\n",
        "                             'initialized'.format(attr, self.__class__.__name__))\n",
        "\n",
        "        super(InMemDataLoader, self).__setattr__(attr, val)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for batch_indices in self.batch_sampler:\n",
        "            yield self.dataset[batch_indices]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.batch_sampler)\n",
        "    \n",
        "    def to(self, device):\n",
        "        self.dataset.tensors = tuple(t.to(device) for t in self.dataset.tensors)\n",
        "        return self"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "o74maLaKqrci",
        "colab_type": "code",
        "outputId": "8e47b197-94d8-4d35-bd28-9b63ee9c32df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 907
        }
      },
      "source": [
        "##### HOW TO USE! ###\n",
        "# Download raw data\n",
        "# !command runs shell command in jupyter notebook\n",
        "!pip install -q gdown httpimport\n",
        "![ -e mnist.npz ] || gdown 'https://drive.google.com/uc?id=1QPaC3IKB_5tX6yIZgRgkpcqFrfVqPTXU' -O mnist.npz\n",
        "\n",
        "#Extracting data\n",
        "with np.load('mnist.npz') as data:\n",
        "    mnist_full_train_data = data['train_data'].astype('float32') / 255.0\n",
        "\n",
        "\n",
        "#Fast loader initialziation\n",
        "train_loader = InMemDataLoader(\n",
        "    (mnist_full_train_data, ), batch_size=25, shuffle=True)\n",
        "next(iter(train_loader))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QPaC3IKB_5tX6yIZgRgkpcqFrfVqPTXU\n",
            "To: /content/mnist.npz\n",
            "55.4MB [00:00, 152MB/s] \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]]]),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sRoNPkjqrcl",
        "colab_type": "text"
      },
      "source": [
        "Used materials:\n",
        "* Deep Learning with PyTorch: A 60 Minute Blitz https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\n",
        "* Writing Custom Datasets, DataLoaders and Transforms https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
      ]
    }
  ]
}