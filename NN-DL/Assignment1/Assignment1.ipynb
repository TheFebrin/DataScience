{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bb0zN1GvapSt"
   },
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zIBf-IF_ahTI"
   },
   "source": [
    "## Assignment text\n",
    "1. **[1p]** Download data competition from a Kaggle competition on sentiment prediction from [[https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data)].  Keep only full sentences, i.e. for each `SenteceId` keep only the entry with the lowest `PhraseId`.  Use first 7000 sentences as a `train set` and the remaining 1529 sentences as the `test set`. \n",
    "\n",
    "2. **[1p]** Prepare the data for logistic regression:\n",
    "\tMap the sentiment scores $0,1,2,3,4$ to a probability of the sentence being by setting $p(\\textrm{positive}) = \\textrm{sentiment}/4$.\n",
    "\tBuild a dictionary of at most 20000 most frequent words.\n",
    "\n",
    "3. **[3p]** Treat each document as a bag of words. e.g. if the vocabulary is \n",
    "\t```\n",
    "\t0: the\n",
    "\t1: good\n",
    "\t2: movie\n",
    "\t3: is\n",
    "\t4: not\n",
    "\t5: a\n",
    "\t6: funny\n",
    "\t```\n",
    "\tThen the encodings can be:\n",
    "\t```\n",
    "\tgood:                           [0,1,0,0,0,0,0]\n",
    "\tnot good:                       [0,1,0,0,1,0,0] \n",
    "\tthe movie is not a funny movie: [1,0,2,1,1,1,1]\n",
    "\t```\n",
    "    Train a logistic regression model to predict the sentiment. Compute the correlation between the predicted probabilities and the sentiment. Record the most positive and negative words.\n",
    "    Please note that in this model each word gets its sentiment parameter $S_w$ and the score for a sentence is \n",
    "    $$\\text{score}(\\text{sentence}) = \\sum_{w\\text{ in sentence}}S_w$$\n",
    "\n",
    "4. **[3p]** Now prepare an encoding in which negation flips the sign of the following words. For instance for our vocabulary the encodings become:\n",
    "\t```\n",
    "\tgood:                           [0,1,0,0,0,0,0]\n",
    "\tnot good:                       [0,-1,0,0,1,0,0]\n",
    "\tnot not good:                   [0,1,0,0,0,0,0]\n",
    "\tthe movie is not a funny movie: [1,0,0,1,1,-1,-1]\n",
    "\t```\n",
    "\tFor best results, you will probably need to construct a list of negative words.\n",
    "\t\n",
    "\tAgain train a logistic regression classifier and compare the results to the Bag of Words approach.\n",
    "\t\n",
    "\tPlease note that this model still maintains a single parameter for each word, but now the sentence score is\n",
    "\t$$\\text{score}(\\text{sentence}) = \\sum_{w\\text{ in sentence}}-1^{\\text{count of negations preceeding }w}S_w$$\n",
    "\n",
    "5. **[5p]** Now also consider emphasizing words such as `very`. They can boost (multiply by a constant >1) the following words.\n",
    "\tImplement learning the modifying multiplier for negation and for emphasis. One way to do this is to introduce a model which has:\n",
    "\t- two modifiers, $N$ for negation and $E$ for emphasis\n",
    "\t- a sentiment score $S_w$ for each word \n",
    "And score each sentence as:\n",
    "$$\\text{score}(\\text{sentence}) = \\sum_{w\\text{ in sentence}}N^{\\text{\\#negs prec. }w}E^{\\text{\\#emphs prec. }w}S_w$$\n",
    "\n",
    "You will need to implement a custom logistic regression model to support it.\n",
    "\n",
    "6. **[2pb]** Propose, implement, and evaluate an extension to the above model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict \n",
    "import re\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import scipy.optimize as sopt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mord import LogisticAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8529, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.tsv', sep='\\t')\n",
    "# test_df = pd.read_csv('test.tsv', sep='\\t')\n",
    "\n",
    "df = df.groupby(['SentenceId'], \n",
    "                          as_index=False).agg({'PhraseId' : 'min',\n",
    "                                               'Phrase' : 'first',\n",
    "                                               'Sentiment' : 'first'})\n",
    "\n",
    "df['Sentiment'] = df['Sentiment'].apply(lambda x: x / 4)\n",
    "df = df.drop(['PhraseId', 'SentenceId'], axis=1)\n",
    "df.Phrase = df.Phrase.apply(lambda row: regex(row))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a series of escapades demonstrating the adage ...</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this quiet  introspective and entertaining ind...</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>even fans of ismail merchant s work  i suspect...</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a positively thrilling combination of ethnogra...</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aggressive selfglorification and a manipulativ...</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Phrase  Sentiment\n",
       "0  a series of escapades demonstrating the adage ...       0.25\n",
       "1  this quiet  introspective and entertaining ind...       1.00\n",
       "2  even fans of ismail merchant s work  i suspect...       0.25\n",
       "3  a positively thrilling combination of ethnogra...       0.75\n",
       "4  aggressive selfglorification and a manipulativ...       0.25"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75    2321\n",
       "0.25    2200\n",
       "0.50    1655\n",
       "1.00    1281\n",
       "0.00    1072\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target value counts\n",
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 2) (1529, 2)\n"
     ]
    }
   ],
   "source": [
    "# test and train split\n",
    "train_df = df.iloc[: 7000]\n",
    "test_df = df.iloc[7000: ]\n",
    "\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 & 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic_Regression:\n",
    "    def __init__(self, max_iter=500, solver_calls=5,lambda_ = 0.1,Theta=None,\n",
    "                 solver=sopt.fmin_l_bfgs_b, debug=False):\n",
    "        self.Theta = Theta\n",
    "        self.solver_calls = solver_calls\n",
    "        self.max_iter = max_iter\n",
    "        self.solver = solver\n",
    "        self.debug = debug\n",
    "        self.lambda_ = lambda_\n",
    "    \n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))    \n",
    "    \n",
    "    def __logreg_loss(self, Theta, X, Y):\n",
    "        Theta = Theta.astype(np.float64)\n",
    "        X = X.astype(np.float64)\n",
    "        Y = Y.astype(np.float64)\n",
    "        \n",
    "        Z = np.dot(Theta, X.T)\n",
    "\n",
    "        SZ = self.__sigmoid(Z)\n",
    "        Y_ = Y[:,np.newaxis]\n",
    "        nll = -np.sum((Y_ * np.log2(SZ + 1e-50) + (1-Y_) * np.log2(1 - SZ + 1e-50)))\n",
    "\n",
    "        nll += (self.lambda_/2) * np.sum(Theta**2)\n",
    "\n",
    "        grad = np.dot(X.T, (SZ - Y).T )\n",
    "        grad = grad.reshape(Theta.shape) + self.lambda_ * Theta\n",
    "\n",
    "        return nll, grad\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        Theta = self.Theta\n",
    "        if Theta is None:\n",
    "            Theta = np.ones(X.shape[1]+1)\n",
    "        \n",
    "        X_with_ones = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "      \n",
    "        for i in tqdm(range(self.solver_calls), desc='Calculating Theta', position=0):\n",
    "            Theta = self.solver(lambda th: self.__logreg_loss(th, X_with_ones, y), \n",
    "                                Theta, maxiter=self.max_iter)[0]\n",
    "        self.Theta = Theta\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_with_ones = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "        preds = np.dot(self.Theta, X_with_ones.T)\n",
    "#         preds = np.dot(self.Theta, X_with_ones.T)\n",
    "        return preds, self.__sigmoid(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCountVectorizer:\n",
    "    def __init__(self, min_df=-1, max_df=1e18, binary=False):\n",
    "        self.min_df = min_df\n",
    "        self.max_df = max_df\n",
    "        self.binary = binary\n",
    "    \n",
    "    def fit(self, df):\n",
    "        words_cnt = defaultdict(int)\n",
    "        col = df.columns[0]\n",
    "        \n",
    "        for i in range(len(df)):\n",
    "            text = df.iloc[i][col]\n",
    "            for word in text.split():\n",
    "                words_cnt[word] += 1\n",
    "                \n",
    "        all_words = []\n",
    "        for word, cnt in words_cnt.items():\n",
    "            if self.min_df <= cnt <= self.max_df:\n",
    "                all_words.append(word)\n",
    "                \n",
    "        self.all_words_ids = {w:i for i,w in enumerate(all_words)}\n",
    "        self.width = len(all_words)\n",
    "        \n",
    "    \n",
    "    def transform(self, df):\n",
    "        col = df.columns[0]\n",
    "        count_matrix = np.zeros([len(df), self.width], \\\n",
    "                                dtype=np.int32)\n",
    "        \n",
    "        for i in range(len(df)):\n",
    "            text = df.iloc[i][col]\n",
    "            words_cnt = defaultdict(int)\n",
    "            \n",
    "            for word in text.split():\n",
    "                words_cnt[word] += 1\n",
    "            \n",
    "            for word, cnt in words_cnt.items():\n",
    "                if word in self.all_words_ids:\n",
    "                    pos = self.all_words_ids[word]\n",
    "                    if self.binary:\n",
    "                        count_matrix[i][pos] = 1\n",
    "                    else:\n",
    "                        count_matrix[i][pos] = cnt\n",
    "                    \n",
    "        return count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes LR output and maps for closest targets\n",
    "\n",
    "targets = np.array([0, 0.25, 0.5, 0.75, 1])\n",
    "def find_nearest(value, array=targets):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data embedding \n",
    "\n",
    "cv = MyCountVectorizer()\n",
    "cv.fit(train_df)\n",
    "\n",
    "X_train = cv.transform(train_df) \n",
    "X_test = cv.transform(test_df)\n",
    "\n",
    "y_train = train_df.Sentiment\n",
    "y_test = test_df.Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Theta: 100%|████████████████████████████████████████████████████████████████| 1/1 [02:18<00:00, 138.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "my_LR = Logistic_Regression(max_iter=1000, lambda_=10, Theta=None, debug=False, solver_calls=1)\n",
    "my_LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = my_LR.predict(X_train)\n",
    "test_preds = my_LR.predict(X_test)\n",
    "\n",
    "test_preds = list(map(lambda x: find_nearest(x), test_preds[1]))\n",
    "train_preds = list(map(lambda x: find_nearest(x), train_preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 35.243%\n",
      "Test acc: 29.562%\n"
     ]
    }
   ],
   "source": [
    "print(f'Train acc: {(np.array(train_preds) == np.array(y_train)).mean() * 100:.3f}%')\n",
    "print(f'Test acc: {(np.array(test_preds) == np.array(y_test)).mean() * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "0.50    4236\n",
      "0.75    1647\n",
      "0.25    1088\n",
      "1.00      18\n",
      "0.00      11\n",
      "dtype: int64\n",
      "\n",
      "Actual Train\n",
      "0.75    419\n",
      "0.25    390\n",
      "0.50    293\n",
      "1.00    233\n",
      "0.00    194\n",
      "Name: Sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Train')\n",
    "print(pd.Series(train_preds).value_counts())\n",
    "\n",
    "print('\\nActual Train')\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "0.50    1026\n",
      "0.75     295\n",
      "0.25     201\n",
      "0.00       5\n",
      "1.00       2\n",
      "dtype: int64\n",
      "\n",
      "Actual train\n",
      "0.75    419\n",
      "0.25    390\n",
      "0.50    293\n",
      "1.00    233\n",
      "0.00    194\n",
      "Name: Sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Test')\n",
    "print(pd.Series(test_preds).value_counts())\n",
    "\n",
    "print('\\nActual Test')\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 35.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "LR = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "LR.fit(X_train, y_train * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 96.700%\n",
      "Test acc: 39.111%\n"
     ]
    }
   ],
   "source": [
    "train_preds2 = LR.predict(X_train)\n",
    "test_preds2 = LR.predict(X_test)\n",
    "\n",
    "print(f'Train acc: {(np.array(train_preds2) == np.array(y_train * 4)).mean() * 100:.3f}%')\n",
    "print(f'Test acc: {(np.array(test_preds2) == np.array(y_test * 4)).mean() * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "3.0    1913\n",
      "1.0    1866\n",
      "2.0    1355\n",
      "4.0    1018\n",
      "0.0     848\n",
      "dtype: int64\n",
      "\n",
      "Actual Train\n",
      "0.75    419\n",
      "0.25    390\n",
      "0.50    293\n",
      "1.00    233\n",
      "0.00    194\n",
      "Name: Sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Train')\n",
    "print(pd.Series(train_preds2).value_counts())\n",
    "\n",
    "print('\\nActual Train')\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "3.0    459\n",
      "1.0    432\n",
      "2.0    292\n",
      "4.0    202\n",
      "0.0    144\n",
      "dtype: int64\n",
      "\n",
      "Actual Test\n",
      "0.75    419\n",
      "0.25    390\n",
      "0.50    293\n",
      "1.00    233\n",
      "0.00    194\n",
      "Name: Sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Test')\n",
    "print(pd.Series(test_preds2).value_counts())\n",
    "\n",
    "print('\\nActual Test')\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oridinal Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "oridinal_LR = LogisticAT(alpha=0)\n",
    "oridinal_LR.fit(X_train, (y_train * 4).astype(np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2, 7000]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    627\u001b[0m             \u001b[0mrefit_metric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'score'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 629\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 205\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2, 7000]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "cv.fit(train_df.Phrase)\n",
    "\n",
    "X_train = cv.transform(train_df) \n",
    "X_test = cv.transform(test_df)\n",
    "\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid.fit(X_train, train_df.Sentiment * 4)\n",
    "\n",
    "# print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "# print(\"Best parameters: \", grid.best_params_)\n",
    "# print(\"Best estimator: \", grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Febrin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\externals\\six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
      "C:\\Users\\Febrin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-b79e4319a447>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmglearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisualize_coefficients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_top_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "\n",
    "feature_names = cv.get_feature_names()\n",
    "mglearn.tools.visualize_coefficients(grid.best_estimator_.coef_, feature_names, n_top_features=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOq9DmD52l9ZwYdGlCpK8hb",
   "include_colab_link": true,
   "name": "Assignment1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
