{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimpleRNN - intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru (GRU)                    (None, 15, 200)           181200    \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 500)               1053000   \n",
      "=================================================================\n",
      "Total params: 1,234,200\n",
      "Trainable params: 1,234,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add( GRU(200, return_sequences=True, input_shape=(15, 100)) )\n",
    "model.add( GRU(500))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'gru_input:0' shape=(None, 15, 100) dtype=float32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'gru_1/Identity:0' shape=(None, 500) dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "8982 train sequences\n",
      "2246 test sequences\n",
      "46 classes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import reuters\n",
    "max_words  = 400\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words, test_split=0.2)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "print(num_classes, 'classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T14:54:09.644364Z",
     "start_time": "2018-11-15T14:54:09.634212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87, 56, 527)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[0]), len(x_train[1]), len(x_train[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T14:54:10.069682Z",
     "start_time": "2018-11-15T14:54:10.063856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 56,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 56,\n",
       " 2,\n",
       " 2,\n",
       " 81,\n",
       " 5,\n",
       " 2,\n",
       " 57,\n",
       " 366,\n",
       " 2,\n",
       " 132,\n",
       " 20,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 49,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 10,\n",
       " 241,\n",
       " 16,\n",
       " 2,\n",
       " 129,\n",
       " 231,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 48,\n",
       " 34,\n",
       " 191,\n",
       " 44,\n",
       " 35,\n",
       " 2,\n",
       " 2,\n",
       " 17,\n",
       " 12]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T14:54:10.731508Z",
     "start_time": "2018-11-15T14:54:10.593667Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sprawdzamy, czy gdziekolwiek użyto zerowego kodu słowa\n",
    "np.sum( np.array( [np.sum( np.array( x_train[i] ) == 0 ) for i in range(len(x_train))] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T14:54:19.190385Z",
     "start_time": "2018-11-15T14:54:18.735834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (8982, 46)\n",
      "y_test shape: (2246, 46)\n"
     ]
    }
   ],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train        shape: (8982,)\n",
      "x_test         shape: (2246,)\n",
      "x_train_padded shape: (8982, 200)\n",
      "x_test_padded  shape: (2246, 200)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "maxlen = 200\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train_padded = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test_padded  = sequence.pad_sequences(x_test,  maxlen=maxlen)\n",
    "print('x_train        shape:', x_train.shape)\n",
    "print('x_test         shape:', x_test.shape)\n",
    "print('x_train_padded shape:', x_train_padded.shape)\n",
    "print('x_test_padded  shape:', x_test_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   2,   2,   8,\n",
       "        43,  10,   2,   5,  25, 207, 270,   5,   2, 111,  16, 369, 186,\n",
       "        90,  67,   7,  89,   5,  19, 102,   6,  19, 124,  15,  90,  67,\n",
       "        84,  22,   2,  26,   7,  48,   4,  49,   8,   2,  39, 209, 154,\n",
       "         6, 151,   6,  83,  11,  15,  22, 155,  11,  15,   7,  48,   9,\n",
       "         2,   2,   2,   6, 258,   6, 272,  11,  15,  22, 134,  44,  11,\n",
       "        15,  16,   8, 197,   2,  90,  67,  52,  29, 209,  30,  32, 132,\n",
       "         6, 109,  15,  17,  12], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_padded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://image.slidesharecdn.com/translatefrombadenglishtogoodone-2-160606105036/95/aibigdata-lab-2016-11-638.jpg?cb=1465210454\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Dropout, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 200, 128)          51200     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 200, 250)          285000    \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 500)               1128000   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 46)                23046     \n",
      "=================================================================\n",
      "Total params: 1,487,246\n",
      "Trainable params: 1,487,246\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embeddings_dim = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add( Embedding( 400 , embeddings_dim , input_length=200)  )\n",
    "# model.add( Dropout(0.2) )\n",
    "\n",
    "model.add( GRU(250, return_sequences=True) )\n",
    "model.add( GRU(500) )\n",
    "\n",
    "model.add( Dense(46, activation='softmax') )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_input:0' shape=(None, 200) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense/Identity:0' shape=(None, 46) dtype=float32>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "8083/8083 [==============================] - 21s 3ms/sample - loss: 2.0621 - accuracy: 0.4617 - val_loss: 1.8135 - val_accuracy: 0.5184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6950243250>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_padded, y_train, batch_size=32, epochs=1, verbose=1, validation_split=0.1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'embedding_3/embeddings:0' shape=(400, 128) dtype=float32, numpy=\n",
       " array([[ 0.02655471,  0.0424326 ,  0.01030646, ...,  0.01516584,\n",
       "          0.01014158,  0.05025052],\n",
       "        [ 0.03735615, -0.00410256, -0.01206659, ...,  0.02475554,\n",
       "         -0.04505358, -0.02580771],\n",
       "        [ 0.0288943 , -0.00987562,  0.04722525, ...,  0.0110033 ,\n",
       "         -0.00849142,  0.03443868],\n",
       "        ...,\n",
       "        [ 0.00135914,  0.00666283,  0.00708391, ...,  0.04539788,\n",
       "          0.00697697, -0.02247263],\n",
       "        [ 0.01823797, -0.02547565, -0.00559118, ...,  0.02901956,\n",
       "         -0.01527192, -0.01932083],\n",
       "        [-0.00689064,  0.02441138, -0.02999184, ...,  0.04719028,\n",
       "          0.03238411,  0.03331821]], dtype=float32)>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "\n",
    "from   gensim.models import Word2Vec\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('/home/rno/data/models/GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "BASE_DIR = ''\n",
    "GLOVE_DIR = os.path.join(BASE_DIR, '/home/datasets/models/glove.6B')\n",
    "# EMBEDDING_DIM = 100\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'), encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.60587 ,  0.027989,  0.018495, -0.018674, -0.39562 ,  1.0309  ,\n",
       "       -0.35793 ,  0.20527 ,  0.3293  ,  0.035267, -0.38475 ,  0.31452 ,\n",
       "        0.32538 ,  0.70024 ,  0.13935 , -0.58923 ,  0.36985 , -0.080566,\n",
       "       -0.59721 ,  1.0215  , -0.55154 ,  0.042073,  0.34687 ,  0.86511 ,\n",
       "        0.63521 ,  0.52616 , -0.92199 , -1.4634  ,  0.34517 ,  0.58921 ,\n",
       "        0.12295 ,  0.7323  ,  1.0468  ,  0.065458, -0.27033 , -0.095179,\n",
       "        0.20613 ,  0.22589 ,  0.90409 , -0.11252 , -0.58059 ,  0.036599,\n",
       "        0.32003 , -0.53638 ,  0.19297 ,  0.035694, -0.56487 ,  0.1527  ,\n",
       "        0.70196 , -0.24191 ,  0.10476 , -0.23424 ,  1.212   ,  1.1612  ,\n",
       "       -0.033677, -1.9996  , -0.79448 , -0.087088,  0.51475 ,  0.44601 ,\n",
       "        0.638   ,  0.89893 ,  0.17408 , -0.32006 ,  0.41652 ,  0.23289 ,\n",
       "        0.50642 ,  0.26938 , -0.1453  ,  0.1207  , -0.26246 ,  0.16991 ,\n",
       "        0.16702 , -0.042041,  0.64841 ,  0.9827  , -0.092602, -0.56797 ,\n",
       "       -0.63854 , -0.38415 , -0.13816 ,  0.43137 ,  0.44748 ,  0.24486 ,\n",
       "       -1.5669  , -0.80245 , -0.15123 , -0.18795 , -0.4888  , -0.67834 ,\n",
       "        0.27133 , -0.36768 ,  1.1268  ,  0.44722 , -0.91335 , -0.055973,\n",
       "       -0.38328 , -0.62756 , -0.24055 , -0.22544 ], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index['mother']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   2,   2,   8,\n",
       "        43,  10,   2,   5,  25, 207, 270,   5,   2, 111,  16, 369, 186,\n",
       "        90,  67,   7,  89,   5,  19, 102,   6,  19, 124,  15,  90,  67,\n",
       "        84,  22,   2,  26,   7,  48,   4,  49,   8,   2,  39, 209, 154,\n",
       "         6, 151,   6,  83,  11,  15,  22, 155,  11,  15,   7,  48,   9,\n",
       "         2,   2,   2,   6, 258,   6, 272,  11,  15,  22, 134,  44,  11,\n",
       "        15,  16,   8, 197,   2,  90,  67,  52,  29, 209,  30,  32, 132,\n",
       "         6, 109,  15,  17,  12], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_padded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "embedding_matrix = np.random.randn(400, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 200, 100)          40000     \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 200, 250)          264000    \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, 500)               1128000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 46)                23046     \n",
      "=================================================================\n",
      "Total params: 1,455,046\n",
      "Trainable params: 1,415,046\n",
      "Non-trainable params: 40,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embeddings_dim = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add( Embedding( 400 , embeddings_dim , input_length=200, weights=[embedding_matrix], trainable=False)  )\n",
    "# model.add( Dropout(0.2) )\n",
    "\n",
    "model.add( GRU(250, return_sequences=True) )\n",
    "model.add( GRU(500) )\n",
    "\n",
    "model.add( Dense(46, activation='softmax') )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
