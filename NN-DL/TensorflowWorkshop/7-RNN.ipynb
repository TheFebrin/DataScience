{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:1', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "8982 train sequences\n",
      "2246 test sequences\n",
      "46 classes\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "\n",
    "max_words  = 400\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words, test_split=0.2)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "print(num_classes, 'classes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train        shape: (8982,)\n",
      "x_test         shape: (2246,)\n",
      "x_train_padded shape: (8982, 200)\n",
      "x_test_padded  shape: (2246, 200)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "maxlen = 200\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train_padded = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test_padded  = sequence.pad_sequences(x_test,  maxlen=maxlen)\n",
    "print('x_train        shape:', x_train.shape)\n",
    "print('x_test         shape:', x_test.shape)\n",
    "print('x_train_padded shape:', x_train_padded.shape)\n",
    "print('x_test_padded  shape:', x_test_padded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dropout, Dense, Conv1D, MaxPool1D, GlobalMaxPooling1D, BatchNormalization\n",
    "from tensorflow.keras.layers import ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "embeddings_dim = 200\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add( Embedding(max_words , embeddings_dim , input_length=maxlen, trainable=True)  )\n",
    "model.add( Dropout(0.6))\n",
    "model.add( Conv1D(filters=256, kernel_size=(11,), strides=3, padding='same', activation=None) )\n",
    "model.add( BatchNormalization() )\n",
    "model.add( ReLU() )\n",
    "model.add( Conv1D(filters=128, kernel_size=(7,), strides=2, padding='same', activation=None) )\n",
    "model.add( BatchNormalization() )\n",
    "model.add( ReLU() )\n",
    "model.add( MaxPool1D(pool_size=2) )\n",
    "model.add( Conv1D(filters=128, kernel_size=(5,), strides=2, padding='same', activation=None) )\n",
    "model.add( BatchNormalization() )\n",
    "model.add( ReLU() )\n",
    "model.add( GlobalMaxPooling1D() )\n",
    "model.add( Dense(100, activation='tanh') )\n",
    "model.add( Dropout(0.6))\n",
    "model.add( Dense(num_classes, activation='softmax') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 200, 200)          80000     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 200, 200)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 67, 256)           563456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 67, 256)           1024      \n",
      "_________________________________________________________________\n",
      "re_lu_21 (ReLU)              (None, 67, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 34, 128)           229504    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 34, 128)           512       \n",
      "_________________________________________________________________\n",
      "re_lu_22 (ReLU)              (None, 34, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 17, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 9, 128)            82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 9, 128)            512       \n",
      "_________________________________________________________________\n",
      "re_lu_23 (ReLU)              (None, 9, 128)            0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_7 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 46)                4646      \n",
      "=================================================================\n",
      "Total params: 974,602\n",
      "Trainable params: 973,578\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "8982/8982 [==============================] - 4s 478us/sample - loss: 2.2198 - accuracy: 0.4748 - val_loss: 2.9008 - val_accuracy: 0.3330\n",
      "Epoch 2/30\n",
      "8982/8982 [==============================] - 3s 389us/sample - loss: 1.6688 - accuracy: 0.5961 - val_loss: 1.5634 - val_accuracy: 0.6140\n",
      "Epoch 3/30\n",
      "8982/8982 [==============================] - 4s 391us/sample - loss: 1.4610 - accuracy: 0.6531 - val_loss: 1.3228 - val_accuracy: 0.6745\n",
      "Epoch 4/30\n",
      "8982/8982 [==============================] - 3s 388us/sample - loss: 1.3118 - accuracy: 0.6860 - val_loss: 1.2724 - val_accuracy: 0.6870\n",
      "Epoch 5/30\n",
      "8982/8982 [==============================] - 3s 382us/sample - loss: 1.2187 - accuracy: 0.7069 - val_loss: 1.2697 - val_accuracy: 0.6906\n",
      "Epoch 6/30\n",
      "8982/8982 [==============================] - 3s 387us/sample - loss: 1.1352 - accuracy: 0.7240 - val_loss: 1.1833 - val_accuracy: 0.7155\n",
      "Epoch 7/30\n",
      "8982/8982 [==============================] - 3s 387us/sample - loss: 1.0846 - accuracy: 0.7297 - val_loss: 1.1469 - val_accuracy: 0.7311\n",
      "Epoch 8/30\n",
      "8982/8982 [==============================] - 4s 395us/sample - loss: 1.0063 - accuracy: 0.7542 - val_loss: 1.1573 - val_accuracy: 0.7262\n",
      "Epoch 9/30\n",
      "8982/8982 [==============================] - 3s 386us/sample - loss: 0.9561 - accuracy: 0.7635 - val_loss: 1.1032 - val_accuracy: 0.7391\n",
      "Epoch 10/30\n",
      "8982/8982 [==============================] - 4s 394us/sample - loss: 0.9030 - accuracy: 0.7729 - val_loss: 1.1636 - val_accuracy: 0.7231\n",
      "Epoch 11/30\n",
      "8982/8982 [==============================] - 4s 394us/sample - loss: 0.8653 - accuracy: 0.7828 - val_loss: 1.1586 - val_accuracy: 0.7360\n",
      "Epoch 12/30\n",
      "8982/8982 [==============================] - 4s 398us/sample - loss: 0.8104 - accuracy: 0.7927 - val_loss: 1.1652 - val_accuracy: 0.7346\n",
      "Epoch 13/30\n",
      "8982/8982 [==============================] - 4s 394us/sample - loss: 0.7321 - accuracy: 0.8124 - val_loss: 1.1774 - val_accuracy: 0.7320\n",
      "Epoch 14/30\n",
      "8982/8982 [==============================] - 3s 387us/sample - loss: 0.7222 - accuracy: 0.8137 - val_loss: 1.1826 - val_accuracy: 0.7280\n",
      "Epoch 15/30\n",
      "8982/8982 [==============================] - 3s 387us/sample - loss: 0.6818 - accuracy: 0.8226 - val_loss: 1.2174 - val_accuracy: 0.7351\n",
      "Epoch 16/30\n",
      "8982/8982 [==============================] - 4s 391us/sample - loss: 0.6405 - accuracy: 0.8338 - val_loss: 1.2376 - val_accuracy: 0.7222\n",
      "Epoch 17/30\n",
      "8982/8982 [==============================] - 3s 387us/sample - loss: 0.6014 - accuracy: 0.8395 - val_loss: 1.2811 - val_accuracy: 0.7266\n",
      "Epoch 18/30\n",
      "8982/8982 [==============================] - 3s 389us/sample - loss: 0.5702 - accuracy: 0.8521 - val_loss: 1.2350 - val_accuracy: 0.7306\n",
      "Epoch 19/30\n",
      "8982/8982 [==============================] - 4s 393us/sample - loss: 0.5360 - accuracy: 0.8567 - val_loss: 1.2849 - val_accuracy: 0.7271\n",
      "Epoch 20/30\n",
      "8982/8982 [==============================] - 4s 393us/sample - loss: 0.5088 - accuracy: 0.8662 - val_loss: 1.2854 - val_accuracy: 0.7395\n",
      "Epoch 21/30\n",
      "8982/8982 [==============================] - 3s 389us/sample - loss: 0.4890 - accuracy: 0.8683 - val_loss: 1.3215 - val_accuracy: 0.7311\n",
      "Epoch 22/30\n",
      "8982/8982 [==============================] - 4s 393us/sample - loss: 0.4682 - accuracy: 0.8754 - val_loss: 1.3726 - val_accuracy: 0.7333\n",
      "Epoch 23/30\n",
      "8982/8982 [==============================] - 4s 396us/sample - loss: 0.4548 - accuracy: 0.8762 - val_loss: 1.3647 - val_accuracy: 0.7297\n",
      "Epoch 24/30\n",
      "8982/8982 [==============================] - 4s 391us/sample - loss: 0.4385 - accuracy: 0.8802 - val_loss: 1.4464 - val_accuracy: 0.7271\n",
      "Epoch 25/30\n",
      "8982/8982 [==============================] - 3s 387us/sample - loss: 0.4151 - accuracy: 0.8868 - val_loss: 1.3953 - val_accuracy: 0.7280\n",
      "Epoch 26/30\n",
      "8982/8982 [==============================] - 4s 394us/sample - loss: 0.3997 - accuracy: 0.8913 - val_loss: 1.4466 - val_accuracy: 0.7355\n",
      "Epoch 27/30\n",
      "8982/8982 [==============================] - 3s 384us/sample - loss: 0.3892 - accuracy: 0.8958 - val_loss: 1.4740 - val_accuracy: 0.7262\n",
      "Epoch 28/30\n",
      "8982/8982 [==============================] - 3s 387us/sample - loss: 0.3800 - accuracy: 0.8951 - val_loss: 1.4444 - val_accuracy: 0.7418\n",
      "Epoch 29/30\n",
      "8982/8982 [==============================] - 3s 389us/sample - loss: 0.3647 - accuracy: 0.9016 - val_loss: 1.4830 - val_accuracy: 0.7271\n",
      "Epoch 30/30\n",
      "8982/8982 [==============================] - 3s 386us/sample - loss: 0.3503 - accuracy: 0.9064 - val_loss: 1.4593 - val_accuracy: 0.7364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0fc83e7750>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_padded, y_train, batch_size=32, epochs=30, verbose=1, validation_data=(x_test_padded, y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add( Embedding( 400 , embeddings_dim , input_length=200)  )\n",
    "# model.add( Dropout(0.2) )\n",
    "\n",
    "model.add( LSTM(250, return_sequences=True) )\n",
    "model.add( LSTM(300) )\n",
    "\n",
    "model.add( Dense(46, activation='softmax') )\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 200, 200)          80000     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 200, 250)          451000    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 300)               661200    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 46)                13846     \n",
      "=================================================================\n",
      "Total params: 1,206,046\n",
      "Trainable params: 1,206,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/30\n",
      "8982/8982 [==============================] - 10s 1ms/sample - loss: 2.0916 - accuracy: 0.4582 - val_loss: 1.8863 - val_accuracy: 0.5209\n",
      "Epoch 2/30\n",
      "8982/8982 [==============================] - 8s 942us/sample - loss: 1.7918 - accuracy: 0.5429 - val_loss: 1.7335 - val_accuracy: 0.5623\n",
      "Epoch 3/30\n",
      "8982/8982 [==============================] - 8s 944us/sample - loss: 1.8236 - accuracy: 0.5314 - val_loss: 1.9186 - val_accuracy: 0.5129\n",
      "Epoch 4/30\n",
      "8982/8982 [==============================] - 8s 942us/sample - loss: 1.7274 - accuracy: 0.5596 - val_loss: 1.6884 - val_accuracy: 0.5748\n",
      "Epoch 5/30\n",
      "8982/8982 [==============================] - 8s 946us/sample - loss: 1.5880 - accuracy: 0.5910 - val_loss: 1.6663 - val_accuracy: 0.5797\n",
      "Epoch 6/30\n",
      "8982/8982 [==============================] - 8s 940us/sample - loss: 1.5189 - accuracy: 0.6129 - val_loss: 1.5775 - val_accuracy: 0.5984\n",
      "Epoch 7/30\n",
      "8982/8982 [==============================] - 8s 941us/sample - loss: 1.4332 - accuracy: 0.6306 - val_loss: 1.4622 - val_accuracy: 0.6322\n",
      "Epoch 8/30\n",
      "8982/8982 [==============================] - 8s 943us/sample - loss: 1.3537 - accuracy: 0.6542 - val_loss: 1.3848 - val_accuracy: 0.6425\n",
      "Epoch 9/30\n",
      "8982/8982 [==============================] - 8s 945us/sample - loss: 1.2828 - accuracy: 0.6713 - val_loss: 1.3307 - val_accuracy: 0.6679\n",
      "Epoch 10/30\n",
      "8982/8982 [==============================] - 9s 950us/sample - loss: 1.2284 - accuracy: 0.6856 - val_loss: 1.2803 - val_accuracy: 0.6870\n",
      "Epoch 11/30\n",
      "8982/8982 [==============================] - 9s 949us/sample - loss: 1.1548 - accuracy: 0.7149 - val_loss: 1.2632 - val_accuracy: 0.6874\n",
      "Epoch 12/30\n",
      "8982/8982 [==============================] - 9s 949us/sample - loss: 1.0925 - accuracy: 0.7233 - val_loss: 1.1873 - val_accuracy: 0.7102\n",
      "Epoch 13/30\n",
      "8982/8982 [==============================] - 9s 949us/sample - loss: 1.0569 - accuracy: 0.7329 - val_loss: 1.1877 - val_accuracy: 0.7119\n",
      "Epoch 14/30\n",
      "8982/8982 [==============================] - 9s 948us/sample - loss: 1.0052 - accuracy: 0.7472 - val_loss: 1.1597 - val_accuracy: 0.7208\n",
      "Epoch 15/30\n",
      "8982/8982 [==============================] - 8s 946us/sample - loss: 0.9596 - accuracy: 0.7581 - val_loss: 1.1395 - val_accuracy: 0.7244\n",
      "Epoch 16/30\n",
      "8982/8982 [==============================] - 9s 948us/sample - loss: 0.9165 - accuracy: 0.7685 - val_loss: 1.2111 - val_accuracy: 0.7084\n",
      "Epoch 17/30\n",
      "8982/8982 [==============================] - 9s 947us/sample - loss: 0.8921 - accuracy: 0.7731 - val_loss: 1.1223 - val_accuracy: 0.7320\n",
      "Epoch 18/30\n",
      "8982/8982 [==============================] - 9s 947us/sample - loss: 0.8373 - accuracy: 0.7837 - val_loss: 1.1201 - val_accuracy: 0.7315\n",
      "Epoch 19/30\n",
      "8982/8982 [==============================] - 9s 950us/sample - loss: 0.8094 - accuracy: 0.7897 - val_loss: 1.1567 - val_accuracy: 0.7240\n",
      "Epoch 20/30\n",
      "8982/8982 [==============================] - 9s 947us/sample - loss: 0.7557 - accuracy: 0.8009 - val_loss: 1.1226 - val_accuracy: 0.7418\n",
      "Epoch 21/30\n",
      "8982/8982 [==============================] - 8s 944us/sample - loss: 0.7195 - accuracy: 0.8116 - val_loss: 1.1378 - val_accuracy: 0.7329\n",
      "Epoch 22/30\n",
      "8982/8982 [==============================] - 8s 945us/sample - loss: 0.6962 - accuracy: 0.8138 - val_loss: 1.1493 - val_accuracy: 0.7382\n",
      "Epoch 23/30\n",
      "8982/8982 [==============================] - 9s 947us/sample - loss: 0.6370 - accuracy: 0.8262 - val_loss: 1.1782 - val_accuracy: 0.7293\n",
      "Epoch 24/30\n",
      "8982/8982 [==============================] - 9s 949us/sample - loss: 0.6019 - accuracy: 0.8361 - val_loss: 1.1760 - val_accuracy: 0.7378\n",
      "Epoch 25/30\n",
      "8982/8982 [==============================] - 8s 943us/sample - loss: 0.5338 - accuracy: 0.8517 - val_loss: 1.2008 - val_accuracy: 0.7400\n",
      "Epoch 26/30\n",
      "8982/8982 [==============================] - 8s 944us/sample - loss: 0.4868 - accuracy: 0.8658 - val_loss: 1.1978 - val_accuracy: 0.7315\n",
      "Epoch 27/30\n",
      "8982/8982 [==============================] - 8s 943us/sample - loss: 0.4418 - accuracy: 0.8789 - val_loss: 1.2315 - val_accuracy: 0.7324\n",
      "Epoch 28/30\n",
      "8982/8982 [==============================] - 9s 949us/sample - loss: 0.3960 - accuracy: 0.8900 - val_loss: 1.2536 - val_accuracy: 0.7231\n",
      "Epoch 29/30\n",
      "8982/8982 [==============================] - 9s 950us/sample - loss: 0.3576 - accuracy: 0.8999 - val_loss: 1.3079 - val_accuracy: 0.7240\n",
      "Epoch 30/30\n",
      "8982/8982 [==============================] - 8s 944us/sample - loss: 0.3304 - accuracy: 0.9057 - val_loss: 1.3332 - val_accuracy: 0.7235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0f8c5a7610>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_padded, y_train, batch_size=32, epochs=30, verbose=1, validation_data=(x_test_padded, y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
