{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Rafa≈Ç Nowak\n",
    "\n",
    "Warsztat Deep Learning\n",
    "\n",
    "9 kwietnia 2020\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:19:42.945315Z",
     "start_time": "2020-04-09T17:19:41.497406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:19:42.974397Z",
     "start_time": "2020-04-09T17:19:42.946795Z"
    }
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:19:43.135292Z",
     "start_time": "2020-04-09T17:19:42.975746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr  9 19:19:43 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 435.21       Driver Version: 435.21       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 105...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   56C    P0    N/A /  N/A |    522MiB /  4042MiB |     14%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      2487      G   /usr/lib/xorg/Xorg                           277MiB |\n",
      "|    0      2689      G   /usr/bin/gnome-shell                         210MiB |\n",
      "|    0      3753      G   ...quest-channel-token=2193344205732405486    24MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10 From `tensorflow_datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:19:43.484834Z",
     "start_time": "2020-04-09T17:19:43.136651Z"
    }
   },
   "outputs": [],
   "source": [
    "###########\n",
    "# Option 1\n",
    "# dataset = tfds.load('cifar10', as_supervised=True)\n",
    "# ds_train, ds_test = dataset['train'], dataset['test']\n",
    "###########\n",
    "\n",
    "\n",
    "###########\n",
    "# Option 2\n",
    "dataset = tfds.image.cifar.Cifar10()\n",
    "\n",
    "# Download dataset\n",
    "dataset.download_and_prepare()\n",
    "\n",
    "ds = dataset.as_dataset(as_supervised=True)\n",
    "ds_train, ds_test = ds['train'], ds['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:19:43.525410Z",
     "start_time": "2020-04-09T17:19:43.485908Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocess dataset (scale to [0, 1) and convert to float)\n",
    "\n",
    "def preprocess_fn(image, label):\n",
    "    return tf.image.convert_image_dtype(image, dtype=tf.float32), label\n",
    "\n",
    "ds_train = ds_train.map(preprocess_fn)\n",
    "ds_test  = ds_test.map(preprocess_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model1 = MLP from tf.keras.models.Sequential with softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:19:43.850562Z",
     "start_time": "2020-04-09T17:19:43.526391Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "model1 = Sequential([\n",
    "    Flatten(input_shape=(32, 32, 3)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take some batch from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:19:43.905692Z",
     "start_time": "2020-04-09T17:19:43.851567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of x_batch is (16, 32, 32, 3)\n",
      "The shape of y_batch is (16,)\n"
     ]
    }
   ],
   "source": [
    "x_batch, y_batch = next( ds_train.batch(16).take(1).__iter__() )\n",
    "\n",
    "print(f\"The shape of x_batch is {x_batch.shape}\")\n",
    "print(f\"The shape of y_batch is {y_batch.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two tensors `x_batch` and `y_batch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:19:43.914391Z",
     "start_time": "2020-04-09T17:19:43.907170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensorflow.python.framework.ops.EagerTensor,\n",
       " tensorflow.python.framework.ops.EagerTensor)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_batch), type(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:19:43.925473Z",
     "start_time": "2020-04-09T17:19:43.915962Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 8, 4, 4, 6, 5, 2, 9, 6, 6, 9, 9, 3, 0, 8, 7])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets feedforward the model with `x_batch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:19:44.082412Z",
     "start_time": "2020-04-09T17:19:43.926751Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model1(x_batch) # Tensor\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we used `softmax` at the end our predictions are actually *probaibilites* (not logits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:19:44.139450Z",
     "start_time": "2020-04-09T17:19:44.083528Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred1 = model1.predict(x_batch)\n",
    "y_pred2 = model1.predict_proba(x_batch)\n",
    "\n",
    "assert np.all( np.equal( y_pred1, y_pred2 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once also ask for the classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:19:44.160956Z",
     "start_time": "2020-04-09T17:19:44.140647Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 7, 7, 7, 9, 9, 7, 7, 9, 7, 9, 9, 7, 7, 9, 9])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.predict_classes(x_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can try to compare this with labels from ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:19:44.231540Z",
     "start_time": "2020-04-09T17:19:44.161891Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16,), dtype=int64, numpy=array([7, 8, 4, 4, 6, 5, 2, 9, 6, 6, 9, 9, 3, 0, 8, 7])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = next( ds_train.batch(16).take(1).map(lambda _, label: label).__iter__() )\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:19:44.253038Z",
     "start_time": "2020-04-09T17:19:44.232796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 1 - using numpy\n",
    "np.mean( labels.numpy() == model1.predict_classes(x_batch) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:19:44.259568Z",
     "start_time": "2020-04-09T17:19:44.254175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.125>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 2 - using only tensorflow\n",
    "\n",
    "# Info: this is probably too complicated :-)\n",
    "tf.reduce_mean(\n",
    "    tf.cast(\n",
    "        tf.equal(\n",
    "            tf.argmax( model1(x_batch), axis=1 ), \n",
    "            labels\n",
    "        ),\n",
    "        dtype=tf.float32\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model2 = model1 without softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:19:44.282638Z",
     "start_time": "2020-04-09T17:19:44.260709Z"
    }
   },
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Flatten(input_shape=(32, 32, 3)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10) # no more softmax activation\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few more experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:19:44.287900Z",
     "start_time": "2020-04-09T17:19:44.283895Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model2(x_batch) # Tensor\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we didn't use `softmax` at the end our predictions are actually **logits**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:19:44.329719Z",
     "start_time": "2020-04-09T17:19:44.288792Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred1 = model2.predict(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:19:44.353436Z",
     "start_time": "2020-04-09T17:19:44.330841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n"
     ]
    }
   ],
   "source": [
    "# Warning: one should not use predict_proba now\n",
    "y_pred2 = model2.predict_proba(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:19:44.356269Z",
     "start_time": "2020-04-09T17:19:44.354356Z"
    }
   },
   "outputs": [],
   "source": [
    "# but the assertion passes\n",
    "assert np.all( np.equal( y_pred1, y_pred2 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T16:01:15.610037Z",
     "start_time": "2020-04-09T16:01:15.599668Z"
    }
   },
   "source": [
    "Once also ask for the classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:19:44.384810Z",
     "start_time": "2020-04-09T17:19:44.357176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 4, 6, 6, 4, 6, 5, 6, 6, 6, 6, 6, 4, 5, 6, 6])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict_classes(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:19:44.406152Z",
     "start_time": "2020-04-09T17:19:44.385807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean( labels.numpy() == model2.predict_classes(x_batch) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to use `from_logits=False` (`True`) with `model1` (`model2`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:19:44.434797Z",
     "start_time": "2020-04-09T17:19:44.408621Z"
    }
   },
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:19:44.459810Z",
     "start_time": "2020-04-09T17:19:44.435991Z"
    }
   },
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models for 5 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use `batch_size=16`.\n",
    "\n",
    "One can observe that `model2` is usually insignificantly better "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:20:11.130386Z",
     "start_time": "2020-04-09T17:19:44.461069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.8956 - accuracy: 0.3155\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 1.7707 - accuracy: 0.3654\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 1.7366 - accuracy: 0.3788\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 1.7169 - accuracy: 0.3877\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 1.7033 - accuracy: 0.3913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc114161f10>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(ds_train.batch(16), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:20:39.183948Z",
     "start_time": "2020-04-09T17:20:11.131715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 8s 2ms/step - loss: 1.9414 - accuracy: 0.2840\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 1.8522 - accuracy: 0.3285\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 1.8235 - accuracy: 0.3436\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 1.7982 - accuracy: 0.3526\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 1.7750 - accuracy: 0.3654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc10c31ff10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(ds_train.batch(16), epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train again and monitor the validation loss (and accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:21:09.130838Z",
     "start_time": "2020-04-09T17:20:39.184982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 8s 3ms/step - loss: 1.6925 - accuracy: 0.3962 - val_loss: 1.7002 - val_accuracy: 0.3955\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 1.6837 - accuracy: 0.3993 - val_loss: 1.7007 - val_accuracy: 0.3945\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 1.6754 - accuracy: 0.4020 - val_loss: 1.6932 - val_accuracy: 0.3960\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 1.6687 - accuracy: 0.4046 - val_loss: 1.6975 - val_accuracy: 0.3924\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 1.6620 - accuracy: 0.4072 - val_loss: 1.7002 - val_accuracy: 0.3916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc1046d0f50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(ds_train.batch(16), epochs=5, validation_data=ds_test.batch(64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:21:39.143581Z",
     "start_time": "2020-04-09T17:21:09.131873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3125/3125 [==============================] - 8s 2ms/step - loss: 1.7609 - accuracy: 0.3704 - val_loss: 1.7762 - val_accuracy: 0.3694\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 1.7515 - accuracy: 0.3739 - val_loss: 1.7774 - val_accuracy: 0.3673\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 1.7441 - accuracy: 0.3771 - val_loss: 1.7713 - val_accuracy: 0.3689\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 1.7385 - accuracy: 0.3788 - val_loss: 1.7669 - val_accuracy: 0.3699\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 1.7338 - accuracy: 0.3804 - val_loss: 1.7645 - val_accuracy: 0.3691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc1046dba10>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(ds_train.batch(16), epochs=5, validation_data=ds_test.batch(64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can see above the logged values of `val_loss` and `val_accuracy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse the confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:21:39.184872Z",
     "start_time": "2020-04-09T17:21:39.145054Z"
    }
   },
   "outputs": [],
   "source": [
    "train_images = ds_train.map(lambda img,label: img)\n",
    "train_labels = ds_train.map(lambda img,label: label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:21:45.732714Z",
     "start_time": "2020-04-09T17:21:39.186069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
       "array([[1841,  189,  206,   36,  187,  111,   88,  365, 1569,  408],\n",
       "       [ 214, 2084,   78,   25,  116,   82,  125,  239,  578, 1459],\n",
       "       [ 414,  126,  717,   80, 1428,  391,  591,  658,  425,  170],\n",
       "       [ 125,  191,  295,  341,  601, 1214,  696,  605,  445,  487],\n",
       "       [ 221,  123,  352,   36, 2184,  188,  561,  843,  313,  179],\n",
       "       [  82,  137,  399,  218,  641, 1703,  446,  718,  396,  260],\n",
       "       [  35,  102,  170,  152, 1100,  416, 2231,  318,  172,  304],\n",
       "       [ 163,  182,  176,   38,  656,  282,  111, 2775,  245,  372],\n",
       "       [ 253,  207,   60,   14,   85,  140,   42,   78, 3600,  521],\n",
       "       [ 212,  572,   70,    9,   77,   92,  117,  269,  674, 2908]],\n",
       "      dtype=int32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model1.predict_classes( train_images.batch(32), batch_size=None )\n",
    "tf.math.confusion_matrix( list(train_labels), predictions )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:21:47.725632Z",
     "start_time": "2020-04-09T17:21:45.733791Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = model2.predict_classes( train_images.batch(32), batch_size=None )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remember to use callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:21:47.729081Z",
     "start_time": "2020-04-09T17:21:47.726643Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:21:47.832765Z",
     "start_time": "2020-04-09T17:21:47.730230Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lets start from scratch\n",
    "\n",
    "model1 = Sequential([\n",
    "    Flatten(input_shape=(32, 32, 3)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model2 = Sequential([\n",
    "    Flatten(input_shape=(32, 32, 3)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10) # no more softmax activation\n",
    "])\n",
    "\n",
    "model1.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:21:47.836866Z",
     "start_time": "2020-04-09T17:21:47.833833Z"
    }
   },
   "outputs": [],
   "source": [
    "# stop training when 5 epochs does not improve validation loss\n",
    "early_stopping = EarlyStopping(monitor='val_loss', verbose=1, patience=5)\n",
    "# logging tensorboard values\n",
    "tensorboard1 = TensorBoard('logs/mlp-model1')\n",
    "tensorboard2 = TensorBoard('logs/mlp-model2')\n",
    "# reduce learning rate when monitored values does not improve\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', verbose=1, patience=3)  # reduce_lr.patience should be smaller than early_stopping.patience\n",
    "\n",
    "# save the best model\n",
    "model1_checkpoint = ModelCheckpoint('model1.h5', save_best_only=True)\n",
    "model2_checkpoint = ModelCheckpoint('model2.h5', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:31:10.771592Z",
     "start_time": "2020-04-09T17:21:47.837916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 1.9185 - accuracy: 0.2993 - val_loss: 1.8050 - val_accuracy: 0.3529\n",
      "Epoch 2/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.7970 - accuracy: 0.3556 - val_loss: 1.7520 - val_accuracy: 0.3712\n",
      "Epoch 3/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.7564 - accuracy: 0.3733 - val_loss: 1.7416 - val_accuracy: 0.3736\n",
      "Epoch 4/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.7247 - accuracy: 0.3841 - val_loss: 1.7117 - val_accuracy: 0.3796\n",
      "Epoch 5/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.6999 - accuracy: 0.3925 - val_loss: 1.6897 - val_accuracy: 0.3889\n",
      "Epoch 6/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.6863 - accuracy: 0.3966 - val_loss: 1.6877 - val_accuracy: 0.3890\n",
      "Epoch 7/100\n",
      "3125/3125 [==============================] - 8s 2ms/step - loss: 1.6752 - accuracy: 0.4003 - val_loss: 1.6844 - val_accuracy: 0.3900\n",
      "Epoch 8/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.6658 - accuracy: 0.4038 - val_loss: 1.6844 - val_accuracy: 0.3928\n",
      "Epoch 9/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.6569 - accuracy: 0.4077 - val_loss: 1.6806 - val_accuracy: 0.3974\n",
      "Epoch 10/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.6462 - accuracy: 0.4130 - val_loss: 1.6763 - val_accuracy: 0.4001\n",
      "Epoch 11/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.6393 - accuracy: 0.4144 - val_loss: 1.6844 - val_accuracy: 0.3959\n",
      "Epoch 12/100\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 1.6336 - accuracy: 0.4174 - val_loss: 1.6806 - val_accuracy: 0.3960\n",
      "Epoch 13/100\n",
      "3099/3125 [============================>.] - ETA: 0s - loss: 1.6296 - accuracy: 0.4202\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.6293 - accuracy: 0.4205 - val_loss: 1.6862 - val_accuracy: 0.3946\n",
      "Epoch 14/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5733 - accuracy: 0.4423 - val_loss: 1.6081 - val_accuracy: 0.4304\n",
      "Epoch 15/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5669 - accuracy: 0.4463 - val_loss: 1.6064 - val_accuracy: 0.4312\n",
      "Epoch 16/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5647 - accuracy: 0.4472 - val_loss: 1.6056 - val_accuracy: 0.4323\n",
      "Epoch 17/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5630 - accuracy: 0.4472 - val_loss: 1.6056 - val_accuracy: 0.4326\n",
      "Epoch 18/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5616 - accuracy: 0.4477 - val_loss: 1.6051 - val_accuracy: 0.4336\n",
      "Epoch 19/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5604 - accuracy: 0.4484 - val_loss: 1.6048 - val_accuracy: 0.4333\n",
      "Epoch 20/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5593 - accuracy: 0.4491 - val_loss: 1.6044 - val_accuracy: 0.4332\n",
      "Epoch 21/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5583 - accuracy: 0.4497 - val_loss: 1.6043 - val_accuracy: 0.4339\n",
      "Epoch 22/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5573 - accuracy: 0.4499 - val_loss: 1.6043 - val_accuracy: 0.4338\n",
      "Epoch 23/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5564 - accuracy: 0.4502 - val_loss: 1.6041 - val_accuracy: 0.4337\n",
      "Epoch 24/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5555 - accuracy: 0.4506 - val_loss: 1.6039 - val_accuracy: 0.4335\n",
      "Epoch 25/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5547 - accuracy: 0.4511 - val_loss: 1.6038 - val_accuracy: 0.4339\n",
      "Epoch 26/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5538 - accuracy: 0.4512 - val_loss: 1.6036 - val_accuracy: 0.4332\n",
      "Epoch 27/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5531 - accuracy: 0.4513 - val_loss: 1.6034 - val_accuracy: 0.4332\n",
      "Epoch 28/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5523 - accuracy: 0.4515 - val_loss: 1.6034 - val_accuracy: 0.4332\n",
      "Epoch 29/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5516 - accuracy: 0.4518 - val_loss: 1.6032 - val_accuracy: 0.4330\n",
      "Epoch 30/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5509 - accuracy: 0.4519 - val_loss: 1.6028 - val_accuracy: 0.4330\n",
      "Epoch 31/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5502 - accuracy: 0.4524 - val_loss: 1.6030 - val_accuracy: 0.4346\n",
      "Epoch 32/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 1.5495 - accuracy: 0.4527 - val_loss: 1.6030 - val_accuracy: 0.4350\n",
      "Epoch 33/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5488 - accuracy: 0.4525 - val_loss: 1.6027 - val_accuracy: 0.4344\n",
      "Epoch 34/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5481 - accuracy: 0.4527 - val_loss: 1.6028 - val_accuracy: 0.4351\n",
      "Epoch 35/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5475 - accuracy: 0.4528 - val_loss: 1.6027 - val_accuracy: 0.4363\n",
      "Epoch 36/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5468 - accuracy: 0.4531 - val_loss: 1.6026 - val_accuracy: 0.4361\n",
      "Epoch 37/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5462 - accuracy: 0.4532 - val_loss: 1.6024 - val_accuracy: 0.4359\n",
      "Epoch 38/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5456 - accuracy: 0.4535 - val_loss: 1.6023 - val_accuracy: 0.4362\n",
      "Epoch 39/100\n",
      "3125/3125 [==============================] - 8s 3ms/step - loss: 1.5450 - accuracy: 0.4535 - val_loss: 1.6021 - val_accuracy: 0.4362\n",
      "Epoch 40/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5444 - accuracy: 0.4540 - val_loss: 1.6018 - val_accuracy: 0.4364\n",
      "Epoch 41/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5439 - accuracy: 0.4541 - val_loss: 1.6017 - val_accuracy: 0.4366\n",
      "Epoch 42/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5433 - accuracy: 0.4544 - val_loss: 1.6017 - val_accuracy: 0.4359\n",
      "Epoch 43/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5428 - accuracy: 0.4546 - val_loss: 1.6015 - val_accuracy: 0.4361\n",
      "Epoch 44/100\n",
      "3125/3125 [==============================] - 8s 2ms/step - loss: 1.5422 - accuracy: 0.4549 - val_loss: 1.6014 - val_accuracy: 0.4366\n",
      "Epoch 45/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5416 - accuracy: 0.4550 - val_loss: 1.6010 - val_accuracy: 0.4366\n",
      "Epoch 46/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5411 - accuracy: 0.4552 - val_loss: 1.6009 - val_accuracy: 0.4362\n",
      "Epoch 47/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5405 - accuracy: 0.4556 - val_loss: 1.6008 - val_accuracy: 0.4364\n",
      "Epoch 48/100\n",
      "3125/3125 [==============================] - 8s 3ms/step - loss: 1.5400 - accuracy: 0.4557 - val_loss: 1.6006 - val_accuracy: 0.4369\n",
      "Epoch 49/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5395 - accuracy: 0.4563 - val_loss: 1.6006 - val_accuracy: 0.4372\n",
      "Epoch 50/100\n",
      "3125/3125 [==============================] - 8s 3ms/step - loss: 1.5390 - accuracy: 0.4565 - val_loss: 1.6005 - val_accuracy: 0.4371\n",
      "Epoch 51/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5384 - accuracy: 0.4563 - val_loss: 1.6007 - val_accuracy: 0.4374\n",
      "Epoch 52/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5379 - accuracy: 0.4568 - val_loss: 1.6007 - val_accuracy: 0.4372\n",
      "Epoch 53/100\n",
      "3110/3125 [============================>.] - ETA: 0s - loss: 1.5380 - accuracy: 0.4567\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5375 - accuracy: 0.4570 - val_loss: 1.6005 - val_accuracy: 0.4373\n",
      "Epoch 54/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5300 - accuracy: 0.4590 - val_loss: 1.5953 - val_accuracy: 0.4381\n",
      "Epoch 55/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5295 - accuracy: 0.4594 - val_loss: 1.5952 - val_accuracy: 0.4384\n",
      "Epoch 56/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5294 - accuracy: 0.4596 - val_loss: 1.5951 - val_accuracy: 0.4383\n",
      "Epoch 57/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5293 - accuracy: 0.4597 - val_loss: 1.5951 - val_accuracy: 0.4384\n",
      "Epoch 58/100\n",
      "3104/3125 [============================>.] - ETA: 0s - loss: 1.5296 - accuracy: 0.4596\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5292 - accuracy: 0.4598 - val_loss: 1.5951 - val_accuracy: 0.4383\n",
      "Epoch 59/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5285 - accuracy: 0.4598 - val_loss: 1.5946 - val_accuracy: 0.4378\n",
      "Epoch 60/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5283 - accuracy: 0.4597 - val_loss: 1.5945 - val_accuracy: 0.4371\n",
      "Epoch 61/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5283 - accuracy: 0.4595 - val_loss: 1.5945 - val_accuracy: 0.4375\n",
      "Epoch 62/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5283 - accuracy: 0.4595 - val_loss: 1.5945 - val_accuracy: 0.4378\n",
      "Epoch 63/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5282 - accuracy: 0.4596 - val_loss: 1.5944 - val_accuracy: 0.4380\n",
      "Epoch 64/100\n",
      "3109/3125 [============================>.] - ETA: 0s - loss: 1.5287 - accuracy: 0.4592\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5282 - accuracy: 0.4595 - val_loss: 1.5944 - val_accuracy: 0.4379\n",
      "Epoch 65/100\n",
      "3125/3125 [==============================] - 8s 2ms/step - loss: 1.5281 - accuracy: 0.4596 - val_loss: 1.5944 - val_accuracy: 0.4379\n",
      "Epoch 66/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5281 - accuracy: 0.4596 - val_loss: 1.5944 - val_accuracy: 0.4380\n",
      "Epoch 67/100\n",
      "3101/3125 [============================>.] - ETA: 0s - loss: 1.5283 - accuracy: 0.4594\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "3125/3125 [==============================] - 10s 3ms/step - loss: 1.5281 - accuracy: 0.4596 - val_loss: 1.5944 - val_accuracy: 0.4380\n",
      "Epoch 68/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5281 - accuracy: 0.4596 - val_loss: 1.5944 - val_accuracy: 0.4380\n",
      "Epoch 69/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 1.5281 - accuracy: 0.4596 - val_loss: 1.5944 - val_accuracy: 0.4380\n",
      "Epoch 70/100\n",
      "3116/3125 [============================>.] - ETA: 0s - loss: 1.5282 - accuracy: 0.4595\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5281 - accuracy: 0.4596 - val_loss: 1.5944 - val_accuracy: 0.4380\n",
      "Epoch 71/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5281 - accuracy: 0.4596 - val_loss: 1.5944 - val_accuracy: 0.4380\n",
      "Epoch 72/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5281 - accuracy: 0.4596 - val_loss: 1.5944 - val_accuracy: 0.4380\n",
      "Epoch 73/100\n",
      "3124/3125 [============================>.] - ETA: 0s - loss: 1.5280 - accuracy: 0.4596\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5281 - accuracy: 0.4596 - val_loss: 1.5944 - val_accuracy: 0.4380\n",
      "Epoch 74/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 1.5281 - accuracy: 0.4596 - val_loss: 1.5944 - val_accuracy: 0.4380\n",
      "Epoch 75/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5281 - accuracy: 0.4596 - val_loss: 1.5944 - val_accuracy: 0.4380\n",
      "Epoch 76/100\n",
      "3115/3125 [============================>.] - ETA: 0s - loss: 1.5282 - accuracy: 0.4595\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5281 - accuracy: 0.4596 - val_loss: 1.5944 - val_accuracy: 0.4380\n",
      "Epoch 77/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5281 - accuracy: 0.4596 - val_loss: 1.5944 - val_accuracy: 0.4380\n",
      "Epoch 78/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5281 - accuracy: 0.4596 - val_loss: 1.5944 - val_accuracy: 0.4380\n",
      "Epoch 79/100\n",
      "3120/3125 [============================>.] - ETA: 0s - loss: 1.5281 - accuracy: 0.4595\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5281 - accuracy: 0.4596 - val_loss: 1.5944 - val_accuracy: 0.4380\n",
      "Epoch 80/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5281 - accuracy: 0.4596 - val_loss: 1.5944 - val_accuracy: 0.4380\n",
      "Epoch 81/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5281 - accuracy: 0.4596 - val_loss: 1.5944 - val_accuracy: 0.4380\n",
      "Epoch 00081: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc1046926d0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(\n",
    "    ds_train.batch(16), epochs=100, validation_data=ds_test.batch(64),\n",
    "    callbacks=[early_stopping, tensorboard1, reduce_lr, model1_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:37:45.926912Z",
     "start_time": "2020-04-09T17:31:10.772552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 1.8821 - accuracy: 0.3217 - val_loss: 1.7720 - val_accuracy: 0.3623\n",
      "Epoch 2/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.7468 - accuracy: 0.3718 - val_loss: 1.7085 - val_accuracy: 0.3880\n",
      "Epoch 3/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.7001 - accuracy: 0.3894 - val_loss: 1.6659 - val_accuracy: 0.4019\n",
      "Epoch 4/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.6699 - accuracy: 0.4014 - val_loss: 1.6607 - val_accuracy: 0.4017\n",
      "Epoch 5/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.6505 - accuracy: 0.4078 - val_loss: 1.6543 - val_accuracy: 0.4017\n",
      "Epoch 6/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.6351 - accuracy: 0.4143 - val_loss: 1.6397 - val_accuracy: 0.4101\n",
      "Epoch 7/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.6229 - accuracy: 0.4169 - val_loss: 1.6385 - val_accuracy: 0.4080\n",
      "Epoch 8/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.6138 - accuracy: 0.4209 - val_loss: 1.6350 - val_accuracy: 0.4120\n",
      "Epoch 9/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.6051 - accuracy: 0.4240 - val_loss: 1.6342 - val_accuracy: 0.4141\n",
      "Epoch 10/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5983 - accuracy: 0.4268 - val_loss: 1.6284 - val_accuracy: 0.4173\n",
      "Epoch 11/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5920 - accuracy: 0.4283 - val_loss: 1.6307 - val_accuracy: 0.4153\n",
      "Epoch 12/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5858 - accuracy: 0.4296 - val_loss: 1.6343 - val_accuracy: 0.4142\n",
      "Epoch 13/100\n",
      "3112/3125 [============================>.] - ETA: 0s - loss: 1.5814 - accuracy: 0.4319\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5806 - accuracy: 0.4322 - val_loss: 1.6337 - val_accuracy: 0.4150\n",
      "Epoch 14/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5199 - accuracy: 0.4578 - val_loss: 1.5669 - val_accuracy: 0.4423\n",
      "Epoch 15/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 1.5139 - accuracy: 0.4604 - val_loss: 1.5653 - val_accuracy: 0.4438\n",
      "Epoch 16/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5117 - accuracy: 0.4607 - val_loss: 1.5646 - val_accuracy: 0.4434\n",
      "Epoch 17/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5100 - accuracy: 0.4607 - val_loss: 1.5636 - val_accuracy: 0.4443\n",
      "Epoch 18/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5086 - accuracy: 0.4608 - val_loss: 1.5636 - val_accuracy: 0.4444\n",
      "Epoch 19/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5073 - accuracy: 0.4612 - val_loss: 1.5629 - val_accuracy: 0.4458\n",
      "Epoch 20/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5061 - accuracy: 0.4612 - val_loss: 1.5629 - val_accuracy: 0.4459\n",
      "Epoch 21/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5049 - accuracy: 0.4613 - val_loss: 1.5624 - val_accuracy: 0.4456\n",
      "Epoch 22/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5038 - accuracy: 0.4617 - val_loss: 1.5619 - val_accuracy: 0.4457\n",
      "Epoch 23/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5027 - accuracy: 0.4622 - val_loss: 1.5617 - val_accuracy: 0.4450\n",
      "Epoch 24/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 1.5017 - accuracy: 0.4627 - val_loss: 1.5614 - val_accuracy: 0.4453\n",
      "Epoch 25/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.5007 - accuracy: 0.4629 - val_loss: 1.5614 - val_accuracy: 0.4455\n",
      "Epoch 26/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4998 - accuracy: 0.4633 - val_loss: 1.5611 - val_accuracy: 0.4455\n",
      "Epoch 27/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4988 - accuracy: 0.4640 - val_loss: 1.5612 - val_accuracy: 0.4457\n",
      "Epoch 28/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4980 - accuracy: 0.4644 - val_loss: 1.5610 - val_accuracy: 0.4461\n",
      "Epoch 29/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4971 - accuracy: 0.4646 - val_loss: 1.5610 - val_accuracy: 0.4455\n",
      "Epoch 30/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4962 - accuracy: 0.4647 - val_loss: 1.5609 - val_accuracy: 0.4450\n",
      "Epoch 31/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4954 - accuracy: 0.4647 - val_loss: 1.5612 - val_accuracy: 0.4441\n",
      "Epoch 32/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4945 - accuracy: 0.4651 - val_loss: 1.5609 - val_accuracy: 0.4446\n",
      "Epoch 33/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4937 - accuracy: 0.4654 - val_loss: 1.5606 - val_accuracy: 0.4442\n",
      "Epoch 34/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4929 - accuracy: 0.4656 - val_loss: 1.5607 - val_accuracy: 0.4443\n",
      "Epoch 35/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4921 - accuracy: 0.4664 - val_loss: 1.5606 - val_accuracy: 0.4442\n",
      "Epoch 36/100\n",
      "3104/3125 [============================>.] - ETA: 0s - loss: 1.4916 - accuracy: 0.4664\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4913 - accuracy: 0.4666 - val_loss: 1.5607 - val_accuracy: 0.4445\n",
      "Epoch 37/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4841 - accuracy: 0.4688 - val_loss: 1.5550 - val_accuracy: 0.4458\n",
      "Epoch 38/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4833 - accuracy: 0.4693 - val_loss: 1.5548 - val_accuracy: 0.4456\n",
      "Epoch 39/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4831 - accuracy: 0.4696 - val_loss: 1.5547 - val_accuracy: 0.4462\n",
      "Epoch 40/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4829 - accuracy: 0.4696 - val_loss: 1.5547 - val_accuracy: 0.4462\n",
      "Epoch 41/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 1.4828 - accuracy: 0.4698 - val_loss: 1.5547 - val_accuracy: 0.4462\n",
      "Epoch 42/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4827 - accuracy: 0.4698 - val_loss: 1.5547 - val_accuracy: 0.4462\n",
      "Epoch 43/100\n",
      "3111/3125 [============================>.] - ETA: 0s - loss: 1.4829 - accuracy: 0.4696\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4826 - accuracy: 0.4698 - val_loss: 1.5547 - val_accuracy: 0.4466\n",
      "Epoch 44/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 1.4818 - accuracy: 0.4700 - val_loss: 1.5543 - val_accuracy: 0.4473\n",
      "Epoch 45/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4816 - accuracy: 0.4704 - val_loss: 1.5543 - val_accuracy: 0.4479\n",
      "Epoch 46/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 1.4816 - accuracy: 0.4705 - val_loss: 1.5543 - val_accuracy: 0.4483\n",
      "Epoch 47/100\n",
      "3114/3125 [============================>.] - ETA: 0s - loss: 1.4818 - accuracy: 0.4702\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4815 - accuracy: 0.4703 - val_loss: 1.5543 - val_accuracy: 0.4484\n",
      "Epoch 48/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4814 - accuracy: 0.4705 - val_loss: 1.5543 - val_accuracy: 0.4482\n",
      "Epoch 49/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4814 - accuracy: 0.4706 - val_loss: 1.5542 - val_accuracy: 0.4481\n",
      "Epoch 50/100\n",
      "3102/3125 [============================>.] - ETA: 0s - loss: 1.4815 - accuracy: 0.4705\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4814 - accuracy: 0.4705 - val_loss: 1.5542 - val_accuracy: 0.4480\n",
      "Epoch 51/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4814 - accuracy: 0.4705 - val_loss: 1.5542 - val_accuracy: 0.4481\n",
      "Epoch 52/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4814 - accuracy: 0.4705 - val_loss: 1.5542 - val_accuracy: 0.4481\n",
      "Epoch 53/100\n",
      "3117/3125 [============================>.] - ETA: 0s - loss: 1.4815 - accuracy: 0.4704\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4814 - accuracy: 0.4705 - val_loss: 1.5542 - val_accuracy: 0.4481\n",
      "Epoch 54/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4814 - accuracy: 0.4705 - val_loss: 1.5542 - val_accuracy: 0.4481\n",
      "Epoch 55/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4814 - accuracy: 0.4705 - val_loss: 1.5542 - val_accuracy: 0.4481\n",
      "Epoch 56/100\n",
      "3114/3125 [============================>.] - ETA: 0s - loss: 1.4817 - accuracy: 0.4704\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4814 - accuracy: 0.4705 - val_loss: 1.5542 - val_accuracy: 0.4481\n",
      "Epoch 57/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 1.4814 - accuracy: 0.4705 - val_loss: 1.5542 - val_accuracy: 0.4481\n",
      "Epoch 58/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.4814 - accuracy: 0.4705 - val_loss: 1.5542 - val_accuracy: 0.4481\n",
      "Epoch 59/100\n",
      "3120/3125 [============================>.] - ETA: 0s - loss: 1.4814 - accuracy: 0.4704\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 1.4814 - accuracy: 0.4705 - val_loss: 1.5542 - val_accuracy: 0.4481\n",
      "Epoch 00059: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc1045b4f90>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(\n",
    "    ds_train.batch(16), epochs=100, validation_data=ds_test.batch(64),\n",
    "    callbacks=[early_stopping, tensorboard2, reduce_lr, model2_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:37:46.361371Z",
     "start_time": "2020-04-09T17:37:45.929091Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model1 = load_model('model1.h5')\n",
    "model2 = load_model('model2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and evaluate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:37:49.671912Z",
     "start_time": "2020-04-09T17:37:46.362739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    157/Unknown - 1s 4ms/step - loss: 1.5944 - accuracy: 0.4380"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1.5282324253750579, 0.45964], [1.594430197576049, 0.438])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(ds_train.batch(64)), model1.evaluate(ds_test.batch(64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:37:52.977456Z",
     "start_time": "2020-04-09T17:37:49.672750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    157/Unknown - 0s 3ms/step - loss: 1.5542 - accuracy: 0.4481"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1.48145048377459, 0.4705], [1.5542375684543779, 0.4481])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(ds_train.batch(64)), model2.evaluate(ds_test.batch(64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We have 43% (41%) accuracy on train (test) dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T18:17:24.526823Z",
     "start_time": "2020-04-09T18:17:24.492107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 6)         168       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 32, 32, 6)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 6)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               196736    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 198,194\n",
      "Trainable params: 198,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Convolution2D, ReLU, MaxPooling2D\n",
    "\n",
    "# Lets start with very poor convolutional network\n",
    "model_cnn = Sequential([\n",
    "    Convolution2D(filters=6, kernel_size=(3,3), padding='same', input_shape=(32,32,3)),\n",
    "    ReLU(),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10) # no more softmax activation\n",
    "])\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:37:53.049522Z",
     "start_time": "2020-04-09T17:37:53.010268Z"
    }
   },
   "outputs": [],
   "source": [
    "model_cnn.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:39:17.253439Z",
     "start_time": "2020-04-09T17:37:53.050531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3125/3125 [==============================] - 10s 3ms/step - loss: 1.5026 - accuracy: 0.4649 - val_loss: 1.3326 - val_accuracy: 0.5195\n",
      "Epoch 2/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.2612 - accuracy: 0.5539 - val_loss: 1.2675 - val_accuracy: 0.5508\n",
      "Epoch 3/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.1595 - accuracy: 0.5905 - val_loss: 1.2391 - val_accuracy: 0.5618\n",
      "Epoch 4/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.0829 - accuracy: 0.6189 - val_loss: 1.2250 - val_accuracy: 0.5742\n",
      "Epoch 5/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 1.0220 - accuracy: 0.6411 - val_loss: 1.2286 - val_accuracy: 0.5772\n",
      "Epoch 6/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 0.9703 - accuracy: 0.6592 - val_loss: 1.2194 - val_accuracy: 0.5835\n",
      "Epoch 7/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 0.9215 - accuracy: 0.6777 - val_loss: 1.2311 - val_accuracy: 0.5860\n",
      "Epoch 8/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 0.8776 - accuracy: 0.6936 - val_loss: 1.2485 - val_accuracy: 0.5906\n",
      "Epoch 9/100\n",
      "3109/3125 [============================>.] - ETA: 0s - loss: 0.8389 - accuracy: 0.7061\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "3125/3125 [==============================] - 8s 2ms/step - loss: 0.8381 - accuracy: 0.7066 - val_loss: 1.2744 - val_accuracy: 0.5871\n",
      "Epoch 10/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 0.7312 - accuracy: 0.7444 - val_loss: 1.2305 - val_accuracy: 0.5966\n",
      "Epoch 11/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 0.7082 - accuracy: 0.7534 - val_loss: 1.2326 - val_accuracy: 0.5987\n",
      "Epoch 00011: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc10420df10>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', verbose=1, patience=5)\n",
    "tensorboard = TensorBoard('logs/cnn-model')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', verbose=1, patience=3)\n",
    "model_checkpoint = ModelCheckpoint('model_cnn.h5', save_best_only=True)\n",
    "\n",
    "model_cnn.fit(\n",
    "    ds_train.batch(16), epochs=100, validation_data=ds_test.batch(64),\n",
    "    callbacks=[early_stopping, tensorboard, reduce_lr, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We have 75% (60%) accuracy on train (test) dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MLP (dense) model is not good a~choice for images\n",
    "* CNN is usually much better feature extractor\n",
    "* Be carefull with overfitting - one can observe that training loss became smaller and smaller quite fast; however validation loss didn't decrease - that's why we used **early stopping**\n",
    "* Our CNN was very poor - try with more filters and more conv layers"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "373.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
