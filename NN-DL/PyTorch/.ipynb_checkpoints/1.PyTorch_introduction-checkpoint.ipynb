{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Random matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5674, 0.0123, 0.7586],\n",
       "        [0.8574, 0.8623, 0.0655],\n",
       "        [0.1519, 0.0093, 0.9814],\n",
       "        [0.7849, 0.2955, 0.0602],\n",
       "        [0.9725, 0.2970, 0.5397]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(5, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Zero matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(5, 3, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.5000, 3.0000])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([5.5, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "\n",
    "x.new_ones(5, 3, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0420, -0.6931])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn_like(x, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5454, 1.3203, 1.3691, 0.4068],\n",
       "        [0.3580, 0.6525, 1.6004, 1.3519]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2, 4)\n",
    "y = torch.rand(2, 4)\n",
    "\n",
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5454, 1.3203, 1.3691, 0.4068],\n",
       "        [0.3580, 0.6525, 1.6004, 1.3519]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.add(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5454, 1.3203, 1.3691, 0.4068],\n",
       "        [0.3580, 0.6525, 1.6004, 1.3519]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5454, 1.3203, 1.3691, 0.4068],\n",
       "        [0.3580, 0.6525, 1.6004, 1.3519]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5454, 1.3203, 1.3691, 0.4068],\n",
       "        [0.3580, 0.6525, 1.6004, 1.3519]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add in place\n",
    "\n",
    "x.add_(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5454, 1.3203, 1.3691, 0.4068],\n",
       "        [0.3580, 0.6525, 1.6004, 1.3519]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Resize tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16) # 1D arr\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Tensor to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([124., 124., 124., 124., 124.])\n",
      "[124. 124. 124. 124. 124.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(123)\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 Numpy to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 3. 3. 3. 3.]\n",
      "tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "\n",
    "np.add(a, 1, out=a)\n",
    "a += 1\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9 CUDA Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.9004,  1.2853,  0.4679,  0.9145],\n",
      "        [ 2.1668,  1.8665,  0.5706,  0.4936],\n",
      "        [ 1.6633,  1.7613, -0.6835,  1.7846],\n",
      "        [ 1.3760,  3.0645,  1.2138,  2.8116]], device='cuda:0')\n",
      "tensor([[ 2.9004,  1.2853,  0.4679,  0.9145],\n",
      "        [ 2.1668,  1.8665,  0.5706,  0.4936],\n",
      "        [ 1.6633,  1.7613, -0.6835,  1.7846],\n",
      "        [ 1.3760,  3.0645,  1.2138,  2.8116]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. AUTOGRAD: AUTOMATIC DIFFERENTIATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], requires_grad=True)\n",
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 3, requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3., grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<SumBackward0 object at 0x000001F402595588>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad)\n",
    "\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.9102, grad_fn=<SumBackward0>) <SumBackward0 object at 0x000001F402595128>\n",
      "tensor(11.9102, grad_fn=<SumBackward0>) <SumBackward0 object at 0x000001F40256A908>\n"
     ]
    }
   ],
   "source": [
    "print(b, b.grad_fn)\n",
    "b.backward()\n",
    "print(b, b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-994.6222, -212.4204,  647.2190], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "y.backward(v)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=1024, out_features=200, bias=True)\n",
      "  (fc2): Linear(in_features=200, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # an affine operations: y = Wx + b\n",
    "        self.fc1 = nn.Linear(32 * 32, 200)\n",
    "        self.fc2 = nn.Linear(200, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x.shape => BATCH_SIZE x Height X Width \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x \n",
    "    \n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_with_sequential(\n",
      "  (dense_layers): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net_with_sequential(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net_with_sequential, self).__init__()\n",
    "        # an affine operations: y = Wx + b\n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Linear(32 * 32, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 10),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.dense_layers(x)\n",
    "        return x \n",
    "    \n",
    "\n",
    "net_ws = Net_with_sequential()\n",
    "on_GPU=net_ws.to(device)\n",
    "print(net_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1145, -0.1046, -0.1944,  0.0630, -0.0267, -0.0982,  0.1126,  0.0141,\n",
      "          0.0173, -0.0250]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "IN = torch.rand(1, 1, 32, 32)\n",
    "out = net(IN)\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1145, -0.1046, -0.1944,  0.0630, -0.0267, -0.0982,  0.1126,  0.0141,\n",
      "          0.0173, -0.0250]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "#  Zero the gradient buffers of all parameters and backprops with random gradients:\n",
    "\n",
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3684, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = net(IN)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "fc1.bias.grad after backward\n",
      "tensor([-8.9673e-03,  0.0000e+00,  1.2916e-02,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  3.7128e-02, -2.5175e-02,  0.0000e+00,  0.0000e+00,\n",
      "        -4.2075e-02,  0.0000e+00,  0.0000e+00, -2.1234e-03,  0.0000e+00,\n",
      "         0.0000e+00, -6.0958e-03,  0.0000e+00,  0.0000e+00, -1.7580e-02,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -7.2036e-03,  0.0000e+00,\n",
      "        -4.9953e-02,  0.0000e+00,  5.0366e-02,  2.0652e-02,  0.0000e+00,\n",
      "         0.0000e+00,  6.7017e-03, -9.4575e-03,  0.0000e+00, -1.5930e-02,\n",
      "         4.1331e-03,  2.6466e-02, -3.2657e-02,  9.5878e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  4.4905e-02,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  3.3797e-02,  1.7420e-02,\n",
      "        -1.9951e-02, -2.0487e-02,  0.0000e+00,  3.9089e-02,  2.3967e-02,\n",
      "         3.3704e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0834e-02,\n",
      "        -3.1132e-02, -1.4787e-02,  0.0000e+00,  1.5123e-02,  0.0000e+00,\n",
      "         8.9911e-03,  0.0000e+00,  1.8374e-02,  4.6232e-02,  0.0000e+00,\n",
      "         5.7044e-03,  1.6554e-02, -3.0829e-02,  0.0000e+00, -1.9666e-02,\n",
      "         0.0000e+00, -5.2359e-02,  0.0000e+00,  1.8982e-03,  7.5384e-02,\n",
      "        -9.2490e-03, -2.4392e-02,  0.0000e+00,  9.7653e-03,  2.3031e-03,\n",
      "         3.6711e-02,  7.7825e-02,  2.7499e-03,  1.3692e-03,  0.0000e+00,\n",
      "        -3.1612e-02,  0.0000e+00, -2.1038e-02,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  2.4634e-02,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -5.8131e-02,  0.0000e+00,  4.6697e-04,\n",
      "         0.0000e+00, -1.6962e-02, -3.7201e-02,  0.0000e+00,  2.9476e-02,\n",
      "         0.0000e+00,  1.7158e-02, -6.9419e-03,  0.0000e+00, -3.3024e-02,\n",
      "         0.0000e+00,  5.3490e-03,  0.0000e+00, -1.8484e-02, -6.1038e-03,\n",
      "         2.8738e-03,  0.0000e+00, -1.2683e-02,  0.0000e+00, -2.7452e-02,\n",
      "         0.0000e+00,  2.3078e-02,  5.3299e-03,  4.5728e-03,  0.0000e+00,\n",
      "        -4.4725e-03,  6.9128e-03, -6.5334e-02,  1.2939e-04, -2.4210e-02,\n",
      "         2.4945e-02,  0.0000e+00,  8.3865e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -1.2695e-02,  0.0000e+00,  5.6617e-02,\n",
      "         0.0000e+00, -1.9913e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         3.7746e-02, -1.5824e-03,  4.5337e-02,  1.5951e-02,  0.0000e+00,\n",
      "        -1.9429e-02, -7.9167e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         1.0756e-02, -1.9923e-02,  0.0000e+00,  0.0000e+00, -3.7023e-02,\n",
      "         0.0000e+00,  4.2653e-03,  0.0000e+00,  1.7800e-02, -2.3306e-02,\n",
      "        -1.1934e-02,  1.6597e-02, -3.7589e-02,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  1.5773e-02,  3.2944e-02, -7.3102e-06,  0.0000e+00,\n",
      "         0.0000e+00,  2.5715e-02,  0.0000e+00,  0.0000e+00, -2.7462e-02,\n",
      "         2.3639e-02,  0.0000e+00,  0.0000e+00,  2.0460e-02,  4.6822e-02,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -5.9936e-02,\n",
      "         0.0000e+00,  2.5215e-02, -3.9607e-02,  0.0000e+00, -1.0390e-02])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('fc1.bias.grad before backward')\n",
    "print(net.fc1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('fc1.bias.grad after backward')\n",
    "print(net.fc1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Update the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(IN)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_len: 8192\n",
      "{'image': tensor([[1., 1., 0., 0., 0., 1., 1., 0., 0., 1.],\n",
      "        [0., 1., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 1., 1., 1., 1.],\n",
      "        [0., 1., 1., 0., 0., 1., 1., 1., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 1., 1., 1., 0., 1.],\n",
      "        [1., 0., 1., 0., 1., 1., 1., 0., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 1., 0., 1., 1., 0., 0.]]), 'label': tensor(1.)}\n",
      "looping sucesfull\n"
     ]
    }
   ],
   "source": [
    "PICTURE_SIZE = 10\n",
    "\n",
    "class SimpleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, size):\n",
    "        self.data = torch.zeros(size, PICTURE_SIZE, PICTURE_SIZE)\n",
    "        self.data[torch.rand_like(self.data) > 0.5] = 1.\n",
    "        \n",
    "        self.labels = torch.zeros(size)\n",
    "        self.labels[self.data.mean(dim=[1,2]) > 0.5] = 1.\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        # Accepts scalars, tuples and dictionaries\n",
    "        return {\n",
    "                'image': self.data[item],\n",
    "                'label': self.labels[item]\n",
    "        }\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "dataset = SimpleDataset(2**13)\n",
    "# __len__\n",
    "print('dataset_len:', len(dataset))\n",
    "\n",
    "# __getitem__\n",
    "print(dataset[15])\n",
    "\n",
    "for x in dataset:\n",
    "    pass\n",
    "print('looping sucesfull')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 800\n",
    "\n",
    "class CustomDenseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomDenseNetwork, self).__init__()\n",
    "        self.hidden = nn.Sequential(\n",
    "                nn.Linear(PICTURE_SIZE * PICTURE_SIZE, HIDDEN_SIZE),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(HIDDEN_SIZE, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, PICTURE_SIZE * PICTURE_SIZE)\n",
    "        x = self.hidden(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 14848) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    762\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\multiprocessing\\queues.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    104\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-4b552277e1db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mloss_avg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0macc_avg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[1;31m# Start with zeroing .grad fields in model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    839\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    806\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 808\u001b[1;33m                 \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    809\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    772\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 774\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    775\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 14848) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "\n",
    "# Move model weigths to device\n",
    "device = ('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "net = CustomDenseNetwork().to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.005)\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    loss_avg = 0.\n",
    "    acc_avg = 0.\n",
    "    for i, batch_data in enumerate(dataloader):\n",
    "        # Start with zeroing .grad fields in model\n",
    "        net.zero_grad()\n",
    "        \n",
    "        # Move data to device\n",
    "        images = batch_data['image'].to(device)\n",
    "        labels = batch_data['label'].to(device)\n",
    "        \n",
    "        #Run neural net\n",
    "        out = net(images)\n",
    "\n",
    "        #Compute loss and apply autograd for model parameters\n",
    "        loss = ((out.view(-1) - labels)** 2).mean()\n",
    "        loss.backward()\n",
    "        \n",
    "        #Update network weigths\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistics generation\n",
    "        res = torch.where(\n",
    "                out.view(-1) > 0.5,\n",
    "                torch.tensor(1., device=device),\n",
    "                torch.tensor(0., device=device)\n",
    "        )\n",
    "        acc = (res == labels).sum()\n",
    "        loss_avg += loss\n",
    "        acc_avg += acc\n",
    "        if i % 30 == 0 and i != 0:\n",
    "            print(f'epoch:{e + 1:2d} step: {(i):3d} loss: {loss_avg / 30:.3f} acc: {acc_avg / (BATCH_SIZE * 30):.3f}')\n",
    "            acc_avg = 0.\n",
    "            loss_avg = 0.\n",
    "        # End of statistics generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.ProTip: mnist InMemDataLoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InMemDataLoader(object):\n",
    "    __initialized = False\n",
    "    def __init__(self, tensors, batch_size=1, shuffle=False, sampler=None,\n",
    "                 batch_sampler=None, drop_last=False):\n",
    "        \"\"\"A torch dataloader that fetches data from memory.\"\"\"\n",
    "        tensors = [torch.tensor(tensor) for tensor in tensors]\n",
    "        dataset = torch.utils.data.TensorDataset(*tensors)\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.drop_last = drop_last\n",
    "        \n",
    "        if batch_sampler is not None:\n",
    "            if batch_size > 1 or shuffle or sampler is not None or drop_last:\n",
    "                raise ValueError('batch_sampler option is mutually exclusive '\n",
    "                                 'with batch_size, shuffle, sampler, and '\n",
    "                                 'drop_last')\n",
    "            self.batch_size = None\n",
    "            self.drop_last = None\n",
    "\n",
    "        if sampler is not None and shuffle:\n",
    "            raise ValueError('sampler option is mutually exclusive with '\n",
    "                             'shuffle')\n",
    "            \n",
    "        if batch_sampler is None:\n",
    "            if sampler is None:\n",
    "                if shuffle:\n",
    "                    sampler = torch.utils.data.RandomSampler(dataset)\n",
    "                else:\n",
    "                    sampler = torch.utils.data.SequentialSampler(dataset)\n",
    "            batch_sampler = torch.utils.data.BatchSampler(sampler, batch_size, drop_last)\n",
    "\n",
    "        self.sampler = sampler\n",
    "        self.batch_sampler = batch_sampler\n",
    "        self.__initialized = True\n",
    "    \n",
    "    def __setattr__(self, attr, val):\n",
    "        if self.__initialized and attr in ('batch_size', 'sampler', 'drop_last'):\n",
    "            raise ValueError('{} attribute should not be set after {} is '\n",
    "                             'initialized'.format(attr, self.__class__.__name__))\n",
    "\n",
    "        super(InMemDataLoader, self).__setattr__(attr, val)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch_indices in self.batch_sampler:\n",
    "            yield self.dataset[batch_indices]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batch_sampler)\n",
    "    \n",
    "    def to(self, device):\n",
    "        self.dataset.tensors = tuple(t.to(device) for t in self.dataset.tensors)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'[' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\febrin\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"c:\\users\\febrin\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Febrin\\AppData\\Local\\Programs\\Python\\Python37\\Scripts\\gdown.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"c:\\users\\febrin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\gdown\\cli.py\", line 66, in main\n",
      "    download(url=url, output=args.output, quiet=args.quiet)\n",
      "  File \"c:\\users\\febrin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\gdown\\download.py\", line 50, in download\n",
      "    res = sess.get(url, stream=True)\n",
      "  File \"c:\\users\\febrin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\requests\\sessions.py\", line 546, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"c:\\users\\febrin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\requests\\sessions.py\", line 533, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\users\\febrin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\requests\\sessions.py\", line 640, in send\n",
      "    adapter = self.get_adapter(url=request.url)\n",
      "  File \"c:\\users\\febrin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\requests\\sessions.py\", line 731, in get_adapter\n",
      "    raise InvalidSchema(\"No connection adapters were found for '%s'\" % url)\n",
      "requests.exceptions.InvalidSchema: No connection adapters were found for ''https://drive.google.com/uc?id=1QPaC3IKB_5tX6yIZgRgkpcqFrfVqPTXU''\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'mnist.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-bd15593cca78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#Extracting data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mnist.npz'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mmnist_full_train_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train_data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mnist.npz'"
     ]
    }
   ],
   "source": [
    "##### HOW TO USE! ###\n",
    "# Download raw data\n",
    "# !command runs shell command in jupyter notebook\n",
    "!pip install -q gdown httpimport\n",
    "![ -e mnist.npz ] || gdown 'https://drive.google.com/uc?id=1QPaC3IKB_5tX6yIZgRgkpcqFrfVqPTXU' -O mnist.npz\n",
    "\n",
    "#Extracting data\n",
    "with np.load('mnist.npz') as data:\n",
    "    mnist_full_train_data = data['train_data'].astype('float32') / 255.0\n",
    "\n",
    "\n",
    "#Fast loader initialziation\n",
    "train_loader = InMemDataLoader(\n",
    "    (mnist_full_train_data, ), batch_size=25, shuffle=True)\n",
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
