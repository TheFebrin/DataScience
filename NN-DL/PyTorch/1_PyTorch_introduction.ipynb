{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "1.PyTorch_introduction.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdT7pLyCt-33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZdPGafnt-36",
        "colab_type": "text"
      },
      "source": [
        "# 1. Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNymsbfft-37",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Random matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Pn8XeGLt-37",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "2e47753b-26f4-4c92-9bf5-ec327d47bc28"
      },
      "source": [
        "torch.rand(5, 3)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0750, 0.8932, 0.8225],\n",
              "        [0.2799, 0.9963, 0.1660],\n",
              "        [0.9836, 0.5259, 0.4346],\n",
              "        [0.1090, 0.9594, 0.1183],\n",
              "        [0.7944, 0.4027, 0.4745]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCxVlfZRt-3-",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 Zero matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CSvEX7et-3_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8ce2ec1a-f6ec-4db2-8447-7670e36f8985"
      },
      "source": [
        "torch.zeros(5, 3, dtype=torch.long)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JC3goadt-4B",
        "colab_type": "text"
      },
      "source": [
        "### 1.3 Tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp9Nt78Dt-4B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09d2f8d9-0a3d-49d9-f653-a0e8c6b756e7"
      },
      "source": [
        "torch.tensor([5.5, 3])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5.5000, 3.0000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4I69vWyt-4E",
        "colab_type": "text"
      },
      "source": [
        "### 1.4 Overwrite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHllg79_t-4E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "19062844-7fda-4767-9c52-31440f78ca4f"
      },
      "source": [
        "x = torch.tensor([5.5, 3])\n",
        "\n",
        "x.new_ones(5, 3, dtype=torch.double)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82k6UibEt-4G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0b78e2d-bb0f-47a1-edcb-423208822e97"
      },
      "source": [
        "torch.randn_like(x, dtype=torch.float)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.2281, -0.5443])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bX9sBd47t-4J",
        "colab_type": "text"
      },
      "source": [
        "### 1.5 Add"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwf8PwSRt-4J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f97ac6ac-c1a9-4c23-dc0e-365b37805ae0"
      },
      "source": [
        "x = torch.rand(2, 4)\n",
        "y = torch.rand(2, 4)\n",
        "\n",
        "x + y"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.3276, 0.7671, 1.1726, 1.0645],\n",
              "        [1.1546, 1.1523, 0.4990, 1.0558]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9NnTC4ft-4M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0e196c74-e2a8-4ff3-f546-71b790034c43"
      },
      "source": [
        "x.add(y)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.3276, 0.7671, 1.1726, 1.0645],\n",
              "        [1.1546, 1.1523, 0.4990, 1.0558]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRHWDcCct-4N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ed4dc7f7-e2c7-4460-dd19-c0ccc21fc4b8"
      },
      "source": [
        "torch.add(x, y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.3276, 0.7671, 1.1726, 1.0645],\n",
              "        [1.1546, 1.1523, 0.4990, 1.0558]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLj8SQsFt-4P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ab0563d3-cb6f-4e70-e7ad-3191c78f6309"
      },
      "source": [
        "result = torch.empty(5, 3)\n",
        "torch.add(x, y, out=result)\n",
        "\n",
        "result"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.3276, 0.7671, 1.1726, 1.0645],\n",
              "        [1.1546, 1.1523, 0.4990, 1.0558]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_FpqjoAt-4S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3cf7c21c-1ea0-4586-cf2d-7e628d531ea6"
      },
      "source": [
        "# add in place\n",
        "\n",
        "x.add_(y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.3276, 0.7671, 1.1726, 1.0645],\n",
              "        [1.1546, 1.1523, 0.4990, 1.0558]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al-H6JMNt-4V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "264b4d0e-1ce7-4f52-cd3e-4927ecd18bdc"
      },
      "source": [
        "x"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.3276, 0.7671, 1.1726, 1.0645],\n",
              "        [1.1546, 1.1523, 0.4990, 1.0558]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gJyXSVZt-4X",
        "colab_type": "text"
      },
      "source": [
        "### 1.6 Resize tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zJikZgct-4X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fbbf3450-c5e5-42a6-9793-65864434bd9e"
      },
      "source": [
        "x = torch.randn(4, 4)\n",
        "y = x.view(16) # 1D arr\n",
        "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
        "\n",
        "print(x.size(), y.size(), z.size())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqO_79u4t-4Z",
        "colab_type": "text"
      },
      "source": [
        "### 1.7 Tensor to numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWszYu5zt-4Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a9baa857-f35f-4f98-be48-cc970d32baba"
      },
      "source": [
        "a = torch.ones(5)\n",
        "b = a.numpy()\n",
        "\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlkXA6vAt-4b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d8d35b80-fe62-4d33-968a-284b00fb582a"
      },
      "source": [
        "a.add_(123)\n",
        "\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([124., 124., 124., 124., 124.])\n",
            "[124. 124. 124. 124. 124.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x_07dzbt-4d",
        "colab_type": "text"
      },
      "source": [
        "### 1.8 Numpy to tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eueloXN0t-4e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cdf0f817-7ec3-431a-b844-28e13f262526"
      },
      "source": [
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "\n",
        "np.add(a, 1, out=a)\n",
        "a += 1\n",
        "\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3. 3. 3. 3. 3.]\n",
            "tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEQKnzJSt-4g",
        "colab_type": "text"
      },
      "source": [
        "### 1.9 CUDA Tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw7yOkrNt-4g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "1f4b1e59-1cec-4768-d0ac-e97b64e8d6fd"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    print(z)\n",
        "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.8563, -0.3412, -0.2331, -0.3536],\n",
            "        [ 1.3282,  0.6738, -0.5558,  0.1061],\n",
            "        [ 2.9679,  1.4826,  2.3489, -0.3947],\n",
            "        [ 0.5042, -0.0970,  0.8650, -0.5044]], device='cuda:0')\n",
            "tensor([[ 0.8563, -0.3412, -0.2331, -0.3536],\n",
            "        [ 1.3282,  0.6738, -0.5558,  0.1061],\n",
            "        [ 2.9679,  1.4826,  2.3489, -0.3947],\n",
            "        [ 0.5042, -0.0970,  0.8650, -0.5044]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocNMHbZjt-4i",
        "colab_type": "text"
      },
      "source": [
        "# 2. AUTOGRAD: AUTOMATIC DIFFERENTIATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bm5DCsXGt-4i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f46b7004-5296-4516-cc24-121ce8928483"
      },
      "source": [
        "x = torch.ones(2, 3, requires_grad=True)\n",
        "print(x)\n",
        "\n",
        "y = x + 2\n",
        "print(y)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]], requires_grad=True)\n",
            "tensor([[3., 3., 3.],\n",
            "        [3., 3., 3.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6i0Wd_Wt-4k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f52c5640-35de-4d1d-c852-afae0173b0d9"
      },
      "source": [
        "y.mean()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3., grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTn0u3Vpt-4m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c4272ade-1a7f-4e6e-8987-68fd31dcf15c"
      },
      "source": [
        "a = torch.randn(2, 2)\n",
        "a = ((a * 3) / (a - 1))\n",
        "print(a.requires_grad)\n",
        "\n",
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n",
        "\n",
        "b = (a * a).sum()\n",
        "print(b.grad_fn)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n",
            "<SumBackward0 object at 0x7f9f10896ac8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9R37YdUt-4n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "02b723db-4d3e-4a86-c36b-63ee4e596651"
      },
      "source": [
        "print(b, b.grad_fn)\n",
        "b.backward()\n",
        "print(b, b.grad_fn)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(524.1561, grad_fn=<SumBackward0>) <SumBackward0 object at 0x7f9f10896550>\n",
            "tensor(524.1561, grad_fn=<SumBackward0>) <SumBackward0 object at 0x7f9f10896550>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdSzDvF-t-4p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f15fab53-3e5f-41ac-80d1-3fa77137506b"
      },
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "while y.data.norm() < 1000:\n",
        "    y = y * 2\n",
        "\n",
        "print(y)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-356.0541, -326.8693, -992.3766], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TweGNwx7t-4r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d98efbe3-21ea-4b79-a0cd-84fcd5ff3ffb"
      },
      "source": [
        "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
        "y.backward(v)\n",
        "\n",
        "print(x.grad)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5.1200e+01, 5.1200e+02, 5.1200e-02])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi3n59FRt-4t",
        "colab_type": "text"
      },
      "source": [
        "# 3. Neural net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwFp_B-it-4u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b52d0adb-0573-4a15-f8b6-08a49d835a3c"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # an affine operations: y = Wx + b\n",
        "        self.fc1 = nn.Linear(32 * 32, 200)\n",
        "        self.fc2 = nn.Linear(200, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # x.shape => BATCH_SIZE x Height X Width \n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x \n",
        "    \n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=1024, out_features=200, bias=True)\n",
            "  (fc2): Linear(in_features=200, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cOXCVl4t-4v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "a699f2b0-40ff-4852-9fc2-527ec44cd23c"
      },
      "source": [
        "class Net_with_sequential(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net_with_sequential, self).__init__()\n",
        "        # an affine operations: y = Wx + b\n",
        "        self.dense_layers = nn.Sequential(\n",
        "            nn.Linear(32 * 32, 200),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(200, 10),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.dense_layers(x)\n",
        "        return x \n",
        "    \n",
        "\n",
        "net_ws = Net_with_sequential()\n",
        "on_GPU=net_ws.to(device)\n",
        "print(net_ws)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net_with_sequential(\n",
            "  (dense_layers): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=200, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQBIdnDvt-4z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6575a581-19f4-410e-aed8-06a42dab771a"
      },
      "source": [
        "IN = torch.rand(1, 1, 32, 32)\n",
        "out = net(IN)\n",
        "\n",
        "print(out)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.3463, -0.2621, -0.0353, -0.1105, -0.1398,  0.1535, -0.0291, -0.1528,\n",
            "         -0.1935,  0.2155]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-1isyc-t-41",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ae034629-fdfa-4da9-846c-8c948df88b18"
      },
      "source": [
        "#  Zero the gradient buffers of all parameters and backprops with random gradients:\n",
        "\n",
        "net.zero_grad()\n",
        "out.backward(torch.randn(1, 10))\n",
        "\n",
        "print(out)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.3463, -0.2621, -0.0353, -0.1105, -0.1398,  0.1535, -0.0291, -0.1528,\n",
            "         -0.1935,  0.2155]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVoW232wt-43",
        "colab_type": "text"
      },
      "source": [
        "# 4. Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDjhATvlt-44",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0df12b9d-a763-44ea-8cf5-8c374e8167e5"
      },
      "source": [
        "output = net(IN)\n",
        "target = torch.randn(10)  # a dummy target, for example\n",
        "target = target.view(1, -1)  # make it the same shape as output\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "loss = criterion(output, target)\n",
        "print(loss)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.5335, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWNhhAIvt-46",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "05bb4a7b-6000-4a1d-8eb7-96f2f1404375"
      },
      "source": [
        "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
        "\n",
        "print('fc1.bias.grad before backward')\n",
        "print(net.fc1.bias.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('fc1.bias.grad after backward')\n",
        "print(net.fc1.bias.grad)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fc1.bias.grad before backward\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "fc1.bias.grad after backward\n",
            "tensor([ 0.0020,  0.0000,  0.0078,  0.0000,  0.0000,  0.0000,  0.0171, -0.0223,\n",
            "         0.0000, -0.0266,  0.0000,  0.0000,  0.0000, -0.0171,  0.0000,  0.0048,\n",
            "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0087,  0.0030,\n",
            "        -0.0166, -0.0070,  0.0000, -0.0231, -0.0179,  0.0000, -0.0253, -0.0042,\n",
            "         0.0118, -0.0075, -0.0023,  0.0033,  0.0000,  0.0017,  0.0000,  0.0026,\n",
            "         0.0000, -0.0168, -0.0019, -0.0173,  0.0081,  0.0000,  0.0000, -0.0141,\n",
            "        -0.0145,  0.0308,  0.0048,  0.0216, -0.0307, -0.0003,  0.0000,  0.0000,\n",
            "         0.0247,  0.0000,  0.0052, -0.0349, -0.0191,  0.0000, -0.0279, -0.0091,\n",
            "         0.0000,  0.0172,  0.0000,  0.0000, -0.0234,  0.0000,  0.0033,  0.0000,\n",
            "        -0.0458,  0.0000,  0.0000, -0.0083, -0.0240,  0.0000,  0.0240,  0.0000,\n",
            "         0.0000, -0.0364, -0.0055,  0.0000, -0.0180,  0.0000, -0.0134,  0.0000,\n",
            "         0.0000,  0.0000,  0.0000,  0.0146,  0.0000,  0.0069,  0.0000,  0.0000,\n",
            "        -0.0201,  0.0000,  0.0000,  0.0097, -0.0280,  0.0000,  0.0000, -0.0346,\n",
            "         0.0000,  0.0000, -0.0029,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         0.0000, -0.0128, -0.0297, -0.0277,  0.0000, -0.0054, -0.0018,  0.0000,\n",
            "         0.0000,  0.0106,  0.0237,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "        -0.0175, -0.0027,  0.0151,  0.0009,  0.0000,  0.0000,  0.0000,  0.0075,\n",
            "        -0.0001,  0.0132, -0.0049,  0.0316, -0.0170,  0.0000,  0.0000,  0.0017,\n",
            "         0.0080,  0.0000, -0.0062,  0.0202,  0.0000, -0.0298,  0.0000,  0.0000,\n",
            "         0.0000,  0.0000, -0.0007, -0.0133,  0.0192, -0.0007,  0.0000, -0.0153,\n",
            "        -0.0309, -0.0238, -0.0099,  0.0000, -0.0156,  0.0334,  0.0233,  0.0000,\n",
            "         0.0273,  0.0000,  0.0000, -0.0196,  0.0000,  0.0154,  0.0003, -0.0044,\n",
            "         0.0000,  0.0053, -0.0090, -0.0010,  0.0000,  0.0000,  0.0000, -0.0065,\n",
            "        -0.0059, -0.0237,  0.0000, -0.0017, -0.0113,  0.0000,  0.0000,  0.0000,\n",
            "        -0.0095,  0.0000, -0.0293,  0.0000,  0.0000,  0.0000,  0.0205,  0.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgHqJSg_t-47",
        "colab_type": "text"
      },
      "source": [
        "# 5. Update the weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjDbBmXdt-48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# create your optimizer\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "# in your training loop:\n",
        "optimizer.zero_grad()   # zero the gradient buffers\n",
        "output = net(IN)\n",
        "loss = criterion(output, target)\n",
        "loss.backward()\n",
        "optimizer.step()    # Does the update"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGUqs5Srt-4-",
        "colab_type": "text"
      },
      "source": [
        "### 5.1 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgVC4UHxt-4-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "1dd1c170-a3ce-4409-d741-37d8e79cd3e5"
      },
      "source": [
        "PICTURE_SIZE = 10\n",
        "\n",
        "class SimpleDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, size):\n",
        "        self.data = torch.zeros(size, PICTURE_SIZE, PICTURE_SIZE)\n",
        "        self.data[torch.rand_like(self.data) > 0.5] = 1.\n",
        "        \n",
        "        self.labels = torch.zeros(size)\n",
        "        self.labels[self.data.mean(dim=[1,2]) > 0.5] = 1.\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        # Accepts scalars, tuples and dictionaries\n",
        "        return {\n",
        "                'image': self.data[item],\n",
        "                'label': self.labels[item]\n",
        "        }\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "dataset = SimpleDataset(2**13)\n",
        "# __len__\n",
        "print('dataset_len:', len(dataset))\n",
        "\n",
        "# __getitem__\n",
        "print(dataset[15])\n",
        "\n",
        "for x in dataset:\n",
        "    pass\n",
        "print('looping sucesfull')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset_len: 8192\n",
            "{'image': tensor([[0., 1., 1., 1., 0., 0., 1., 1., 1., 1.],\n",
            "        [1., 1., 0., 0., 0., 1., 1., 1., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 1., 1., 1., 0., 0., 1., 0.],\n",
            "        [0., 1., 1., 0., 1., 1., 1., 1., 0., 0.],\n",
            "        [0., 1., 0., 0., 1., 1., 0., 0., 1., 1.],\n",
            "        [0., 1., 0., 1., 1., 0., 0., 1., 1., 0.],\n",
            "        [1., 0., 1., 0., 1., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 1., 1., 0., 1., 1., 1.]]), 'label': tensor(1.)}\n",
            "looping sucesfull\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54qyPoqyt-5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8rCZgjyt-5B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HIDDEN_SIZE = 800\n",
        "\n",
        "class CustomDenseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomDenseNetwork, self).__init__()\n",
        "        self.hidden = nn.Sequential(\n",
        "                nn.Linear(PICTURE_SIZE * PICTURE_SIZE, HIDDEN_SIZE),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(HIDDEN_SIZE, 1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, PICTURE_SIZE * PICTURE_SIZE)\n",
        "        x = self.hidden(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwRwOpJBt-5D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7bbc646c-5ba5-4d9b-ad4b-112f48167bb8"
      },
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "# Move model weigths to device\n",
        "device = ('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "net = CustomDenseNetwork().to(device)\n",
        "\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.005)\n",
        "\n",
        "for e in range(EPOCHS):\n",
        "    loss_avg = 0.\n",
        "    acc_avg = 0.\n",
        "    for i, batch_data in enumerate(dataloader):\n",
        "        # Start with zeroing .grad fields in model\n",
        "        net.zero_grad()\n",
        "        \n",
        "        # Move data to device\n",
        "        images = batch_data['image'].to(device)\n",
        "        labels = batch_data['label'].to(device)\n",
        "        \n",
        "        #Run neural net\n",
        "        out = net(images)\n",
        "\n",
        "        #Compute loss and apply autograd for model parameters\n",
        "        loss = ((out.view(-1) - labels)** 2).mean()\n",
        "        loss.backward()\n",
        "        \n",
        "        #Update network weigths\n",
        "        optimizer.step()\n",
        "\n",
        "        # Statistics generation\n",
        "        res = torch.where(\n",
        "                out.view(-1) > 0.5,\n",
        "                torch.tensor(1., device=device),\n",
        "                torch.tensor(0., device=device)\n",
        "        )\n",
        "        acc = (res == labels).sum()\n",
        "        loss_avg += loss\n",
        "        acc_avg += acc\n",
        "        if i % 30 == 0 and i != 0:\n",
        "            print(f'epoch:{e + 1:2d} step: {(i):3d} loss: {loss_avg / 30:.3f} acc: {acc_avg / (BATCH_SIZE * 30):.3f}')\n",
        "            acc_avg = 0.\n",
        "            loss_avg = 0.\n",
        "        # End of statistics generation"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 step:  30 loss: 0.250 acc: 0.606\n",
            "epoch: 1 step:  60 loss: 0.232 acc: 0.608\n",
            "epoch: 1 step:  90 loss: 0.227 acc: 0.647\n",
            "epoch: 1 step: 120 loss: 0.217 acc: 0.659\n",
            "epoch: 1 step: 150 loss: 0.216 acc: 0.667\n",
            "epoch: 1 step: 180 loss: 0.211 acc: 0.684\n",
            "epoch: 1 step: 210 loss: 0.207 acc: 0.713\n",
            "epoch: 1 step: 240 loss: 0.195 acc: 0.745\n",
            "epoch: 2 step:  30 loss: 0.199 acc: 0.788\n",
            "epoch: 2 step:  60 loss: 0.186 acc: 0.784\n",
            "epoch: 2 step:  90 loss: 0.192 acc: 0.767\n",
            "epoch: 2 step: 120 loss: 0.186 acc: 0.780\n",
            "epoch: 2 step: 150 loss: 0.183 acc: 0.791\n",
            "epoch: 2 step: 180 loss: 0.185 acc: 0.783\n",
            "epoch: 2 step: 210 loss: 0.173 acc: 0.816\n",
            "epoch: 2 step: 240 loss: 0.172 acc: 0.833\n",
            "epoch: 3 step:  30 loss: 0.172 acc: 0.856\n",
            "epoch: 3 step:  60 loss: 0.168 acc: 0.834\n",
            "epoch: 3 step:  90 loss: 0.165 acc: 0.831\n",
            "epoch: 3 step: 120 loss: 0.158 acc: 0.859\n",
            "epoch: 3 step: 150 loss: 0.156 acc: 0.846\n",
            "epoch: 3 step: 180 loss: 0.158 acc: 0.853\n",
            "epoch: 3 step: 210 loss: 0.156 acc: 0.854\n",
            "epoch: 3 step: 240 loss: 0.156 acc: 0.852\n",
            "epoch: 4 step:  30 loss: 0.157 acc: 0.900\n",
            "epoch: 4 step:  60 loss: 0.155 acc: 0.840\n",
            "epoch: 4 step:  90 loss: 0.140 acc: 0.885\n",
            "epoch: 4 step: 120 loss: 0.147 acc: 0.855\n",
            "epoch: 4 step: 150 loss: 0.140 acc: 0.872\n",
            "epoch: 4 step: 180 loss: 0.138 acc: 0.884\n",
            "epoch: 4 step: 210 loss: 0.140 acc: 0.864\n",
            "epoch: 4 step: 240 loss: 0.142 acc: 0.872\n",
            "epoch: 5 step:  30 loss: 0.140 acc: 0.921\n",
            "epoch: 5 step:  60 loss: 0.131 acc: 0.885\n",
            "epoch: 5 step:  90 loss: 0.132 acc: 0.894\n",
            "epoch: 5 step: 120 loss: 0.133 acc: 0.884\n",
            "epoch: 5 step: 150 loss: 0.129 acc: 0.895\n",
            "epoch: 5 step: 180 loss: 0.130 acc: 0.896\n",
            "epoch: 5 step: 210 loss: 0.129 acc: 0.888\n",
            "epoch: 5 step: 240 loss: 0.127 acc: 0.893\n",
            "epoch: 6 step:  30 loss: 0.130 acc: 0.932\n",
            "epoch: 6 step:  60 loss: 0.119 acc: 0.903\n",
            "epoch: 6 step:  90 loss: 0.124 acc: 0.895\n",
            "epoch: 6 step: 120 loss: 0.118 acc: 0.905\n",
            "epoch: 6 step: 150 loss: 0.122 acc: 0.884\n",
            "epoch: 6 step: 180 loss: 0.121 acc: 0.896\n",
            "epoch: 6 step: 210 loss: 0.119 acc: 0.900\n",
            "epoch: 6 step: 240 loss: 0.120 acc: 0.900\n",
            "epoch: 7 step:  30 loss: 0.120 acc: 0.938\n",
            "epoch: 7 step:  60 loss: 0.111 acc: 0.921\n",
            "epoch: 7 step:  90 loss: 0.115 acc: 0.899\n",
            "epoch: 7 step: 120 loss: 0.110 acc: 0.910\n",
            "epoch: 7 step: 150 loss: 0.120 acc: 0.884\n",
            "epoch: 7 step: 180 loss: 0.113 acc: 0.893\n",
            "epoch: 7 step: 210 loss: 0.107 acc: 0.915\n",
            "epoch: 7 step: 240 loss: 0.110 acc: 0.903\n",
            "epoch: 8 step:  30 loss: 0.114 acc: 0.936\n",
            "epoch: 8 step:  60 loss: 0.111 acc: 0.915\n",
            "epoch: 8 step:  90 loss: 0.108 acc: 0.909\n",
            "epoch: 8 step: 120 loss: 0.114 acc: 0.891\n",
            "epoch: 8 step: 150 loss: 0.102 acc: 0.923\n",
            "epoch: 8 step: 180 loss: 0.110 acc: 0.898\n",
            "epoch: 8 step: 210 loss: 0.106 acc: 0.915\n",
            "epoch: 8 step: 240 loss: 0.101 acc: 0.920\n",
            "epoch: 9 step:  30 loss: 0.108 acc: 0.943\n",
            "epoch: 9 step:  60 loss: 0.110 acc: 0.911\n",
            "epoch: 9 step:  90 loss: 0.100 acc: 0.928\n",
            "epoch: 9 step: 120 loss: 0.104 acc: 0.915\n",
            "epoch: 9 step: 150 loss: 0.098 acc: 0.931\n",
            "epoch: 9 step: 180 loss: 0.101 acc: 0.918\n",
            "epoch: 9 step: 210 loss: 0.104 acc: 0.919\n",
            "epoch: 9 step: 240 loss: 0.106 acc: 0.906\n",
            "epoch:10 step:  30 loss: 0.107 acc: 0.946\n",
            "epoch:10 step:  60 loss: 0.100 acc: 0.913\n",
            "epoch:10 step:  90 loss: 0.098 acc: 0.925\n",
            "epoch:10 step: 120 loss: 0.098 acc: 0.929\n",
            "epoch:10 step: 150 loss: 0.101 acc: 0.917\n",
            "epoch:10 step: 180 loss: 0.099 acc: 0.929\n",
            "epoch:10 step: 210 loss: 0.098 acc: 0.915\n",
            "epoch:10 step: 240 loss: 0.105 acc: 0.922\n",
            "epoch:11 step:  30 loss: 0.106 acc: 0.952\n",
            "epoch:11 step:  60 loss: 0.097 acc: 0.927\n",
            "epoch:11 step:  90 loss: 0.096 acc: 0.921\n",
            "epoch:11 step: 120 loss: 0.094 acc: 0.941\n",
            "epoch:11 step: 150 loss: 0.100 acc: 0.926\n",
            "epoch:11 step: 180 loss: 0.100 acc: 0.916\n",
            "epoch:11 step: 210 loss: 0.098 acc: 0.939\n",
            "epoch:11 step: 240 loss: 0.095 acc: 0.934\n",
            "epoch:12 step:  30 loss: 0.099 acc: 0.959\n",
            "epoch:12 step:  60 loss: 0.095 acc: 0.928\n",
            "epoch:12 step:  90 loss: 0.096 acc: 0.934\n",
            "epoch:12 step: 120 loss: 0.099 acc: 0.927\n",
            "epoch:12 step: 150 loss: 0.093 acc: 0.934\n",
            "epoch:12 step: 180 loss: 0.096 acc: 0.926\n",
            "epoch:12 step: 210 loss: 0.098 acc: 0.929\n",
            "epoch:12 step: 240 loss: 0.097 acc: 0.920\n",
            "epoch:13 step:  30 loss: 0.098 acc: 0.950\n",
            "epoch:13 step:  60 loss: 0.095 acc: 0.927\n",
            "epoch:13 step:  90 loss: 0.092 acc: 0.925\n",
            "epoch:13 step: 120 loss: 0.098 acc: 0.928\n",
            "epoch:13 step: 150 loss: 0.091 acc: 0.943\n",
            "epoch:13 step: 180 loss: 0.102 acc: 0.913\n",
            "epoch:13 step: 210 loss: 0.095 acc: 0.927\n",
            "epoch:13 step: 240 loss: 0.091 acc: 0.938\n",
            "epoch:14 step:  30 loss: 0.094 acc: 0.973\n",
            "epoch:14 step:  60 loss: 0.099 acc: 0.921\n",
            "epoch:14 step:  90 loss: 0.094 acc: 0.930\n",
            "epoch:14 step: 120 loss: 0.090 acc: 0.939\n",
            "epoch:14 step: 150 loss: 0.092 acc: 0.932\n",
            "epoch:14 step: 180 loss: 0.092 acc: 0.943\n",
            "epoch:14 step: 210 loss: 0.094 acc: 0.943\n",
            "epoch:14 step: 240 loss: 0.094 acc: 0.927\n",
            "epoch:15 step:  30 loss: 0.093 acc: 0.959\n",
            "epoch:15 step:  60 loss: 0.094 acc: 0.930\n",
            "epoch:15 step:  90 loss: 0.098 acc: 0.930\n",
            "epoch:15 step: 120 loss: 0.092 acc: 0.944\n",
            "epoch:15 step: 150 loss: 0.093 acc: 0.928\n",
            "epoch:15 step: 180 loss: 0.092 acc: 0.934\n",
            "epoch:15 step: 210 loss: 0.090 acc: 0.930\n",
            "epoch:15 step: 240 loss: 0.095 acc: 0.942\n",
            "epoch:16 step:  30 loss: 0.100 acc: 0.960\n",
            "epoch:16 step:  60 loss: 0.094 acc: 0.930\n",
            "epoch:16 step:  90 loss: 0.089 acc: 0.939\n",
            "epoch:16 step: 120 loss: 0.094 acc: 0.940\n",
            "epoch:16 step: 150 loss: 0.089 acc: 0.946\n",
            "epoch:16 step: 180 loss: 0.090 acc: 0.947\n",
            "epoch:16 step: 210 loss: 0.091 acc: 0.935\n",
            "epoch:16 step: 240 loss: 0.095 acc: 0.927\n",
            "epoch:17 step:  30 loss: 0.094 acc: 0.972\n",
            "epoch:17 step:  60 loss: 0.089 acc: 0.946\n",
            "epoch:17 step:  90 loss: 0.093 acc: 0.940\n",
            "epoch:17 step: 120 loss: 0.089 acc: 0.933\n",
            "epoch:17 step: 150 loss: 0.092 acc: 0.930\n",
            "epoch:17 step: 180 loss: 0.089 acc: 0.943\n",
            "epoch:17 step: 210 loss: 0.093 acc: 0.936\n",
            "epoch:17 step: 240 loss: 0.088 acc: 0.941\n",
            "epoch:18 step:  30 loss: 0.097 acc: 0.982\n",
            "epoch:18 step:  60 loss: 0.091 acc: 0.928\n",
            "epoch:18 step:  90 loss: 0.088 acc: 0.944\n",
            "epoch:18 step: 120 loss: 0.090 acc: 0.930\n",
            "epoch:18 step: 150 loss: 0.093 acc: 0.936\n",
            "epoch:18 step: 180 loss: 0.090 acc: 0.957\n",
            "epoch:18 step: 210 loss: 0.093 acc: 0.933\n",
            "epoch:18 step: 240 loss: 0.088 acc: 0.938\n",
            "epoch:19 step:  30 loss: 0.087 acc: 0.974\n",
            "epoch:19 step:  60 loss: 0.091 acc: 0.948\n",
            "epoch:19 step:  90 loss: 0.089 acc: 0.952\n",
            "epoch:19 step: 120 loss: 0.089 acc: 0.940\n",
            "epoch:19 step: 150 loss: 0.091 acc: 0.926\n",
            "epoch:19 step: 180 loss: 0.094 acc: 0.940\n",
            "epoch:19 step: 210 loss: 0.086 acc: 0.947\n",
            "epoch:19 step: 240 loss: 0.089 acc: 0.947\n",
            "epoch:20 step:  30 loss: 0.088 acc: 0.977\n",
            "epoch:20 step:  60 loss: 0.089 acc: 0.948\n",
            "epoch:20 step:  90 loss: 0.091 acc: 0.942\n",
            "epoch:20 step: 120 loss: 0.091 acc: 0.944\n",
            "epoch:20 step: 150 loss: 0.090 acc: 0.943\n",
            "epoch:20 step: 180 loss: 0.091 acc: 0.938\n",
            "epoch:20 step: 210 loss: 0.091 acc: 0.935\n",
            "epoch:20 step: 240 loss: 0.086 acc: 0.942\n",
            "epoch:21 step:  30 loss: 0.092 acc: 0.979\n",
            "epoch:21 step:  60 loss: 0.093 acc: 0.939\n",
            "epoch:21 step:  90 loss: 0.085 acc: 0.950\n",
            "epoch:21 step: 120 loss: 0.089 acc: 0.943\n",
            "epoch:21 step: 150 loss: 0.088 acc: 0.954\n",
            "epoch:21 step: 180 loss: 0.088 acc: 0.949\n",
            "epoch:21 step: 210 loss: 0.088 acc: 0.932\n",
            "epoch:21 step: 240 loss: 0.090 acc: 0.938\n",
            "epoch:22 step:  30 loss: 0.089 acc: 0.983\n",
            "epoch:22 step:  60 loss: 0.085 acc: 0.952\n",
            "epoch:22 step:  90 loss: 0.087 acc: 0.947\n",
            "epoch:22 step: 120 loss: 0.092 acc: 0.936\n",
            "epoch:22 step: 150 loss: 0.090 acc: 0.946\n",
            "epoch:22 step: 180 loss: 0.092 acc: 0.952\n",
            "epoch:22 step: 210 loss: 0.085 acc: 0.949\n",
            "epoch:22 step: 240 loss: 0.083 acc: 0.935\n",
            "epoch:23 step:  30 loss: 0.091 acc: 0.976\n",
            "epoch:23 step:  60 loss: 0.089 acc: 0.945\n",
            "epoch:23 step:  90 loss: 0.089 acc: 0.944\n",
            "epoch:23 step: 120 loss: 0.086 acc: 0.954\n",
            "epoch:23 step: 150 loss: 0.083 acc: 0.959\n",
            "epoch:23 step: 180 loss: 0.090 acc: 0.938\n",
            "epoch:23 step: 210 loss: 0.084 acc: 0.946\n",
            "epoch:23 step: 240 loss: 0.089 acc: 0.924\n",
            "epoch:24 step:  30 loss: 0.087 acc: 0.990\n",
            "epoch:24 step:  60 loss: 0.081 acc: 0.957\n",
            "epoch:24 step:  90 loss: 0.087 acc: 0.941\n",
            "epoch:24 step: 120 loss: 0.085 acc: 0.950\n",
            "epoch:24 step: 150 loss: 0.093 acc: 0.945\n",
            "epoch:24 step: 180 loss: 0.088 acc: 0.953\n",
            "epoch:24 step: 210 loss: 0.087 acc: 0.943\n",
            "epoch:24 step: 240 loss: 0.088 acc: 0.941\n",
            "epoch:25 step:  30 loss: 0.094 acc: 0.967\n",
            "epoch:25 step:  60 loss: 0.083 acc: 0.948\n",
            "epoch:25 step:  90 loss: 0.084 acc: 0.958\n",
            "epoch:25 step: 120 loss: 0.082 acc: 0.952\n",
            "epoch:25 step: 150 loss: 0.092 acc: 0.943\n",
            "epoch:25 step: 180 loss: 0.083 acc: 0.958\n",
            "epoch:25 step: 210 loss: 0.090 acc: 0.940\n",
            "epoch:25 step: 240 loss: 0.084 acc: 0.949\n",
            "epoch:26 step:  30 loss: 0.088 acc: 0.981\n",
            "epoch:26 step:  60 loss: 0.082 acc: 0.959\n",
            "epoch:26 step:  90 loss: 0.089 acc: 0.933\n",
            "epoch:26 step: 120 loss: 0.086 acc: 0.945\n",
            "epoch:26 step: 150 loss: 0.090 acc: 0.936\n",
            "epoch:26 step: 180 loss: 0.086 acc: 0.948\n",
            "epoch:26 step: 210 loss: 0.084 acc: 0.943\n",
            "epoch:26 step: 240 loss: 0.085 acc: 0.961\n",
            "epoch:27 step:  30 loss: 0.080 acc: 0.999\n",
            "epoch:27 step:  60 loss: 0.084 acc: 0.958\n",
            "epoch:27 step:  90 loss: 0.090 acc: 0.952\n",
            "epoch:27 step: 120 loss: 0.089 acc: 0.949\n",
            "epoch:27 step: 150 loss: 0.087 acc: 0.943\n",
            "epoch:27 step: 180 loss: 0.087 acc: 0.955\n",
            "epoch:27 step: 210 loss: 0.084 acc: 0.958\n",
            "epoch:27 step: 240 loss: 0.086 acc: 0.952\n",
            "epoch:28 step:  30 loss: 0.088 acc: 0.981\n",
            "epoch:28 step:  60 loss: 0.087 acc: 0.942\n",
            "epoch:28 step:  90 loss: 0.084 acc: 0.940\n",
            "epoch:28 step: 120 loss: 0.081 acc: 0.954\n",
            "epoch:28 step: 150 loss: 0.081 acc: 0.958\n",
            "epoch:28 step: 180 loss: 0.085 acc: 0.955\n",
            "epoch:28 step: 210 loss: 0.081 acc: 0.964\n",
            "epoch:28 step: 240 loss: 0.088 acc: 0.949\n",
            "epoch:29 step:  30 loss: 0.090 acc: 0.993\n",
            "epoch:29 step:  60 loss: 0.078 acc: 0.958\n",
            "epoch:29 step:  90 loss: 0.089 acc: 0.945\n",
            "epoch:29 step: 120 loss: 0.085 acc: 0.958\n",
            "epoch:29 step: 150 loss: 0.074 acc: 0.971\n",
            "epoch:29 step: 180 loss: 0.087 acc: 0.947\n",
            "epoch:29 step: 210 loss: 0.086 acc: 0.945\n",
            "epoch:29 step: 240 loss: 0.086 acc: 0.946\n",
            "epoch:30 step:  30 loss: 0.083 acc: 0.993\n",
            "epoch:30 step:  60 loss: 0.079 acc: 0.969\n",
            "epoch:30 step:  90 loss: 0.085 acc: 0.950\n",
            "epoch:30 step: 120 loss: 0.079 acc: 0.961\n",
            "epoch:30 step: 150 loss: 0.082 acc: 0.950\n",
            "epoch:30 step: 180 loss: 0.090 acc: 0.954\n",
            "epoch:30 step: 210 loss: 0.084 acc: 0.952\n",
            "epoch:30 step: 240 loss: 0.083 acc: 0.942\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEQ654uMt-5F",
        "colab_type": "text"
      },
      "source": [
        "# 6.ProTip: mnist InMemDataLoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_t9uLvut-5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InMemDataLoader(object):\n",
        "    __initialized = False\n",
        "    def __init__(self, tensors, batch_size=1, shuffle=False, sampler=None,\n",
        "                 batch_sampler=None, drop_last=False):\n",
        "        \"\"\"A torch dataloader that fetches data from memory.\"\"\"\n",
        "        tensors = [torch.tensor(tensor) for tensor in tensors]\n",
        "        dataset = torch.utils.data.TensorDataset(*tensors)\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.drop_last = drop_last\n",
        "        \n",
        "        if batch_sampler is not None:\n",
        "            if batch_size > 1 or shuffle or sampler is not None or drop_last:\n",
        "                raise ValueError('batch_sampler option is mutually exclusive '\n",
        "                                 'with batch_size, shuffle, sampler, and '\n",
        "                                 'drop_last')\n",
        "            self.batch_size = None\n",
        "            self.drop_last = None\n",
        "\n",
        "        if sampler is not None and shuffle:\n",
        "            raise ValueError('sampler option is mutually exclusive with '\n",
        "                             'shuffle')\n",
        "            \n",
        "        if batch_sampler is None:\n",
        "            if sampler is None:\n",
        "                if shuffle:\n",
        "                    sampler = torch.utils.data.RandomSampler(dataset)\n",
        "                else:\n",
        "                    sampler = torch.utils.data.SequentialSampler(dataset)\n",
        "            batch_sampler = torch.utils.data.BatchSampler(sampler, batch_size, drop_last)\n",
        "\n",
        "        self.sampler = sampler\n",
        "        self.batch_sampler = batch_sampler\n",
        "        self.__initialized = True\n",
        "    \n",
        "    def __setattr__(self, attr, val):\n",
        "        if self.__initialized and attr in ('batch_size', 'sampler', 'drop_last'):\n",
        "            raise ValueError('{} attribute should not be set after {} is '\n",
        "                             'initialized'.format(attr, self.__class__.__name__))\n",
        "\n",
        "        super(InMemDataLoader, self).__setattr__(attr, val)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for batch_indices in self.batch_sampler:\n",
        "            yield self.dataset[batch_indices]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.batch_sampler)\n",
        "    \n",
        "    def to(self, device):\n",
        "        self.dataset.tensors = tuple(t.to(device) for t in self.dataset.tensors)\n",
        "        return self"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4oyu4cOt-5H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "c4aa21f4-560f-4272-b09e-ba87232c3d93"
      },
      "source": [
        "##### HOW TO USE! ###\n",
        "# Download raw data\n",
        "# !command runs shell command in jupyter notebook\n",
        "!pip install -q gdown httpimport\n",
        "![ -e mnist.npz ] || gdown 'https://drive.google.com/uc?id=1QPaC3IKB_5tX6yIZgRgkpcqFrfVqPTXU' -O mnist.npz\n",
        "\n",
        "#Extracting data\n",
        "with np.load('mnist.npz') as data:\n",
        "    mnist_full_train_data = data['train_data'].astype('float32') / 255.0\n",
        "\n",
        "\n",
        "#Fast loader initialziation\n",
        "train_loader = InMemDataLoader(\n",
        "    (mnist_full_train_data, ), batch_size=25, shuffle=True)\n",
        "next(iter(train_loader))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QPaC3IKB_5tX6yIZgRgkpcqFrfVqPTXU\n",
            "To: /content/mnist.npz\n",
            "55.4MB [00:00, 97.5MB/s]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]]]),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1jdLsAVvO89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}